{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "net = ResNet18()     # Create the network instance.\n",
    "net.to(device)  # Move the network parameters to the specified device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "# We use stochastic gradient descent (SGD) as optimizer.\n",
    "opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:    99] avg mini-batch loss: 2.429\n",
      "[epoch: 0, i:   199] avg mini-batch loss: 2.296\n",
      "[epoch: 0, i:   299] avg mini-batch loss: 2.199\n",
      "[epoch: 0, i:   399] avg mini-batch loss: 2.129\n",
      "[epoch: 0, i:   499] avg mini-batch loss: 2.043\n",
      "[epoch: 0, i:   599] avg mini-batch loss: 2.029\n",
      "[epoch: 0, i:   699] avg mini-batch loss: 2.097\n",
      "[epoch: 0, i:   799] avg mini-batch loss: 1.976\n",
      "[epoch: 0, i:   899] avg mini-batch loss: 1.924\n",
      "[epoch: 0, i:   999] avg mini-batch loss: 1.913\n",
      "[epoch: 0, i:  1099] avg mini-batch loss: 1.965\n",
      "[epoch: 0, i:  1199] avg mini-batch loss: 1.956\n",
      "[epoch: 0, i:  1299] avg mini-batch loss: 1.918\n",
      "[epoch: 0, i:  1399] avg mini-batch loss: 1.885\n",
      "[epoch: 0, i:  1499] avg mini-batch loss: 1.804\n",
      "[epoch: 0, i:  1599] avg mini-batch loss: 1.784\n",
      "[epoch: 0, i:  1699] avg mini-batch loss: 1.779\n",
      "[epoch: 0, i:  1799] avg mini-batch loss: 1.733\n",
      "[epoch: 0, i:  1899] avg mini-batch loss: 1.671\n",
      "[epoch: 0, i:  1999] avg mini-batch loss: 1.787\n",
      "[epoch: 0, i:  2099] avg mini-batch loss: 1.855\n",
      "[epoch: 0, i:  2199] avg mini-batch loss: 1.754\n",
      "[epoch: 0, i:  2299] avg mini-batch loss: 1.791\n",
      "[epoch: 0, i:  2399] avg mini-batch loss: 1.698\n",
      "[epoch: 0, i:  2499] avg mini-batch loss: 1.753\n",
      "[epoch: 0, i:  2599] avg mini-batch loss: 1.777\n",
      "[epoch: 0, i:  2699] avg mini-batch loss: 1.707\n",
      "[epoch: 0, i:  2799] avg mini-batch loss: 1.620\n",
      "[epoch: 0, i:  2899] avg mini-batch loss: 1.586\n",
      "[epoch: 0, i:  2999] avg mini-batch loss: 1.682\n",
      "[epoch: 0, i:  3099] avg mini-batch loss: 1.576\n",
      "[epoch: 0, i:  3199] avg mini-batch loss: 1.591\n",
      "[epoch: 0, i:  3299] avg mini-batch loss: 1.572\n",
      "[epoch: 0, i:  3399] avg mini-batch loss: 1.644\n",
      "[epoch: 0, i:  3499] avg mini-batch loss: 1.602\n",
      "[epoch: 0, i:  3599] avg mini-batch loss: 1.645\n",
      "[epoch: 0, i:  3699] avg mini-batch loss: 1.471\n",
      "[epoch: 0, i:  3799] avg mini-batch loss: 1.505\n",
      "[epoch: 0, i:  3899] avg mini-batch loss: 1.559\n",
      "[epoch: 0, i:  3999] avg mini-batch loss: 1.674\n",
      "[epoch: 0, i:  4099] avg mini-batch loss: 1.571\n",
      "[epoch: 0, i:  4199] avg mini-batch loss: 1.484\n",
      "[epoch: 0, i:  4299] avg mini-batch loss: 1.366\n",
      "[epoch: 0, i:  4399] avg mini-batch loss: 1.448\n",
      "[epoch: 0, i:  4499] avg mini-batch loss: 1.565\n",
      "[epoch: 0, i:  4599] avg mini-batch loss: 1.418\n",
      "[epoch: 0, i:  4699] avg mini-batch loss: 1.595\n",
      "[epoch: 0, i:  4799] avg mini-batch loss: 1.509\n",
      "[epoch: 0, i:  4899] avg mini-batch loss: 1.444\n",
      "[epoch: 0, i:  4999] avg mini-batch loss: 1.489\n",
      "[epoch: 0, i:  5099] avg mini-batch loss: 1.449\n",
      "[epoch: 0, i:  5199] avg mini-batch loss: 1.446\n",
      "[epoch: 0, i:  5299] avg mini-batch loss: 1.376\n",
      "[epoch: 0, i:  5399] avg mini-batch loss: 1.510\n",
      "[epoch: 0, i:  5499] avg mini-batch loss: 1.299\n",
      "[epoch: 0, i:  5599] avg mini-batch loss: 1.467\n",
      "[epoch: 0, i:  5699] avg mini-batch loss: 1.394\n",
      "[epoch: 0, i:  5799] avg mini-batch loss: 1.335\n",
      "[epoch: 0, i:  5899] avg mini-batch loss: 1.387\n",
      "[epoch: 0, i:  5999] avg mini-batch loss: 1.373\n",
      "[epoch: 0, i:  6099] avg mini-batch loss: 1.311\n",
      "[epoch: 0, i:  6199] avg mini-batch loss: 1.395\n",
      "[epoch: 0, i:  6299] avg mini-batch loss: 1.329\n",
      "[epoch: 0, i:  6399] avg mini-batch loss: 1.372\n",
      "[epoch: 0, i:  6499] avg mini-batch loss: 1.148\n",
      "[epoch: 0, i:  6599] avg mini-batch loss: 1.351\n",
      "[epoch: 0, i:  6699] avg mini-batch loss: 1.154\n",
      "[epoch: 0, i:  6799] avg mini-batch loss: 1.139\n",
      "[epoch: 0, i:  6899] avg mini-batch loss: 1.365\n",
      "[epoch: 0, i:  6999] avg mini-batch loss: 1.124\n",
      "[epoch: 0, i:  7099] avg mini-batch loss: 1.436\n",
      "[epoch: 0, i:  7199] avg mini-batch loss: 1.210\n",
      "[epoch: 0, i:  7299] avg mini-batch loss: 1.271\n",
      "[epoch: 0, i:  7399] avg mini-batch loss: 1.129\n",
      "[epoch: 0, i:  7499] avg mini-batch loss: 1.289\n",
      "[epoch: 0, i:  7599] avg mini-batch loss: 1.284\n",
      "[epoch: 0, i:  7699] avg mini-batch loss: 1.172\n",
      "[epoch: 0, i:  7799] avg mini-batch loss: 1.231\n",
      "[epoch: 0, i:  7899] avg mini-batch loss: 1.249\n",
      "[epoch: 0, i:  7999] avg mini-batch loss: 1.199\n",
      "[epoch: 0, i:  8099] avg mini-batch loss: 1.304\n",
      "[epoch: 0, i:  8199] avg mini-batch loss: 1.266\n",
      "[epoch: 0, i:  8299] avg mini-batch loss: 1.198\n",
      "[epoch: 0, i:  8399] avg mini-batch loss: 1.174\n",
      "[epoch: 0, i:  8499] avg mini-batch loss: 1.211\n",
      "[epoch: 0, i:  8599] avg mini-batch loss: 1.134\n",
      "[epoch: 0, i:  8699] avg mini-batch loss: 1.204\n",
      "[epoch: 0, i:  8799] avg mini-batch loss: 1.024\n",
      "[epoch: 0, i:  8899] avg mini-batch loss: 1.156\n",
      "[epoch: 0, i:  8999] avg mini-batch loss: 1.151\n",
      "[epoch: 0, i:  9099] avg mini-batch loss: 1.119\n",
      "[epoch: 0, i:  9199] avg mini-batch loss: 1.106\n",
      "[epoch: 0, i:  9299] avg mini-batch loss: 1.009\n",
      "[epoch: 0, i:  9399] avg mini-batch loss: 1.076\n",
      "[epoch: 0, i:  9499] avg mini-batch loss: 1.070\n",
      "[epoch: 0, i:  9599] avg mini-batch loss: 1.101\n",
      "[epoch: 0, i:  9699] avg mini-batch loss: 1.121\n",
      "[epoch: 0, i:  9799] avg mini-batch loss: 1.066\n",
      "[epoch: 0, i:  9899] avg mini-batch loss: 1.081\n",
      "[epoch: 0, i:  9999] avg mini-batch loss: 1.089\n",
      "[epoch: 0, i: 10099] avg mini-batch loss: 1.255\n",
      "[epoch: 0, i: 10199] avg mini-batch loss: 1.136\n",
      "[epoch: 0, i: 10299] avg mini-batch loss: 1.102\n",
      "[epoch: 0, i: 10399] avg mini-batch loss: 1.165\n",
      "[epoch: 0, i: 10499] avg mini-batch loss: 1.092\n",
      "[epoch: 0, i: 10599] avg mini-batch loss: 1.044\n",
      "[epoch: 0, i: 10699] avg mini-batch loss: 1.015\n",
      "[epoch: 0, i: 10799] avg mini-batch loss: 1.091\n",
      "[epoch: 0, i: 10899] avg mini-batch loss: 1.112\n",
      "[epoch: 0, i: 10999] avg mini-batch loss: 1.123\n",
      "[epoch: 0, i: 11099] avg mini-batch loss: 0.981\n",
      "[epoch: 0, i: 11199] avg mini-batch loss: 1.000\n",
      "[epoch: 0, i: 11299] avg mini-batch loss: 0.960\n",
      "[epoch: 0, i: 11399] avg mini-batch loss: 1.042\n",
      "[epoch: 0, i: 11499] avg mini-batch loss: 1.007\n",
      "[epoch: 0, i: 11599] avg mini-batch loss: 1.026\n",
      "[epoch: 0, i: 11699] avg mini-batch loss: 1.068\n",
      "[epoch: 0, i: 11799] avg mini-batch loss: 1.001\n",
      "[epoch: 0, i: 11899] avg mini-batch loss: 1.114\n",
      "[epoch: 0, i: 11999] avg mini-batch loss: 1.057\n",
      "[epoch: 0, i: 12099] avg mini-batch loss: 1.135\n",
      "[epoch: 0, i: 12199] avg mini-batch loss: 1.021\n",
      "[epoch: 0, i: 12299] avg mini-batch loss: 1.037\n",
      "[epoch: 0, i: 12399] avg mini-batch loss: 0.931\n",
      "[epoch: 0, i: 12499] avg mini-batch loss: 0.982\n",
      "[epoch: 1, i:    99] avg mini-batch loss: 0.937\n",
      "[epoch: 1, i:   199] avg mini-batch loss: 0.925\n",
      "[epoch: 1, i:   299] avg mini-batch loss: 0.932\n",
      "[epoch: 1, i:   399] avg mini-batch loss: 1.006\n",
      "[epoch: 1, i:   499] avg mini-batch loss: 0.908\n",
      "[epoch: 1, i:   599] avg mini-batch loss: 0.968\n",
      "[epoch: 1, i:   699] avg mini-batch loss: 0.952\n",
      "[epoch: 1, i:   799] avg mini-batch loss: 0.959\n",
      "[epoch: 1, i:   899] avg mini-batch loss: 0.913\n",
      "[epoch: 1, i:   999] avg mini-batch loss: 0.952\n",
      "[epoch: 1, i:  1099] avg mini-batch loss: 0.946\n",
      "[epoch: 1, i:  1199] avg mini-batch loss: 1.052\n",
      "[epoch: 1, i:  1299] avg mini-batch loss: 0.992\n",
      "[epoch: 1, i:  1399] avg mini-batch loss: 0.929\n",
      "[epoch: 1, i:  1499] avg mini-batch loss: 0.826\n",
      "[epoch: 1, i:  1599] avg mini-batch loss: 0.862\n",
      "[epoch: 1, i:  1699] avg mini-batch loss: 0.864\n",
      "[epoch: 1, i:  1799] avg mini-batch loss: 0.934\n",
      "[epoch: 1, i:  1899] avg mini-batch loss: 0.979\n",
      "[epoch: 1, i:  1999] avg mini-batch loss: 0.976\n",
      "[epoch: 1, i:  2099] avg mini-batch loss: 0.814\n",
      "[epoch: 1, i:  2199] avg mini-batch loss: 0.791\n",
      "[epoch: 1, i:  2299] avg mini-batch loss: 0.932\n",
      "[epoch: 1, i:  2399] avg mini-batch loss: 0.910\n",
      "[epoch: 1, i:  2499] avg mini-batch loss: 0.956\n",
      "[epoch: 1, i:  2599] avg mini-batch loss: 0.961\n",
      "[epoch: 1, i:  2699] avg mini-batch loss: 0.762\n",
      "[epoch: 1, i:  2799] avg mini-batch loss: 0.981\n",
      "[epoch: 1, i:  2899] avg mini-batch loss: 0.884\n",
      "[epoch: 1, i:  2999] avg mini-batch loss: 0.859\n",
      "[epoch: 1, i:  3099] avg mini-batch loss: 0.918\n",
      "[epoch: 1, i:  3199] avg mini-batch loss: 0.890\n",
      "[epoch: 1, i:  3299] avg mini-batch loss: 0.837\n",
      "[epoch: 1, i:  3399] avg mini-batch loss: 0.855\n",
      "[epoch: 1, i:  3499] avg mini-batch loss: 0.847\n",
      "[epoch: 1, i:  3599] avg mini-batch loss: 0.938\n",
      "[epoch: 1, i:  3699] avg mini-batch loss: 0.849\n",
      "[epoch: 1, i:  3799] avg mini-batch loss: 0.982\n",
      "[epoch: 1, i:  3899] avg mini-batch loss: 0.852\n",
      "[epoch: 1, i:  3999] avg mini-batch loss: 0.859\n",
      "[epoch: 1, i:  4099] avg mini-batch loss: 0.803\n",
      "[epoch: 1, i:  4199] avg mini-batch loss: 0.871\n",
      "[epoch: 1, i:  4299] avg mini-batch loss: 0.794\n",
      "[epoch: 1, i:  4399] avg mini-batch loss: 0.872\n",
      "[epoch: 1, i:  4499] avg mini-batch loss: 0.916\n",
      "[epoch: 1, i:  4599] avg mini-batch loss: 0.796\n",
      "[epoch: 1, i:  4699] avg mini-batch loss: 0.882\n",
      "[epoch: 1, i:  4799] avg mini-batch loss: 0.812\n",
      "[epoch: 1, i:  4899] avg mini-batch loss: 0.838\n",
      "[epoch: 1, i:  4999] avg mini-batch loss: 0.852\n",
      "[epoch: 1, i:  5099] avg mini-batch loss: 0.846\n",
      "[epoch: 1, i:  5199] avg mini-batch loss: 0.873\n",
      "[epoch: 1, i:  5299] avg mini-batch loss: 0.885\n",
      "[epoch: 1, i:  5399] avg mini-batch loss: 0.865\n",
      "[epoch: 1, i:  5499] avg mini-batch loss: 0.810\n",
      "[epoch: 1, i:  5599] avg mini-batch loss: 0.661\n",
      "[epoch: 1, i:  5699] avg mini-batch loss: 0.869\n",
      "[epoch: 1, i:  5799] avg mini-batch loss: 0.846\n",
      "[epoch: 1, i:  5899] avg mini-batch loss: 0.830\n",
      "[epoch: 1, i:  5999] avg mini-batch loss: 0.891\n",
      "[epoch: 1, i:  6099] avg mini-batch loss: 0.855\n",
      "[epoch: 1, i:  6199] avg mini-batch loss: 0.867\n",
      "[epoch: 1, i:  6299] avg mini-batch loss: 0.834\n",
      "[epoch: 1, i:  6399] avg mini-batch loss: 0.868\n",
      "[epoch: 1, i:  6499] avg mini-batch loss: 0.878\n",
      "[epoch: 1, i:  6599] avg mini-batch loss: 0.901\n",
      "[epoch: 1, i:  6699] avg mini-batch loss: 0.673\n",
      "[epoch: 1, i:  6799] avg mini-batch loss: 0.724\n",
      "[epoch: 1, i:  6899] avg mini-batch loss: 0.780\n",
      "[epoch: 1, i:  6999] avg mini-batch loss: 0.865\n",
      "[epoch: 1, i:  7099] avg mini-batch loss: 0.852\n",
      "[epoch: 1, i:  7199] avg mini-batch loss: 0.802\n",
      "[epoch: 1, i:  7299] avg mini-batch loss: 0.755\n",
      "[epoch: 1, i:  7399] avg mini-batch loss: 0.759\n",
      "[epoch: 1, i:  7499] avg mini-batch loss: 0.761\n",
      "[epoch: 1, i:  7599] avg mini-batch loss: 0.744\n",
      "[epoch: 1, i:  7699] avg mini-batch loss: 0.779\n",
      "[epoch: 1, i:  7799] avg mini-batch loss: 0.808\n",
      "[epoch: 1, i:  7899] avg mini-batch loss: 0.846\n",
      "[epoch: 1, i:  7999] avg mini-batch loss: 0.796\n",
      "[epoch: 1, i:  8099] avg mini-batch loss: 0.888\n",
      "[epoch: 1, i:  8199] avg mini-batch loss: 0.959\n",
      "[epoch: 1, i:  8299] avg mini-batch loss: 0.731\n",
      "[epoch: 1, i:  8399] avg mini-batch loss: 0.836\n",
      "[epoch: 1, i:  8499] avg mini-batch loss: 0.717\n",
      "[epoch: 1, i:  8599] avg mini-batch loss: 0.693\n",
      "[epoch: 1, i:  8699] avg mini-batch loss: 0.834\n",
      "[epoch: 1, i:  8799] avg mini-batch loss: 0.891\n",
      "[epoch: 1, i:  8899] avg mini-batch loss: 0.752\n",
      "[epoch: 1, i:  8999] avg mini-batch loss: 0.712\n",
      "[epoch: 1, i:  9099] avg mini-batch loss: 0.766\n",
      "[epoch: 1, i:  9199] avg mini-batch loss: 0.767\n",
      "[epoch: 1, i:  9299] avg mini-batch loss: 0.892\n",
      "[epoch: 1, i:  9399] avg mini-batch loss: 0.877\n",
      "[epoch: 1, i:  9499] avg mini-batch loss: 0.780\n",
      "[epoch: 1, i:  9599] avg mini-batch loss: 0.897\n",
      "[epoch: 1, i:  9699] avg mini-batch loss: 0.911\n",
      "[epoch: 1, i:  9799] avg mini-batch loss: 0.798\n",
      "[epoch: 1, i:  9899] avg mini-batch loss: 0.760\n",
      "[epoch: 1, i:  9999] avg mini-batch loss: 0.809\n",
      "[epoch: 1, i: 10099] avg mini-batch loss: 0.697\n",
      "[epoch: 1, i: 10199] avg mini-batch loss: 0.754\n",
      "[epoch: 1, i: 10299] avg mini-batch loss: 0.791\n",
      "[epoch: 1, i: 10399] avg mini-batch loss: 0.814\n",
      "[epoch: 1, i: 10499] avg mini-batch loss: 0.805\n",
      "[epoch: 1, i: 10599] avg mini-batch loss: 0.736\n",
      "[epoch: 1, i: 10699] avg mini-batch loss: 0.754\n",
      "[epoch: 1, i: 10799] avg mini-batch loss: 0.744\n",
      "[epoch: 1, i: 10899] avg mini-batch loss: 0.702\n",
      "[epoch: 1, i: 10999] avg mini-batch loss: 0.761\n",
      "[epoch: 1, i: 11099] avg mini-batch loss: 0.626\n",
      "[epoch: 1, i: 11199] avg mini-batch loss: 0.773\n",
      "[epoch: 1, i: 11299] avg mini-batch loss: 0.781\n",
      "[epoch: 1, i: 11399] avg mini-batch loss: 0.706\n",
      "[epoch: 1, i: 11499] avg mini-batch loss: 0.636\n",
      "[epoch: 1, i: 11599] avg mini-batch loss: 0.831\n",
      "[epoch: 1, i: 11699] avg mini-batch loss: 0.807\n",
      "[epoch: 1, i: 11799] avg mini-batch loss: 0.813\n",
      "[epoch: 1, i: 11899] avg mini-batch loss: 0.759\n",
      "[epoch: 1, i: 11999] avg mini-batch loss: 0.765\n",
      "[epoch: 1, i: 12099] avg mini-batch loss: 0.739\n",
      "[epoch: 1, i: 12199] avg mini-batch loss: 0.752\n",
      "[epoch: 1, i: 12299] avg mini-batch loss: 0.761\n",
      "[epoch: 1, i: 12399] avg mini-batch loss: 0.648\n",
      "[epoch: 1, i: 12499] avg mini-batch loss: 0.669\n",
      "[epoch: 2, i:    99] avg mini-batch loss: 0.619\n",
      "[epoch: 2, i:   199] avg mini-batch loss: 0.637\n",
      "[epoch: 2, i:   299] avg mini-batch loss: 0.559\n",
      "[epoch: 2, i:   399] avg mini-batch loss: 0.650\n",
      "[epoch: 2, i:   499] avg mini-batch loss: 0.641\n",
      "[epoch: 2, i:   599] avg mini-batch loss: 0.603\n",
      "[epoch: 2, i:   699] avg mini-batch loss: 0.654\n",
      "[epoch: 2, i:   799] avg mini-batch loss: 0.721\n",
      "[epoch: 2, i:   899] avg mini-batch loss: 0.660\n",
      "[epoch: 2, i:   999] avg mini-batch loss: 0.685\n",
      "[epoch: 2, i:  1099] avg mini-batch loss: 0.635\n",
      "[epoch: 2, i:  1199] avg mini-batch loss: 0.556\n",
      "[epoch: 2, i:  1299] avg mini-batch loss: 0.691\n",
      "[epoch: 2, i:  1399] avg mini-batch loss: 0.616\n",
      "[epoch: 2, i:  1499] avg mini-batch loss: 0.644\n",
      "[epoch: 2, i:  1599] avg mini-batch loss: 0.629\n",
      "[epoch: 2, i:  1699] avg mini-batch loss: 0.686\n",
      "[epoch: 2, i:  1799] avg mini-batch loss: 0.693\n",
      "[epoch: 2, i:  1899] avg mini-batch loss: 0.683\n",
      "[epoch: 2, i:  1999] avg mini-batch loss: 0.568\n",
      "[epoch: 2, i:  2099] avg mini-batch loss: 0.600\n",
      "[epoch: 2, i:  2199] avg mini-batch loss: 0.656\n",
      "[epoch: 2, i:  2299] avg mini-batch loss: 0.601\n",
      "[epoch: 2, i:  2399] avg mini-batch loss: 0.624\n",
      "[epoch: 2, i:  2499] avg mini-batch loss: 0.598\n",
      "[epoch: 2, i:  2599] avg mini-batch loss: 0.605\n",
      "[epoch: 2, i:  2699] avg mini-batch loss: 0.641\n",
      "[epoch: 2, i:  2799] avg mini-batch loss: 0.617\n",
      "[epoch: 2, i:  2899] avg mini-batch loss: 0.650\n",
      "[epoch: 2, i:  2999] avg mini-batch loss: 0.584\n",
      "[epoch: 2, i:  3099] avg mini-batch loss: 0.590\n",
      "[epoch: 2, i:  3199] avg mini-batch loss: 0.592\n",
      "[epoch: 2, i:  3299] avg mini-batch loss: 0.640\n",
      "[epoch: 2, i:  3399] avg mini-batch loss: 0.586\n",
      "[epoch: 2, i:  3499] avg mini-batch loss: 0.588\n",
      "[epoch: 2, i:  3599] avg mini-batch loss: 0.676\n",
      "[epoch: 2, i:  3699] avg mini-batch loss: 0.586\n",
      "[epoch: 2, i:  3799] avg mini-batch loss: 0.620\n",
      "[epoch: 2, i:  3899] avg mini-batch loss: 0.567\n",
      "[epoch: 2, i:  3999] avg mini-batch loss: 0.691\n",
      "[epoch: 2, i:  4099] avg mini-batch loss: 0.587\n",
      "[epoch: 2, i:  4199] avg mini-batch loss: 0.784\n",
      "[epoch: 2, i:  4299] avg mini-batch loss: 0.613\n",
      "[epoch: 2, i:  4399] avg mini-batch loss: 0.602\n",
      "[epoch: 2, i:  4499] avg mini-batch loss: 0.584\n",
      "[epoch: 2, i:  4599] avg mini-batch loss: 0.684\n",
      "[epoch: 2, i:  4699] avg mini-batch loss: 0.635\n",
      "[epoch: 2, i:  4799] avg mini-batch loss: 0.637\n",
      "[epoch: 2, i:  4899] avg mini-batch loss: 0.680\n",
      "[epoch: 2, i:  4999] avg mini-batch loss: 0.671\n",
      "[epoch: 2, i:  5099] avg mini-batch loss: 0.743\n",
      "[epoch: 2, i:  5199] avg mini-batch loss: 0.556\n",
      "[epoch: 2, i:  5299] avg mini-batch loss: 0.545\n",
      "[epoch: 2, i:  5399] avg mini-batch loss: 0.696\n",
      "[epoch: 2, i:  5499] avg mini-batch loss: 0.691\n",
      "[epoch: 2, i:  5599] avg mini-batch loss: 0.564\n",
      "[epoch: 2, i:  5699] avg mini-batch loss: 0.639\n",
      "[epoch: 2, i:  5799] avg mini-batch loss: 0.532\n",
      "[epoch: 2, i:  5899] avg mini-batch loss: 0.617\n",
      "[epoch: 2, i:  5999] avg mini-batch loss: 0.571\n",
      "[epoch: 2, i:  6099] avg mini-batch loss: 0.601\n",
      "[epoch: 2, i:  6199] avg mini-batch loss: 0.606\n",
      "[epoch: 2, i:  6299] avg mini-batch loss: 0.686\n",
      "[epoch: 2, i:  6399] avg mini-batch loss: 0.656\n",
      "[epoch: 2, i:  6499] avg mini-batch loss: 0.543\n",
      "[epoch: 2, i:  6599] avg mini-batch loss: 0.566\n",
      "[epoch: 2, i:  6699] avg mini-batch loss: 0.670\n",
      "[epoch: 2, i:  6799] avg mini-batch loss: 0.487\n",
      "[epoch: 2, i:  6899] avg mini-batch loss: 0.631\n",
      "[epoch: 2, i:  6999] avg mini-batch loss: 0.614\n",
      "[epoch: 2, i:  7099] avg mini-batch loss: 0.673\n",
      "[epoch: 2, i:  7199] avg mini-batch loss: 0.612\n",
      "[epoch: 2, i:  7299] avg mini-batch loss: 0.585\n",
      "[epoch: 2, i:  7399] avg mini-batch loss: 0.590\n",
      "[epoch: 2, i:  7499] avg mini-batch loss: 0.615\n",
      "[epoch: 2, i:  7599] avg mini-batch loss: 0.544\n",
      "[epoch: 2, i:  7699] avg mini-batch loss: 0.562\n",
      "[epoch: 2, i:  7799] avg mini-batch loss: 0.629\n",
      "[epoch: 2, i:  7899] avg mini-batch loss: 0.603\n",
      "[epoch: 2, i:  7999] avg mini-batch loss: 0.645\n",
      "[epoch: 2, i:  8099] avg mini-batch loss: 0.538\n",
      "[epoch: 2, i:  8199] avg mini-batch loss: 0.650\n",
      "[epoch: 2, i:  8299] avg mini-batch loss: 0.588\n",
      "[epoch: 2, i:  8399] avg mini-batch loss: 0.667\n",
      "[epoch: 2, i:  8499] avg mini-batch loss: 0.508\n",
      "[epoch: 2, i:  8599] avg mini-batch loss: 0.641\n",
      "[epoch: 2, i:  8699] avg mini-batch loss: 0.590\n",
      "[epoch: 2, i:  8799] avg mini-batch loss: 0.694\n",
      "[epoch: 2, i:  8899] avg mini-batch loss: 0.650\n",
      "[epoch: 2, i:  8999] avg mini-batch loss: 0.510\n",
      "[epoch: 2, i:  9099] avg mini-batch loss: 0.650\n",
      "[epoch: 2, i:  9199] avg mini-batch loss: 0.627\n",
      "[epoch: 2, i:  9299] avg mini-batch loss: 0.585\n",
      "[epoch: 2, i:  9399] avg mini-batch loss: 0.588\n",
      "[epoch: 2, i:  9499] avg mini-batch loss: 0.619\n",
      "[epoch: 2, i:  9599] avg mini-batch loss: 0.684\n",
      "[epoch: 2, i:  9699] avg mini-batch loss: 0.628\n",
      "[epoch: 2, i:  9799] avg mini-batch loss: 0.577\n",
      "[epoch: 2, i:  9899] avg mini-batch loss: 0.698\n",
      "[epoch: 2, i:  9999] avg mini-batch loss: 0.647\n",
      "[epoch: 2, i: 10099] avg mini-batch loss: 0.548\n",
      "[epoch: 2, i: 10199] avg mini-batch loss: 0.553\n",
      "[epoch: 2, i: 10299] avg mini-batch loss: 0.588\n",
      "[epoch: 2, i: 10399] avg mini-batch loss: 0.639\n",
      "[epoch: 2, i: 10499] avg mini-batch loss: 0.682\n",
      "[epoch: 2, i: 10599] avg mini-batch loss: 0.554\n",
      "[epoch: 2, i: 10699] avg mini-batch loss: 0.630\n",
      "[epoch: 2, i: 10799] avg mini-batch loss: 0.648\n",
      "[epoch: 2, i: 10899] avg mini-batch loss: 0.553\n",
      "[epoch: 2, i: 10999] avg mini-batch loss: 0.582\n",
      "[epoch: 2, i: 11099] avg mini-batch loss: 0.613\n",
      "[epoch: 2, i: 11199] avg mini-batch loss: 0.668\n",
      "[epoch: 2, i: 11299] avg mini-batch loss: 0.593\n",
      "[epoch: 2, i: 11399] avg mini-batch loss: 0.573\n",
      "[epoch: 2, i: 11499] avg mini-batch loss: 0.556\n",
      "[epoch: 2, i: 11599] avg mini-batch loss: 0.498\n",
      "[epoch: 2, i: 11699] avg mini-batch loss: 0.658\n",
      "[epoch: 2, i: 11799] avg mini-batch loss: 0.581\n",
      "[epoch: 2, i: 11899] avg mini-batch loss: 0.662\n",
      "[epoch: 2, i: 11999] avg mini-batch loss: 0.698\n",
      "[epoch: 2, i: 12099] avg mini-batch loss: 0.603\n",
      "[epoch: 2, i: 12199] avg mini-batch loss: 0.581\n",
      "[epoch: 2, i: 12299] avg mini-batch loss: 0.571\n",
      "[epoch: 2, i: 12399] avg mini-batch loss: 0.645\n",
      "[epoch: 2, i: 12499] avg mini-batch loss: 0.601\n",
      "[epoch: 3, i:    99] avg mini-batch loss: 0.515\n",
      "[epoch: 3, i:   199] avg mini-batch loss: 0.495\n",
      "[epoch: 3, i:   299] avg mini-batch loss: 0.402\n",
      "[epoch: 3, i:   399] avg mini-batch loss: 0.459\n",
      "[epoch: 3, i:   499] avg mini-batch loss: 0.471\n",
      "[epoch: 3, i:   599] avg mini-batch loss: 0.471\n",
      "[epoch: 3, i:   699] avg mini-batch loss: 0.379\n",
      "[epoch: 3, i:   799] avg mini-batch loss: 0.440\n",
      "[epoch: 3, i:   899] avg mini-batch loss: 0.375\n",
      "[epoch: 3, i:   999] avg mini-batch loss: 0.435\n",
      "[epoch: 3, i:  1099] avg mini-batch loss: 0.455\n",
      "[epoch: 3, i:  1199] avg mini-batch loss: 0.381\n",
      "[epoch: 3, i:  1299] avg mini-batch loss: 0.406\n",
      "[epoch: 3, i:  1399] avg mini-batch loss: 0.460\n",
      "[epoch: 3, i:  1499] avg mini-batch loss: 0.444\n",
      "[epoch: 3, i:  1599] avg mini-batch loss: 0.459\n",
      "[epoch: 3, i:  1699] avg mini-batch loss: 0.422\n",
      "[epoch: 3, i:  1799] avg mini-batch loss: 0.536\n",
      "[epoch: 3, i:  1899] avg mini-batch loss: 0.545\n",
      "[epoch: 3, i:  1999] avg mini-batch loss: 0.552\n",
      "[epoch: 3, i:  2099] avg mini-batch loss: 0.521\n",
      "[epoch: 3, i:  2199] avg mini-batch loss: 0.393\n",
      "[epoch: 3, i:  2299] avg mini-batch loss: 0.348\n",
      "[epoch: 3, i:  2399] avg mini-batch loss: 0.467\n",
      "[epoch: 3, i:  2499] avg mini-batch loss: 0.460\n",
      "[epoch: 3, i:  2599] avg mini-batch loss: 0.488\n",
      "[epoch: 3, i:  2699] avg mini-batch loss: 0.489\n",
      "[epoch: 3, i:  2799] avg mini-batch loss: 0.407\n",
      "[epoch: 3, i:  2899] avg mini-batch loss: 0.466\n",
      "[epoch: 3, i:  2999] avg mini-batch loss: 0.413\n",
      "[epoch: 3, i:  3099] avg mini-batch loss: 0.355\n",
      "[epoch: 3, i:  3199] avg mini-batch loss: 0.485\n",
      "[epoch: 3, i:  3299] avg mini-batch loss: 0.493\n",
      "[epoch: 3, i:  3399] avg mini-batch loss: 0.439\n",
      "[epoch: 3, i:  3499] avg mini-batch loss: 0.492\n",
      "[epoch: 3, i:  3599] avg mini-batch loss: 0.583\n",
      "[epoch: 3, i:  3699] avg mini-batch loss: 0.494\n",
      "[epoch: 3, i:  3799] avg mini-batch loss: 0.442\n",
      "[epoch: 3, i:  3899] avg mini-batch loss: 0.484\n",
      "[epoch: 3, i:  3999] avg mini-batch loss: 0.496\n",
      "[epoch: 3, i:  4099] avg mini-batch loss: 0.460\n",
      "[epoch: 3, i:  4199] avg mini-batch loss: 0.443\n",
      "[epoch: 3, i:  4299] avg mini-batch loss: 0.444\n",
      "[epoch: 3, i:  4399] avg mini-batch loss: 0.428\n",
      "[epoch: 3, i:  4499] avg mini-batch loss: 0.421\n",
      "[epoch: 3, i:  4599] avg mini-batch loss: 0.516\n",
      "[epoch: 3, i:  4699] avg mini-batch loss: 0.502\n",
      "[epoch: 3, i:  4799] avg mini-batch loss: 0.507\n",
      "[epoch: 3, i:  4899] avg mini-batch loss: 0.460\n",
      "[epoch: 3, i:  4999] avg mini-batch loss: 0.451\n",
      "[epoch: 3, i:  5099] avg mini-batch loss: 0.382\n",
      "[epoch: 3, i:  5199] avg mini-batch loss: 0.438\n",
      "[epoch: 3, i:  5299] avg mini-batch loss: 0.413\n",
      "[epoch: 3, i:  5399] avg mini-batch loss: 0.517\n",
      "[epoch: 3, i:  5499] avg mini-batch loss: 0.566\n",
      "[epoch: 3, i:  5599] avg mini-batch loss: 0.455\n",
      "[epoch: 3, i:  5699] avg mini-batch loss: 0.536\n",
      "[epoch: 3, i:  5799] avg mini-batch loss: 0.394\n",
      "[epoch: 3, i:  5899] avg mini-batch loss: 0.336\n",
      "[epoch: 3, i:  5999] avg mini-batch loss: 0.472\n",
      "[epoch: 3, i:  6099] avg mini-batch loss: 0.409\n",
      "[epoch: 3, i:  6199] avg mini-batch loss: 0.483\n",
      "[epoch: 3, i:  6299] avg mini-batch loss: 0.539\n",
      "[epoch: 3, i:  6399] avg mini-batch loss: 0.442\n",
      "[epoch: 3, i:  6499] avg mini-batch loss: 0.447\n",
      "[epoch: 3, i:  6599] avg mini-batch loss: 0.421\n",
      "[epoch: 3, i:  6699] avg mini-batch loss: 0.457\n",
      "[epoch: 3, i:  6799] avg mini-batch loss: 0.502\n",
      "[epoch: 3, i:  6899] avg mini-batch loss: 0.579\n",
      "[epoch: 3, i:  6999] avg mini-batch loss: 0.453\n",
      "[epoch: 3, i:  7099] avg mini-batch loss: 0.470\n",
      "[epoch: 3, i:  7199] avg mini-batch loss: 0.437\n",
      "[epoch: 3, i:  7299] avg mini-batch loss: 0.571\n",
      "[epoch: 3, i:  7399] avg mini-batch loss: 0.480\n",
      "[epoch: 3, i:  7499] avg mini-batch loss: 0.406\n",
      "[epoch: 3, i:  7599] avg mini-batch loss: 0.508\n",
      "[epoch: 3, i:  7699] avg mini-batch loss: 0.498\n",
      "[epoch: 3, i:  7799] avg mini-batch loss: 0.491\n",
      "[epoch: 3, i:  7899] avg mini-batch loss: 0.475\n",
      "[epoch: 3, i:  7999] avg mini-batch loss: 0.544\n",
      "[epoch: 3, i:  8099] avg mini-batch loss: 0.416\n",
      "[epoch: 3, i:  8199] avg mini-batch loss: 0.489\n",
      "[epoch: 3, i:  8299] avg mini-batch loss: 0.480\n",
      "[epoch: 3, i:  8399] avg mini-batch loss: 0.514\n",
      "[epoch: 3, i:  8499] avg mini-batch loss: 0.439\n",
      "[epoch: 3, i:  8599] avg mini-batch loss: 0.454\n",
      "[epoch: 3, i:  8699] avg mini-batch loss: 0.537\n",
      "[epoch: 3, i:  8799] avg mini-batch loss: 0.496\n",
      "[epoch: 3, i:  8899] avg mini-batch loss: 0.467\n",
      "[epoch: 3, i:  8999] avg mini-batch loss: 0.536\n",
      "[epoch: 3, i:  9099] avg mini-batch loss: 0.485\n",
      "[epoch: 3, i:  9199] avg mini-batch loss: 0.600\n",
      "[epoch: 3, i:  9299] avg mini-batch loss: 0.550\n",
      "[epoch: 3, i:  9399] avg mini-batch loss: 0.508\n",
      "[epoch: 3, i:  9499] avg mini-batch loss: 0.434\n",
      "[epoch: 3, i:  9599] avg mini-batch loss: 0.441\n",
      "[epoch: 3, i:  9699] avg mini-batch loss: 0.426\n",
      "[epoch: 3, i:  9799] avg mini-batch loss: 0.479\n",
      "[epoch: 3, i:  9899] avg mini-batch loss: 0.369\n",
      "[epoch: 3, i:  9999] avg mini-batch loss: 0.412\n",
      "[epoch: 3, i: 10099] avg mini-batch loss: 0.545\n",
      "[epoch: 3, i: 10199] avg mini-batch loss: 0.420\n",
      "[epoch: 3, i: 10299] avg mini-batch loss: 0.513\n",
      "[epoch: 3, i: 10399] avg mini-batch loss: 0.555\n",
      "[epoch: 3, i: 10499] avg mini-batch loss: 0.430\n",
      "[epoch: 3, i: 10599] avg mini-batch loss: 0.533\n",
      "[epoch: 3, i: 10699] avg mini-batch loss: 0.515\n",
      "[epoch: 3, i: 10799] avg mini-batch loss: 0.358\n",
      "[epoch: 3, i: 10899] avg mini-batch loss: 0.456\n",
      "[epoch: 3, i: 10999] avg mini-batch loss: 0.464\n",
      "[epoch: 3, i: 11099] avg mini-batch loss: 0.458\n",
      "[epoch: 3, i: 11199] avg mini-batch loss: 0.436\n",
      "[epoch: 3, i: 11299] avg mini-batch loss: 0.469\n",
      "[epoch: 3, i: 11399] avg mini-batch loss: 0.562\n",
      "[epoch: 3, i: 11499] avg mini-batch loss: 0.492\n",
      "[epoch: 3, i: 11599] avg mini-batch loss: 0.540\n",
      "[epoch: 3, i: 11699] avg mini-batch loss: 0.519\n",
      "[epoch: 3, i: 11799] avg mini-batch loss: 0.528\n",
      "[epoch: 3, i: 11899] avg mini-batch loss: 0.471\n",
      "[epoch: 3, i: 11999] avg mini-batch loss: 0.555\n",
      "[epoch: 3, i: 12099] avg mini-batch loss: 0.387\n",
      "[epoch: 3, i: 12199] avg mini-batch loss: 0.414\n",
      "[epoch: 3, i: 12299] avg mini-batch loss: 0.549\n",
      "[epoch: 3, i: 12399] avg mini-batch loss: 0.435\n",
      "[epoch: 3, i: 12499] avg mini-batch loss: 0.477\n",
      "[epoch: 4, i:    99] avg mini-batch loss: 0.307\n",
      "[epoch: 4, i:   199] avg mini-batch loss: 0.307\n",
      "[epoch: 4, i:   299] avg mini-batch loss: 0.335\n",
      "[epoch: 4, i:   399] avg mini-batch loss: 0.368\n",
      "[epoch: 4, i:   499] avg mini-batch loss: 0.318\n",
      "[epoch: 4, i:   599] avg mini-batch loss: 0.316\n",
      "[epoch: 4, i:   699] avg mini-batch loss: 0.425\n",
      "[epoch: 4, i:   799] avg mini-batch loss: 0.318\n",
      "[epoch: 4, i:   899] avg mini-batch loss: 0.305\n",
      "[epoch: 4, i:   999] avg mini-batch loss: 0.372\n",
      "[epoch: 4, i:  1099] avg mini-batch loss: 0.344\n",
      "[epoch: 4, i:  1199] avg mini-batch loss: 0.373\n",
      "[epoch: 4, i:  1299] avg mini-batch loss: 0.339\n",
      "[epoch: 4, i:  1399] avg mini-batch loss: 0.410\n",
      "[epoch: 4, i:  1499] avg mini-batch loss: 0.409\n",
      "[epoch: 4, i:  1599] avg mini-batch loss: 0.277\n",
      "[epoch: 4, i:  1699] avg mini-batch loss: 0.289\n",
      "[epoch: 4, i:  1799] avg mini-batch loss: 0.386\n",
      "[epoch: 4, i:  1899] avg mini-batch loss: 0.309\n",
      "[epoch: 4, i:  1999] avg mini-batch loss: 0.376\n",
      "[epoch: 4, i:  2099] avg mini-batch loss: 0.382\n",
      "[epoch: 4, i:  2199] avg mini-batch loss: 0.300\n",
      "[epoch: 4, i:  2299] avg mini-batch loss: 0.349\n",
      "[epoch: 4, i:  2399] avg mini-batch loss: 0.391\n",
      "[epoch: 4, i:  2499] avg mini-batch loss: 0.333\n",
      "[epoch: 4, i:  2599] avg mini-batch loss: 0.355\n",
      "[epoch: 4, i:  2699] avg mini-batch loss: 0.331\n",
      "[epoch: 4, i:  2799] avg mini-batch loss: 0.452\n",
      "[epoch: 4, i:  2899] avg mini-batch loss: 0.342\n",
      "[epoch: 4, i:  2999] avg mini-batch loss: 0.372\n",
      "[epoch: 4, i:  3099] avg mini-batch loss: 0.406\n",
      "[epoch: 4, i:  3199] avg mini-batch loss: 0.351\n",
      "[epoch: 4, i:  3299] avg mini-batch loss: 0.342\n",
      "[epoch: 4, i:  3399] avg mini-batch loss: 0.428\n",
      "[epoch: 4, i:  3499] avg mini-batch loss: 0.329\n",
      "[epoch: 4, i:  3599] avg mini-batch loss: 0.319\n",
      "[epoch: 4, i:  3699] avg mini-batch loss: 0.338\n",
      "[epoch: 4, i:  3799] avg mini-batch loss: 0.381\n",
      "[epoch: 4, i:  3899] avg mini-batch loss: 0.380\n",
      "[epoch: 4, i:  3999] avg mini-batch loss: 0.370\n",
      "[epoch: 4, i:  4099] avg mini-batch loss: 0.324\n",
      "[epoch: 4, i:  4199] avg mini-batch loss: 0.349\n",
      "[epoch: 4, i:  4299] avg mini-batch loss: 0.316\n",
      "[epoch: 4, i:  4399] avg mini-batch loss: 0.420\n",
      "[epoch: 4, i:  4499] avg mini-batch loss: 0.336\n",
      "[epoch: 4, i:  4599] avg mini-batch loss: 0.347\n",
      "[epoch: 4, i:  4699] avg mini-batch loss: 0.308\n",
      "[epoch: 4, i:  4799] avg mini-batch loss: 0.370\n",
      "[epoch: 4, i:  4899] avg mini-batch loss: 0.339\n",
      "[epoch: 4, i:  4999] avg mini-batch loss: 0.350\n",
      "[epoch: 4, i:  5099] avg mini-batch loss: 0.462\n",
      "[epoch: 4, i:  5199] avg mini-batch loss: 0.383\n",
      "[epoch: 4, i:  5299] avg mini-batch loss: 0.323\n",
      "[epoch: 4, i:  5399] avg mini-batch loss: 0.325\n",
      "[epoch: 4, i:  5499] avg mini-batch loss: 0.312\n",
      "[epoch: 4, i:  5599] avg mini-batch loss: 0.400\n",
      "[epoch: 4, i:  5699] avg mini-batch loss: 0.373\n",
      "[epoch: 4, i:  5799] avg mini-batch loss: 0.385\n",
      "[epoch: 4, i:  5899] avg mini-batch loss: 0.347\n",
      "[epoch: 4, i:  5999] avg mini-batch loss: 0.392\n",
      "[epoch: 4, i:  6099] avg mini-batch loss: 0.336\n",
      "[epoch: 4, i:  6199] avg mini-batch loss: 0.312\n",
      "[epoch: 4, i:  6299] avg mini-batch loss: 0.440\n",
      "[epoch: 4, i:  6399] avg mini-batch loss: 0.395\n",
      "[epoch: 4, i:  6499] avg mini-batch loss: 0.326\n",
      "[epoch: 4, i:  6599] avg mini-batch loss: 0.371\n",
      "[epoch: 4, i:  6699] avg mini-batch loss: 0.325\n",
      "[epoch: 4, i:  6799] avg mini-batch loss: 0.373\n",
      "[epoch: 4, i:  6899] avg mini-batch loss: 0.375\n",
      "[epoch: 4, i:  6999] avg mini-batch loss: 0.335\n",
      "[epoch: 4, i:  7099] avg mini-batch loss: 0.276\n",
      "[epoch: 4, i:  7199] avg mini-batch loss: 0.289\n",
      "[epoch: 4, i:  7299] avg mini-batch loss: 0.290\n",
      "[epoch: 4, i:  7399] avg mini-batch loss: 0.357\n",
      "[epoch: 4, i:  7499] avg mini-batch loss: 0.365\n",
      "[epoch: 4, i:  7599] avg mini-batch loss: 0.397\n",
      "[epoch: 4, i:  7699] avg mini-batch loss: 0.389\n",
      "[epoch: 4, i:  7799] avg mini-batch loss: 0.394\n",
      "[epoch: 4, i:  7899] avg mini-batch loss: 0.357\n",
      "[epoch: 4, i:  7999] avg mini-batch loss: 0.366\n",
      "[epoch: 4, i:  8099] avg mini-batch loss: 0.341\n",
      "[epoch: 4, i:  8199] avg mini-batch loss: 0.318\n",
      "[epoch: 4, i:  8299] avg mini-batch loss: 0.282\n",
      "[epoch: 4, i:  8399] avg mini-batch loss: 0.337\n",
      "[epoch: 4, i:  8499] avg mini-batch loss: 0.429\n",
      "[epoch: 4, i:  8599] avg mini-batch loss: 0.396\n",
      "[epoch: 4, i:  8699] avg mini-batch loss: 0.387\n",
      "[epoch: 4, i:  8799] avg mini-batch loss: 0.372\n",
      "[epoch: 4, i:  8899] avg mini-batch loss: 0.373\n",
      "[epoch: 4, i:  8999] avg mini-batch loss: 0.337\n",
      "[epoch: 4, i:  9099] avg mini-batch loss: 0.329\n",
      "[epoch: 4, i:  9199] avg mini-batch loss: 0.391\n",
      "[epoch: 4, i:  9299] avg mini-batch loss: 0.318\n",
      "[epoch: 4, i:  9399] avg mini-batch loss: 0.342\n",
      "[epoch: 4, i:  9499] avg mini-batch loss: 0.296\n",
      "[epoch: 4, i:  9599] avg mini-batch loss: 0.357\n",
      "[epoch: 4, i:  9699] avg mini-batch loss: 0.370\n",
      "[epoch: 4, i:  9799] avg mini-batch loss: 0.352\n",
      "[epoch: 4, i:  9899] avg mini-batch loss: 0.395\n",
      "[epoch: 4, i:  9999] avg mini-batch loss: 0.428\n",
      "[epoch: 4, i: 10099] avg mini-batch loss: 0.347\n",
      "[epoch: 4, i: 10199] avg mini-batch loss: 0.338\n",
      "[epoch: 4, i: 10299] avg mini-batch loss: 0.337\n",
      "[epoch: 4, i: 10399] avg mini-batch loss: 0.452\n",
      "[epoch: 4, i: 10499] avg mini-batch loss: 0.304\n",
      "[epoch: 4, i: 10599] avg mini-batch loss: 0.365\n",
      "[epoch: 4, i: 10699] avg mini-batch loss: 0.380\n",
      "[epoch: 4, i: 10799] avg mini-batch loss: 0.351\n",
      "[epoch: 4, i: 10899] avg mini-batch loss: 0.335\n",
      "[epoch: 4, i: 10999] avg mini-batch loss: 0.352\n",
      "[epoch: 4, i: 11099] avg mini-batch loss: 0.352\n",
      "[epoch: 4, i: 11199] avg mini-batch loss: 0.401\n",
      "[epoch: 4, i: 11299] avg mini-batch loss: 0.432\n",
      "[epoch: 4, i: 11399] avg mini-batch loss: 0.398\n",
      "[epoch: 4, i: 11499] avg mini-batch loss: 0.431\n",
      "[epoch: 4, i: 11599] avg mini-batch loss: 0.423\n",
      "[epoch: 4, i: 11699] avg mini-batch loss: 0.339\n",
      "[epoch: 4, i: 11799] avg mini-batch loss: 0.314\n",
      "[epoch: 4, i: 11899] avg mini-batch loss: 0.415\n",
      "[epoch: 4, i: 11999] avg mini-batch loss: 0.365\n",
      "[epoch: 4, i: 12099] avg mini-batch loss: 0.406\n",
      "[epoch: 4, i: 12199] avg mini-batch loss: 0.376\n",
      "[epoch: 4, i: 12299] avg mini-batch loss: 0.355\n",
      "[epoch: 4, i: 12399] avg mini-batch loss: 0.350\n",
      "[epoch: 4, i: 12499] avg mini-batch loss: 0.422\n",
      "[epoch: 5, i:    99] avg mini-batch loss: 0.305\n",
      "[epoch: 5, i:   199] avg mini-batch loss: 0.188\n",
      "[epoch: 5, i:   299] avg mini-batch loss: 0.172\n",
      "[epoch: 5, i:   399] avg mini-batch loss: 0.195\n",
      "[epoch: 5, i:   499] avg mini-batch loss: 0.222\n",
      "[epoch: 5, i:   599] avg mini-batch loss: 0.258\n",
      "[epoch: 5, i:   699] avg mini-batch loss: 0.245\n",
      "[epoch: 5, i:   799] avg mini-batch loss: 0.220\n",
      "[epoch: 5, i:   899] avg mini-batch loss: 0.239\n",
      "[epoch: 5, i:   999] avg mini-batch loss: 0.255\n",
      "[epoch: 5, i:  1099] avg mini-batch loss: 0.216\n",
      "[epoch: 5, i:  1199] avg mini-batch loss: 0.240\n",
      "[epoch: 5, i:  1299] avg mini-batch loss: 0.185\n",
      "[epoch: 5, i:  1399] avg mini-batch loss: 0.253\n",
      "[epoch: 5, i:  1499] avg mini-batch loss: 0.192\n",
      "[epoch: 5, i:  1599] avg mini-batch loss: 0.312\n",
      "[epoch: 5, i:  1699] avg mini-batch loss: 0.287\n",
      "[epoch: 5, i:  1799] avg mini-batch loss: 0.225\n",
      "[epoch: 5, i:  1899] avg mini-batch loss: 0.217\n",
      "[epoch: 5, i:  1999] avg mini-batch loss: 0.235\n",
      "[epoch: 5, i:  2099] avg mini-batch loss: 0.255\n",
      "[epoch: 5, i:  2199] avg mini-batch loss: 0.246\n",
      "[epoch: 5, i:  2299] avg mini-batch loss: 0.189\n",
      "[epoch: 5, i:  2399] avg mini-batch loss: 0.214\n",
      "[epoch: 5, i:  2499] avg mini-batch loss: 0.231\n",
      "[epoch: 5, i:  2599] avg mini-batch loss: 0.240\n",
      "[epoch: 5, i:  2699] avg mini-batch loss: 0.271\n",
      "[epoch: 5, i:  2799] avg mini-batch loss: 0.221\n",
      "[epoch: 5, i:  2899] avg mini-batch loss: 0.248\n",
      "[epoch: 5, i:  2999] avg mini-batch loss: 0.214\n",
      "[epoch: 5, i:  3099] avg mini-batch loss: 0.231\n",
      "[epoch: 5, i:  3199] avg mini-batch loss: 0.291\n",
      "[epoch: 5, i:  3299] avg mini-batch loss: 0.234\n",
      "[epoch: 5, i:  3399] avg mini-batch loss: 0.200\n",
      "[epoch: 5, i:  3499] avg mini-batch loss: 0.289\n",
      "[epoch: 5, i:  3599] avg mini-batch loss: 0.293\n",
      "[epoch: 5, i:  3699] avg mini-batch loss: 0.242\n",
      "[epoch: 5, i:  3799] avg mini-batch loss: 0.248\n",
      "[epoch: 5, i:  3899] avg mini-batch loss: 0.235\n",
      "[epoch: 5, i:  3999] avg mini-batch loss: 0.251\n",
      "[epoch: 5, i:  4099] avg mini-batch loss: 0.243\n",
      "[epoch: 5, i:  4199] avg mini-batch loss: 0.315\n",
      "[epoch: 5, i:  4299] avg mini-batch loss: 0.275\n",
      "[epoch: 5, i:  4399] avg mini-batch loss: 0.286\n",
      "[epoch: 5, i:  4499] avg mini-batch loss: 0.227\n",
      "[epoch: 5, i:  4599] avg mini-batch loss: 0.213\n",
      "[epoch: 5, i:  4699] avg mini-batch loss: 0.277\n",
      "[epoch: 5, i:  4799] avg mini-batch loss: 0.241\n",
      "[epoch: 5, i:  4899] avg mini-batch loss: 0.249\n",
      "[epoch: 5, i:  4999] avg mini-batch loss: 0.262\n",
      "[epoch: 5, i:  5099] avg mini-batch loss: 0.221\n",
      "[epoch: 5, i:  5199] avg mini-batch loss: 0.258\n",
      "[epoch: 5, i:  5299] avg mini-batch loss: 0.236\n",
      "[epoch: 5, i:  5399] avg mini-batch loss: 0.213\n",
      "[epoch: 5, i:  5499] avg mini-batch loss: 0.293\n",
      "[epoch: 5, i:  5599] avg mini-batch loss: 0.289\n",
      "[epoch: 5, i:  5699] avg mini-batch loss: 0.302\n",
      "[epoch: 5, i:  5799] avg mini-batch loss: 0.280\n",
      "[epoch: 5, i:  5899] avg mini-batch loss: 0.283\n",
      "[epoch: 5, i:  5999] avg mini-batch loss: 0.267\n",
      "[epoch: 5, i:  6099] avg mini-batch loss: 0.360\n",
      "[epoch: 5, i:  6199] avg mini-batch loss: 0.368\n",
      "[epoch: 5, i:  6299] avg mini-batch loss: 0.300\n",
      "[epoch: 5, i:  6399] avg mini-batch loss: 0.257\n",
      "[epoch: 5, i:  6499] avg mini-batch loss: 0.296\n",
      "[epoch: 5, i:  6599] avg mini-batch loss: 0.284\n",
      "[epoch: 5, i:  6699] avg mini-batch loss: 0.260\n",
      "[epoch: 5, i:  6799] avg mini-batch loss: 0.270\n",
      "[epoch: 5, i:  6899] avg mini-batch loss: 0.251\n",
      "[epoch: 5, i:  6999] avg mini-batch loss: 0.260\n",
      "[epoch: 5, i:  7099] avg mini-batch loss: 0.226\n",
      "[epoch: 5, i:  7199] avg mini-batch loss: 0.222\n",
      "[epoch: 5, i:  7299] avg mini-batch loss: 0.303\n",
      "[epoch: 5, i:  7399] avg mini-batch loss: 0.318\n",
      "[epoch: 5, i:  7499] avg mini-batch loss: 0.238\n",
      "[epoch: 5, i:  7599] avg mini-batch loss: 0.267\n",
      "[epoch: 5, i:  7699] avg mini-batch loss: 0.306\n",
      "[epoch: 5, i:  7799] avg mini-batch loss: 0.325\n",
      "[epoch: 5, i:  7899] avg mini-batch loss: 0.226\n",
      "[epoch: 5, i:  7999] avg mini-batch loss: 0.268\n",
      "[epoch: 5, i:  8099] avg mini-batch loss: 0.235\n",
      "[epoch: 5, i:  8199] avg mini-batch loss: 0.214\n",
      "[epoch: 5, i:  8299] avg mini-batch loss: 0.217\n",
      "[epoch: 5, i:  8399] avg mini-batch loss: 0.319\n",
      "[epoch: 5, i:  8499] avg mini-batch loss: 0.338\n",
      "[epoch: 5, i:  8599] avg mini-batch loss: 0.275\n",
      "[epoch: 5, i:  8699] avg mini-batch loss: 0.315\n",
      "[epoch: 5, i:  8799] avg mini-batch loss: 0.310\n",
      "[epoch: 5, i:  8899] avg mini-batch loss: 0.216\n",
      "[epoch: 5, i:  8999] avg mini-batch loss: 0.279\n",
      "[epoch: 5, i:  9099] avg mini-batch loss: 0.270\n",
      "[epoch: 5, i:  9199] avg mini-batch loss: 0.281\n",
      "[epoch: 5, i:  9299] avg mini-batch loss: 0.364\n",
      "[epoch: 5, i:  9399] avg mini-batch loss: 0.226\n",
      "[epoch: 5, i:  9499] avg mini-batch loss: 0.274\n",
      "[epoch: 5, i:  9599] avg mini-batch loss: 0.259\n",
      "[epoch: 5, i:  9699] avg mini-batch loss: 0.377\n",
      "[epoch: 5, i:  9799] avg mini-batch loss: 0.235\n",
      "[epoch: 5, i:  9899] avg mini-batch loss: 0.288\n",
      "[epoch: 5, i:  9999] avg mini-batch loss: 0.293\n",
      "[epoch: 5, i: 10099] avg mini-batch loss: 0.319\n",
      "[epoch: 5, i: 10199] avg mini-batch loss: 0.255\n",
      "[epoch: 5, i: 10299] avg mini-batch loss: 0.237\n",
      "[epoch: 5, i: 10399] avg mini-batch loss: 0.249\n",
      "[epoch: 5, i: 10499] avg mini-batch loss: 0.237\n",
      "[epoch: 5, i: 10599] avg mini-batch loss: 0.374\n",
      "[epoch: 5, i: 10699] avg mini-batch loss: 0.340\n",
      "[epoch: 5, i: 10799] avg mini-batch loss: 0.241\n",
      "[epoch: 5, i: 10899] avg mini-batch loss: 0.247\n",
      "[epoch: 5, i: 10999] avg mini-batch loss: 0.206\n",
      "[epoch: 5, i: 11099] avg mini-batch loss: 0.257\n",
      "[epoch: 5, i: 11199] avg mini-batch loss: 0.304\n",
      "[epoch: 5, i: 11299] avg mini-batch loss: 0.324\n",
      "[epoch: 5, i: 11399] avg mini-batch loss: 0.325\n",
      "[epoch: 5, i: 11499] avg mini-batch loss: 0.299\n",
      "[epoch: 5, i: 11599] avg mini-batch loss: 0.350\n",
      "[epoch: 5, i: 11699] avg mini-batch loss: 0.281\n",
      "[epoch: 5, i: 11799] avg mini-batch loss: 0.278\n",
      "[epoch: 5, i: 11899] avg mini-batch loss: 0.251\n",
      "[epoch: 5, i: 11999] avg mini-batch loss: 0.292\n",
      "[epoch: 5, i: 12099] avg mini-batch loss: 0.298\n",
      "[epoch: 5, i: 12199] avg mini-batch loss: 0.260\n",
      "[epoch: 5, i: 12299] avg mini-batch loss: 0.298\n",
      "[epoch: 5, i: 12399] avg mini-batch loss: 0.304\n",
      "[epoch: 5, i: 12499] avg mini-batch loss: 0.325\n",
      "[epoch: 6, i:    99] avg mini-batch loss: 0.241\n",
      "[epoch: 6, i:   199] avg mini-batch loss: 0.165\n",
      "[epoch: 6, i:   299] avg mini-batch loss: 0.165\n",
      "[epoch: 6, i:   399] avg mini-batch loss: 0.177\n",
      "[epoch: 6, i:   499] avg mini-batch loss: 0.145\n",
      "[epoch: 6, i:   599] avg mini-batch loss: 0.107\n",
      "[epoch: 6, i:   699] avg mini-batch loss: 0.156\n",
      "[epoch: 6, i:   799] avg mini-batch loss: 0.129\n",
      "[epoch: 6, i:   899] avg mini-batch loss: 0.149\n",
      "[epoch: 6, i:   999] avg mini-batch loss: 0.177\n",
      "[epoch: 6, i:  1099] avg mini-batch loss: 0.132\n",
      "[epoch: 6, i:  1199] avg mini-batch loss: 0.148\n",
      "[epoch: 6, i:  1299] avg mini-batch loss: 0.140\n",
      "[epoch: 6, i:  1399] avg mini-batch loss: 0.136\n",
      "[epoch: 6, i:  1499] avg mini-batch loss: 0.140\n",
      "[epoch: 6, i:  1599] avg mini-batch loss: 0.164\n",
      "[epoch: 6, i:  1699] avg mini-batch loss: 0.115\n",
      "[epoch: 6, i:  1799] avg mini-batch loss: 0.154\n",
      "[epoch: 6, i:  1899] avg mini-batch loss: 0.182\n",
      "[epoch: 6, i:  1999] avg mini-batch loss: 0.166\n",
      "[epoch: 6, i:  2099] avg mini-batch loss: 0.114\n",
      "[epoch: 6, i:  2199] avg mini-batch loss: 0.177\n",
      "[epoch: 6, i:  2299] avg mini-batch loss: 0.167\n",
      "[epoch: 6, i:  2399] avg mini-batch loss: 0.186\n",
      "[epoch: 6, i:  2499] avg mini-batch loss: 0.188\n",
      "[epoch: 6, i:  2599] avg mini-batch loss: 0.165\n",
      "[epoch: 6, i:  2699] avg mini-batch loss: 0.206\n",
      "[epoch: 6, i:  2799] avg mini-batch loss: 0.186\n",
      "[epoch: 6, i:  2899] avg mini-batch loss: 0.185\n",
      "[epoch: 6, i:  2999] avg mini-batch loss: 0.169\n",
      "[epoch: 6, i:  3099] avg mini-batch loss: 0.165\n",
      "[epoch: 6, i:  3199] avg mini-batch loss: 0.156\n",
      "[epoch: 6, i:  3299] avg mini-batch loss: 0.152\n",
      "[epoch: 6, i:  3399] avg mini-batch loss: 0.183\n",
      "[epoch: 6, i:  3499] avg mini-batch loss: 0.146\n",
      "[epoch: 6, i:  3599] avg mini-batch loss: 0.176\n",
      "[epoch: 6, i:  3699] avg mini-batch loss: 0.177\n",
      "[epoch: 6, i:  3799] avg mini-batch loss: 0.148\n",
      "[epoch: 6, i:  3899] avg mini-batch loss: 0.147\n",
      "[epoch: 6, i:  3999] avg mini-batch loss: 0.189\n",
      "[epoch: 6, i:  4099] avg mini-batch loss: 0.170\n",
      "[epoch: 6, i:  4199] avg mini-batch loss: 0.167\n",
      "[epoch: 6, i:  4299] avg mini-batch loss: 0.161\n",
      "[epoch: 6, i:  4399] avg mini-batch loss: 0.180\n",
      "[epoch: 6, i:  4499] avg mini-batch loss: 0.250\n",
      "[epoch: 6, i:  4599] avg mini-batch loss: 0.175\n",
      "[epoch: 6, i:  4699] avg mini-batch loss: 0.231\n",
      "[epoch: 6, i:  4799] avg mini-batch loss: 0.191\n",
      "[epoch: 6, i:  4899] avg mini-batch loss: 0.195\n",
      "[epoch: 6, i:  4999] avg mini-batch loss: 0.171\n",
      "[epoch: 6, i:  5099] avg mini-batch loss: 0.153\n",
      "[epoch: 6, i:  5199] avg mini-batch loss: 0.192\n",
      "[epoch: 6, i:  5299] avg mini-batch loss: 0.215\n",
      "[epoch: 6, i:  5399] avg mini-batch loss: 0.152\n",
      "[epoch: 6, i:  5499] avg mini-batch loss: 0.184\n",
      "[epoch: 6, i:  5599] avg mini-batch loss: 0.139\n",
      "[epoch: 6, i:  5699] avg mini-batch loss: 0.144\n",
      "[epoch: 6, i:  5799] avg mini-batch loss: 0.165\n",
      "[epoch: 6, i:  5899] avg mini-batch loss: 0.160\n",
      "[epoch: 6, i:  5999] avg mini-batch loss: 0.215\n",
      "[epoch: 6, i:  6099] avg mini-batch loss: 0.191\n",
      "[epoch: 6, i:  6199] avg mini-batch loss: 0.170\n",
      "[epoch: 6, i:  6299] avg mini-batch loss: 0.199\n",
      "[epoch: 6, i:  6399] avg mini-batch loss: 0.147\n",
      "[epoch: 6, i:  6499] avg mini-batch loss: 0.203\n",
      "[epoch: 6, i:  6599] avg mini-batch loss: 0.269\n",
      "[epoch: 6, i:  6699] avg mini-batch loss: 0.188\n",
      "[epoch: 6, i:  6799] avg mini-batch loss: 0.156\n",
      "[epoch: 6, i:  6899] avg mini-batch loss: 0.181\n",
      "[epoch: 6, i:  6999] avg mini-batch loss: 0.210\n",
      "[epoch: 6, i:  7099] avg mini-batch loss: 0.168\n",
      "[epoch: 6, i:  7199] avg mini-batch loss: 0.210\n",
      "[epoch: 6, i:  7299] avg mini-batch loss: 0.156\n",
      "[epoch: 6, i:  7399] avg mini-batch loss: 0.253\n",
      "[epoch: 6, i:  7499] avg mini-batch loss: 0.166\n",
      "[epoch: 6, i:  7599] avg mini-batch loss: 0.182\n",
      "[epoch: 6, i:  7699] avg mini-batch loss: 0.166\n",
      "[epoch: 6, i:  7799] avg mini-batch loss: 0.246\n",
      "[epoch: 6, i:  7899] avg mini-batch loss: 0.193\n",
      "[epoch: 6, i:  7999] avg mini-batch loss: 0.132\n",
      "[epoch: 6, i:  8099] avg mini-batch loss: 0.265\n",
      "[epoch: 6, i:  8199] avg mini-batch loss: 0.210\n",
      "[epoch: 6, i:  8299] avg mini-batch loss: 0.225\n",
      "[epoch: 6, i:  8399] avg mini-batch loss: 0.164\n",
      "[epoch: 6, i:  8499] avg mini-batch loss: 0.225\n",
      "[epoch: 6, i:  8599] avg mini-batch loss: 0.202\n",
      "[epoch: 6, i:  8699] avg mini-batch loss: 0.219\n",
      "[epoch: 6, i:  8799] avg mini-batch loss: 0.248\n",
      "[epoch: 6, i:  8899] avg mini-batch loss: 0.212\n",
      "[epoch: 6, i:  8999] avg mini-batch loss: 0.226\n",
      "[epoch: 6, i:  9099] avg mini-batch loss: 0.204\n",
      "[epoch: 6, i:  9199] avg mini-batch loss: 0.237\n",
      "[epoch: 6, i:  9299] avg mini-batch loss: 0.202\n",
      "[epoch: 6, i:  9399] avg mini-batch loss: 0.220\n",
      "[epoch: 6, i:  9499] avg mini-batch loss: 0.196\n",
      "[epoch: 6, i:  9599] avg mini-batch loss: 0.209\n",
      "[epoch: 6, i:  9699] avg mini-batch loss: 0.228\n",
      "[epoch: 6, i:  9799] avg mini-batch loss: 0.174\n",
      "[epoch: 6, i:  9899] avg mini-batch loss: 0.231\n",
      "[epoch: 6, i:  9999] avg mini-batch loss: 0.220\n",
      "[epoch: 6, i: 10099] avg mini-batch loss: 0.204\n",
      "[epoch: 6, i: 10199] avg mini-batch loss: 0.175\n",
      "[epoch: 6, i: 10299] avg mini-batch loss: 0.259\n",
      "[epoch: 6, i: 10399] avg mini-batch loss: 0.176\n",
      "[epoch: 6, i: 10499] avg mini-batch loss: 0.241\n",
      "[epoch: 6, i: 10599] avg mini-batch loss: 0.202\n",
      "[epoch: 6, i: 10699] avg mini-batch loss: 0.227\n",
      "[epoch: 6, i: 10799] avg mini-batch loss: 0.198\n",
      "[epoch: 6, i: 10899] avg mini-batch loss: 0.197\n",
      "[epoch: 6, i: 10999] avg mini-batch loss: 0.243\n",
      "[epoch: 6, i: 11099] avg mini-batch loss: 0.260\n",
      "[epoch: 6, i: 11199] avg mini-batch loss: 0.258\n",
      "[epoch: 6, i: 11299] avg mini-batch loss: 0.185\n",
      "[epoch: 6, i: 11399] avg mini-batch loss: 0.216\n",
      "[epoch: 6, i: 11499] avg mini-batch loss: 0.224\n",
      "[epoch: 6, i: 11599] avg mini-batch loss: 0.212\n",
      "[epoch: 6, i: 11699] avg mini-batch loss: 0.195\n",
      "[epoch: 6, i: 11799] avg mini-batch loss: 0.218\n",
      "[epoch: 6, i: 11899] avg mini-batch loss: 0.227\n",
      "[epoch: 6, i: 11999] avg mini-batch loss: 0.219\n",
      "[epoch: 6, i: 12099] avg mini-batch loss: 0.225\n",
      "[epoch: 6, i: 12199] avg mini-batch loss: 0.231\n",
      "[epoch: 6, i: 12299] avg mini-batch loss: 0.237\n",
      "[epoch: 6, i: 12399] avg mini-batch loss: 0.244\n",
      "[epoch: 6, i: 12499] avg mini-batch loss: 0.230\n",
      "[epoch: 7, i:    99] avg mini-batch loss: 0.127\n",
      "[epoch: 7, i:   199] avg mini-batch loss: 0.120\n",
      "[epoch: 7, i:   299] avg mini-batch loss: 0.103\n",
      "[epoch: 7, i:   399] avg mini-batch loss: 0.121\n",
      "[epoch: 7, i:   499] avg mini-batch loss: 0.087\n",
      "[epoch: 7, i:   599] avg mini-batch loss: 0.108\n",
      "[epoch: 7, i:   699] avg mini-batch loss: 0.095\n",
      "[epoch: 7, i:   799] avg mini-batch loss: 0.112\n",
      "[epoch: 7, i:   899] avg mini-batch loss: 0.097\n",
      "[epoch: 7, i:   999] avg mini-batch loss: 0.116\n",
      "[epoch: 7, i:  1099] avg mini-batch loss: 0.092\n",
      "[epoch: 7, i:  1199] avg mini-batch loss: 0.091\n",
      "[epoch: 7, i:  1299] avg mini-batch loss: 0.105\n",
      "[epoch: 7, i:  1399] avg mini-batch loss: 0.103\n",
      "[epoch: 7, i:  1499] avg mini-batch loss: 0.102\n",
      "[epoch: 7, i:  1599] avg mini-batch loss: 0.113\n",
      "[epoch: 7, i:  1699] avg mini-batch loss: 0.084\n",
      "[epoch: 7, i:  1799] avg mini-batch loss: 0.069\n",
      "[epoch: 7, i:  1899] avg mini-batch loss: 0.103\n",
      "[epoch: 7, i:  1999] avg mini-batch loss: 0.099\n",
      "[epoch: 7, i:  2099] avg mini-batch loss: 0.106\n",
      "[epoch: 7, i:  2199] avg mini-batch loss: 0.082\n",
      "[epoch: 7, i:  2299] avg mini-batch loss: 0.106\n",
      "[epoch: 7, i:  2399] avg mini-batch loss: 0.092\n",
      "[epoch: 7, i:  2499] avg mini-batch loss: 0.081\n",
      "[epoch: 7, i:  2599] avg mini-batch loss: 0.139\n",
      "[epoch: 7, i:  2699] avg mini-batch loss: 0.133\n",
      "[epoch: 7, i:  2799] avg mini-batch loss: 0.115\n",
      "[epoch: 7, i:  2899] avg mini-batch loss: 0.099\n",
      "[epoch: 7, i:  2999] avg mini-batch loss: 0.132\n",
      "[epoch: 7, i:  3099] avg mini-batch loss: 0.128\n",
      "[epoch: 7, i:  3199] avg mini-batch loss: 0.117\n",
      "[epoch: 7, i:  3299] avg mini-batch loss: 0.147\n",
      "[epoch: 7, i:  3399] avg mini-batch loss: 0.138\n",
      "[epoch: 7, i:  3499] avg mini-batch loss: 0.204\n",
      "[epoch: 7, i:  3599] avg mini-batch loss: 0.128\n",
      "[epoch: 7, i:  3699] avg mini-batch loss: 0.146\n",
      "[epoch: 7, i:  3799] avg mini-batch loss: 0.162\n",
      "[epoch: 7, i:  3899] avg mini-batch loss: 0.141\n",
      "[epoch: 7, i:  3999] avg mini-batch loss: 0.128\n",
      "[epoch: 7, i:  4099] avg mini-batch loss: 0.115\n",
      "[epoch: 7, i:  4199] avg mini-batch loss: 0.096\n",
      "[epoch: 7, i:  4299] avg mini-batch loss: 0.167\n",
      "[epoch: 7, i:  4399] avg mini-batch loss: 0.134\n",
      "[epoch: 7, i:  4499] avg mini-batch loss: 0.125\n",
      "[epoch: 7, i:  4599] avg mini-batch loss: 0.110\n",
      "[epoch: 7, i:  4699] avg mini-batch loss: 0.101\n",
      "[epoch: 7, i:  4799] avg mini-batch loss: 0.107\n",
      "[epoch: 7, i:  4899] avg mini-batch loss: 0.164\n",
      "[epoch: 7, i:  4999] avg mini-batch loss: 0.068\n",
      "[epoch: 7, i:  5099] avg mini-batch loss: 0.098\n",
      "[epoch: 7, i:  5199] avg mini-batch loss: 0.123\n",
      "[epoch: 7, i:  5299] avg mini-batch loss: 0.109\n",
      "[epoch: 7, i:  5399] avg mini-batch loss: 0.146\n",
      "[epoch: 7, i:  5499] avg mini-batch loss: 0.156\n",
      "[epoch: 7, i:  5599] avg mini-batch loss: 0.105\n",
      "[epoch: 7, i:  5699] avg mini-batch loss: 0.120\n",
      "[epoch: 7, i:  5799] avg mini-batch loss: 0.088\n",
      "[epoch: 7, i:  5899] avg mini-batch loss: 0.192\n",
      "[epoch: 7, i:  5999] avg mini-batch loss: 0.159\n",
      "[epoch: 7, i:  6099] avg mini-batch loss: 0.158\n",
      "[epoch: 7, i:  6199] avg mini-batch loss: 0.138\n",
      "[epoch: 7, i:  6299] avg mini-batch loss: 0.147\n",
      "[epoch: 7, i:  6399] avg mini-batch loss: 0.181\n",
      "[epoch: 7, i:  6499] avg mini-batch loss: 0.130\n",
      "[epoch: 7, i:  6599] avg mini-batch loss: 0.136\n",
      "[epoch: 7, i:  6699] avg mini-batch loss: 0.134\n",
      "[epoch: 7, i:  6799] avg mini-batch loss: 0.088\n",
      "[epoch: 7, i:  6899] avg mini-batch loss: 0.144\n",
      "[epoch: 7, i:  6999] avg mini-batch loss: 0.171\n",
      "[epoch: 7, i:  7099] avg mini-batch loss: 0.141\n",
      "[epoch: 7, i:  7199] avg mini-batch loss: 0.126\n",
      "[epoch: 7, i:  7299] avg mini-batch loss: 0.194\n",
      "[epoch: 7, i:  7399] avg mini-batch loss: 0.106\n",
      "[epoch: 7, i:  7499] avg mini-batch loss: 0.191\n",
      "[epoch: 7, i:  7599] avg mini-batch loss: 0.131\n",
      "[epoch: 7, i:  7699] avg mini-batch loss: 0.110\n",
      "[epoch: 7, i:  7799] avg mini-batch loss: 0.162\n",
      "[epoch: 7, i:  7899] avg mini-batch loss: 0.123\n",
      "[epoch: 7, i:  7999] avg mini-batch loss: 0.147\n",
      "[epoch: 7, i:  8099] avg mini-batch loss: 0.175\n",
      "[epoch: 7, i:  8199] avg mini-batch loss: 0.174\n",
      "[epoch: 7, i:  8299] avg mini-batch loss: 0.152\n",
      "[epoch: 7, i:  8399] avg mini-batch loss: 0.113\n",
      "[epoch: 7, i:  8499] avg mini-batch loss: 0.152\n",
      "[epoch: 7, i:  8599] avg mini-batch loss: 0.124\n",
      "[epoch: 7, i:  8699] avg mini-batch loss: 0.132\n",
      "[epoch: 7, i:  8799] avg mini-batch loss: 0.138\n",
      "[epoch: 7, i:  8899] avg mini-batch loss: 0.157\n",
      "[epoch: 7, i:  8999] avg mini-batch loss: 0.113\n",
      "[epoch: 7, i:  9099] avg mini-batch loss: 0.110\n",
      "[epoch: 7, i:  9199] avg mini-batch loss: 0.148\n",
      "[epoch: 7, i:  9299] avg mini-batch loss: 0.164\n",
      "[epoch: 7, i:  9399] avg mini-batch loss: 0.169\n",
      "[epoch: 7, i:  9499] avg mini-batch loss: 0.160\n",
      "[epoch: 7, i:  9599] avg mini-batch loss: 0.148\n",
      "[epoch: 7, i:  9699] avg mini-batch loss: 0.133\n",
      "[epoch: 7, i:  9799] avg mini-batch loss: 0.126\n",
      "[epoch: 7, i:  9899] avg mini-batch loss: 0.096\n",
      "[epoch: 7, i:  9999] avg mini-batch loss: 0.165\n",
      "[epoch: 7, i: 10099] avg mini-batch loss: 0.160\n",
      "[epoch: 7, i: 10199] avg mini-batch loss: 0.149\n",
      "[epoch: 7, i: 10299] avg mini-batch loss: 0.160\n",
      "[epoch: 7, i: 10399] avg mini-batch loss: 0.186\n",
      "[epoch: 7, i: 10499] avg mini-batch loss: 0.169\n",
      "[epoch: 7, i: 10599] avg mini-batch loss: 0.190\n",
      "[epoch: 7, i: 10699] avg mini-batch loss: 0.131\n",
      "[epoch: 7, i: 10799] avg mini-batch loss: 0.211\n",
      "[epoch: 7, i: 10899] avg mini-batch loss: 0.147\n",
      "[epoch: 7, i: 10999] avg mini-batch loss: 0.119\n",
      "[epoch: 7, i: 11099] avg mini-batch loss: 0.130\n",
      "[epoch: 7, i: 11199] avg mini-batch loss: 0.194\n",
      "[epoch: 7, i: 11299] avg mini-batch loss: 0.138\n",
      "[epoch: 7, i: 11399] avg mini-batch loss: 0.122\n",
      "[epoch: 7, i: 11499] avg mini-batch loss: 0.163\n",
      "[epoch: 7, i: 11599] avg mini-batch loss: 0.166\n",
      "[epoch: 7, i: 11699] avg mini-batch loss: 0.149\n",
      "[epoch: 7, i: 11799] avg mini-batch loss: 0.168\n",
      "[epoch: 7, i: 11899] avg mini-batch loss: 0.126\n",
      "[epoch: 7, i: 11999] avg mini-batch loss: 0.140\n",
      "[epoch: 7, i: 12099] avg mini-batch loss: 0.112\n",
      "[epoch: 7, i: 12199] avg mini-batch loss: 0.189\n",
      "[epoch: 7, i: 12299] avg mini-batch loss: 0.127\n",
      "[epoch: 7, i: 12399] avg mini-batch loss: 0.131\n",
      "[epoch: 7, i: 12499] avg mini-batch loss: 0.168\n",
      "[epoch: 8, i:    99] avg mini-batch loss: 0.072\n",
      "[epoch: 8, i:   199] avg mini-batch loss: 0.068\n",
      "[epoch: 8, i:   299] avg mini-batch loss: 0.084\n",
      "[epoch: 8, i:   399] avg mini-batch loss: 0.048\n",
      "[epoch: 8, i:   499] avg mini-batch loss: 0.065\n",
      "[epoch: 8, i:   599] avg mini-batch loss: 0.058\n",
      "[epoch: 8, i:   699] avg mini-batch loss: 0.087\n",
      "[epoch: 8, i:   799] avg mini-batch loss: 0.085\n",
      "[epoch: 8, i:   899] avg mini-batch loss: 0.070\n",
      "[epoch: 8, i:   999] avg mini-batch loss: 0.101\n",
      "[epoch: 8, i:  1099] avg mini-batch loss: 0.070\n",
      "[epoch: 8, i:  1199] avg mini-batch loss: 0.068\n",
      "[epoch: 8, i:  1299] avg mini-batch loss: 0.074\n",
      "[epoch: 8, i:  1399] avg mini-batch loss: 0.045\n",
      "[epoch: 8, i:  1499] avg mini-batch loss: 0.079\n",
      "[epoch: 8, i:  1599] avg mini-batch loss: 0.055\n",
      "[epoch: 8, i:  1699] avg mini-batch loss: 0.065\n",
      "[epoch: 8, i:  1799] avg mini-batch loss: 0.092\n",
      "[epoch: 8, i:  1899] avg mini-batch loss: 0.083\n",
      "[epoch: 8, i:  1999] avg mini-batch loss: 0.081\n",
      "[epoch: 8, i:  2099] avg mini-batch loss: 0.078\n",
      "[epoch: 8, i:  2199] avg mini-batch loss: 0.071\n",
      "[epoch: 8, i:  2299] avg mini-batch loss: 0.051\n",
      "[epoch: 8, i:  2399] avg mini-batch loss: 0.061\n",
      "[epoch: 8, i:  2499] avg mini-batch loss: 0.072\n",
      "[epoch: 8, i:  2599] avg mini-batch loss: 0.072\n",
      "[epoch: 8, i:  2699] avg mini-batch loss: 0.074\n",
      "[epoch: 8, i:  2799] avg mini-batch loss: 0.050\n",
      "[epoch: 8, i:  2899] avg mini-batch loss: 0.062\n",
      "[epoch: 8, i:  2999] avg mini-batch loss: 0.075\n",
      "[epoch: 8, i:  3099] avg mini-batch loss: 0.073\n",
      "[epoch: 8, i:  3199] avg mini-batch loss: 0.088\n",
      "[epoch: 8, i:  3299] avg mini-batch loss: 0.078\n",
      "[epoch: 8, i:  3399] avg mini-batch loss: 0.067\n",
      "[epoch: 8, i:  3499] avg mini-batch loss: 0.109\n",
      "[epoch: 8, i:  3599] avg mini-batch loss: 0.130\n",
      "[epoch: 8, i:  3699] avg mini-batch loss: 0.106\n",
      "[epoch: 8, i:  3799] avg mini-batch loss: 0.119\n",
      "[epoch: 8, i:  3899] avg mini-batch loss: 0.109\n",
      "[epoch: 8, i:  3999] avg mini-batch loss: 0.069\n",
      "[epoch: 8, i:  4099] avg mini-batch loss: 0.108\n",
      "[epoch: 8, i:  4199] avg mini-batch loss: 0.107\n",
      "[epoch: 8, i:  4299] avg mini-batch loss: 0.121\n",
      "[epoch: 8, i:  4399] avg mini-batch loss: 0.146\n",
      "[epoch: 8, i:  4499] avg mini-batch loss: 0.085\n",
      "[epoch: 8, i:  4599] avg mini-batch loss: 0.094\n",
      "[epoch: 8, i:  4699] avg mini-batch loss: 0.100\n",
      "[epoch: 8, i:  4799] avg mini-batch loss: 0.072\n",
      "[epoch: 8, i:  4899] avg mini-batch loss: 0.140\n",
      "[epoch: 8, i:  4999] avg mini-batch loss: 0.085\n",
      "[epoch: 8, i:  5099] avg mini-batch loss: 0.084\n",
      "[epoch: 8, i:  5199] avg mini-batch loss: 0.076\n",
      "[epoch: 8, i:  5299] avg mini-batch loss: 0.096\n",
      "[epoch: 8, i:  5399] avg mini-batch loss: 0.094\n",
      "[epoch: 8, i:  5499] avg mini-batch loss: 0.069\n",
      "[epoch: 8, i:  5599] avg mini-batch loss: 0.090\n",
      "[epoch: 8, i:  5699] avg mini-batch loss: 0.122\n",
      "[epoch: 8, i:  5799] avg mini-batch loss: 0.088\n",
      "[epoch: 8, i:  5899] avg mini-batch loss: 0.083\n",
      "[epoch: 8, i:  5999] avg mini-batch loss: 0.081\n",
      "[epoch: 8, i:  6099] avg mini-batch loss: 0.103\n",
      "[epoch: 8, i:  6199] avg mini-batch loss: 0.087\n",
      "[epoch: 8, i:  6299] avg mini-batch loss: 0.106\n",
      "[epoch: 8, i:  6399] avg mini-batch loss: 0.108\n",
      "[epoch: 8, i:  6499] avg mini-batch loss: 0.097\n",
      "[epoch: 8, i:  6599] avg mini-batch loss: 0.096\n",
      "[epoch: 8, i:  6699] avg mini-batch loss: 0.103\n",
      "[epoch: 8, i:  6799] avg mini-batch loss: 0.093\n",
      "[epoch: 8, i:  6899] avg mini-batch loss: 0.093\n",
      "[epoch: 8, i:  6999] avg mini-batch loss: 0.135\n",
      "[epoch: 8, i:  7099] avg mini-batch loss: 0.092\n",
      "[epoch: 8, i:  7199] avg mini-batch loss: 0.103\n",
      "[epoch: 8, i:  7299] avg mini-batch loss: 0.129\n",
      "[epoch: 8, i:  7399] avg mini-batch loss: 0.094\n",
      "[epoch: 8, i:  7499] avg mini-batch loss: 0.126\n",
      "[epoch: 8, i:  7599] avg mini-batch loss: 0.094\n",
      "[epoch: 8, i:  7699] avg mini-batch loss: 0.107\n",
      "[epoch: 8, i:  7799] avg mini-batch loss: 0.083\n",
      "[epoch: 8, i:  7899] avg mini-batch loss: 0.085\n",
      "[epoch: 8, i:  7999] avg mini-batch loss: 0.107\n",
      "[epoch: 8, i:  8099] avg mini-batch loss: 0.132\n",
      "[epoch: 8, i:  8199] avg mini-batch loss: 0.093\n",
      "[epoch: 8, i:  8299] avg mini-batch loss: 0.097\n",
      "[epoch: 8, i:  8399] avg mini-batch loss: 0.094\n",
      "[epoch: 8, i:  8499] avg mini-batch loss: 0.147\n",
      "[epoch: 8, i:  8599] avg mini-batch loss: 0.112\n",
      "[epoch: 8, i:  8699] avg mini-batch loss: 0.077\n",
      "[epoch: 8, i:  8799] avg mini-batch loss: 0.092\n",
      "[epoch: 8, i:  8899] avg mini-batch loss: 0.145\n",
      "[epoch: 8, i:  8999] avg mini-batch loss: 0.112\n",
      "[epoch: 8, i:  9099] avg mini-batch loss: 0.077\n",
      "[epoch: 8, i:  9199] avg mini-batch loss: 0.106\n",
      "[epoch: 8, i:  9299] avg mini-batch loss: 0.130\n",
      "[epoch: 8, i:  9399] avg mini-batch loss: 0.091\n",
      "[epoch: 8, i:  9499] avg mini-batch loss: 0.107\n",
      "[epoch: 8, i:  9599] avg mini-batch loss: 0.065\n",
      "[epoch: 8, i:  9699] avg mini-batch loss: 0.089\n",
      "[epoch: 8, i:  9799] avg mini-batch loss: 0.074\n",
      "[epoch: 8, i:  9899] avg mini-batch loss: 0.061\n",
      "[epoch: 8, i:  9999] avg mini-batch loss: 0.071\n",
      "[epoch: 8, i: 10099] avg mini-batch loss: 0.102\n",
      "[epoch: 8, i: 10199] avg mini-batch loss: 0.102\n",
      "[epoch: 8, i: 10299] avg mini-batch loss: 0.097\n",
      "[epoch: 8, i: 10399] avg mini-batch loss: 0.069\n",
      "[epoch: 8, i: 10499] avg mini-batch loss: 0.073\n",
      "[epoch: 8, i: 10599] avg mini-batch loss: 0.074\n",
      "[epoch: 8, i: 10699] avg mini-batch loss: 0.047\n",
      "[epoch: 8, i: 10799] avg mini-batch loss: 0.062\n",
      "[epoch: 8, i: 10899] avg mini-batch loss: 0.077\n",
      "[epoch: 8, i: 10999] avg mini-batch loss: 0.100\n",
      "[epoch: 8, i: 11099] avg mini-batch loss: 0.118\n",
      "[epoch: 8, i: 11199] avg mini-batch loss: 0.084\n",
      "[epoch: 8, i: 11299] avg mini-batch loss: 0.111\n",
      "[epoch: 8, i: 11399] avg mini-batch loss: 0.104\n",
      "[epoch: 8, i: 11499] avg mini-batch loss: 0.173\n",
      "[epoch: 8, i: 11599] avg mini-batch loss: 0.091\n",
      "[epoch: 8, i: 11699] avg mini-batch loss: 0.137\n",
      "[epoch: 8, i: 11799] avg mini-batch loss: 0.128\n",
      "[epoch: 8, i: 11899] avg mini-batch loss: 0.168\n",
      "[epoch: 8, i: 11999] avg mini-batch loss: 0.129\n",
      "[epoch: 8, i: 12099] avg mini-batch loss: 0.161\n",
      "[epoch: 8, i: 12199] avg mini-batch loss: 0.106\n",
      "[epoch: 8, i: 12299] avg mini-batch loss: 0.135\n",
      "[epoch: 8, i: 12399] avg mini-batch loss: 0.124\n",
      "[epoch: 8, i: 12499] avg mini-batch loss: 0.109\n",
      "[epoch: 9, i:    99] avg mini-batch loss: 0.061\n",
      "[epoch: 9, i:   199] avg mini-batch loss: 0.057\n",
      "[epoch: 9, i:   299] avg mini-batch loss: 0.081\n",
      "[epoch: 9, i:   399] avg mini-batch loss: 0.051\n",
      "[epoch: 9, i:   499] avg mini-batch loss: 0.048\n",
      "[epoch: 9, i:   599] avg mini-batch loss: 0.037\n",
      "[epoch: 9, i:   699] avg mini-batch loss: 0.075\n",
      "[epoch: 9, i:   799] avg mini-batch loss: 0.048\n",
      "[epoch: 9, i:   899] avg mini-batch loss: 0.076\n",
      "[epoch: 9, i:   999] avg mini-batch loss: 0.064\n",
      "[epoch: 9, i:  1099] avg mini-batch loss: 0.049\n",
      "[epoch: 9, i:  1199] avg mini-batch loss: 0.046\n",
      "[epoch: 9, i:  1299] avg mini-batch loss: 0.030\n",
      "[epoch: 9, i:  1399] avg mini-batch loss: 0.052\n",
      "[epoch: 9, i:  1499] avg mini-batch loss: 0.102\n",
      "[epoch: 9, i:  1599] avg mini-batch loss: 0.060\n",
      "[epoch: 9, i:  1699] avg mini-batch loss: 0.086\n",
      "[epoch: 9, i:  1799] avg mini-batch loss: 0.050\n",
      "[epoch: 9, i:  1899] avg mini-batch loss: 0.067\n",
      "[epoch: 9, i:  1999] avg mini-batch loss: 0.087\n",
      "[epoch: 9, i:  2099] avg mini-batch loss: 0.039\n",
      "[epoch: 9, i:  2199] avg mini-batch loss: 0.040\n",
      "[epoch: 9, i:  2299] avg mini-batch loss: 0.054\n",
      "[epoch: 9, i:  2399] avg mini-batch loss: 0.072\n",
      "[epoch: 9, i:  2499] avg mini-batch loss: 0.086\n",
      "[epoch: 9, i:  2599] avg mini-batch loss: 0.043\n",
      "[epoch: 9, i:  2699] avg mini-batch loss: 0.067\n",
      "[epoch: 9, i:  2799] avg mini-batch loss: 0.051\n",
      "[epoch: 9, i:  2899] avg mini-batch loss: 0.041\n",
      "[epoch: 9, i:  2999] avg mini-batch loss: 0.044\n",
      "[epoch: 9, i:  3099] avg mini-batch loss: 0.039\n",
      "[epoch: 9, i:  3199] avg mini-batch loss: 0.039\n",
      "[epoch: 9, i:  3299] avg mini-batch loss: 0.064\n",
      "[epoch: 9, i:  3399] avg mini-batch loss: 0.076\n",
      "[epoch: 9, i:  3499] avg mini-batch loss: 0.061\n",
      "[epoch: 9, i:  3599] avg mini-batch loss: 0.061\n",
      "[epoch: 9, i:  3699] avg mini-batch loss: 0.079\n",
      "[epoch: 9, i:  3799] avg mini-batch loss: 0.047\n",
      "[epoch: 9, i:  3899] avg mini-batch loss: 0.041\n",
      "[epoch: 9, i:  3999] avg mini-batch loss: 0.072\n",
      "[epoch: 9, i:  4099] avg mini-batch loss: 0.066\n",
      "[epoch: 9, i:  4199] avg mini-batch loss: 0.043\n",
      "[epoch: 9, i:  4299] avg mini-batch loss: 0.055\n",
      "[epoch: 9, i:  4399] avg mini-batch loss: 0.048\n",
      "[epoch: 9, i:  4499] avg mini-batch loss: 0.062\n",
      "[epoch: 9, i:  4599] avg mini-batch loss: 0.078\n",
      "[epoch: 9, i:  4699] avg mini-batch loss: 0.055\n",
      "[epoch: 9, i:  4799] avg mini-batch loss: 0.057\n",
      "[epoch: 9, i:  4899] avg mini-batch loss: 0.039\n",
      "[epoch: 9, i:  4999] avg mini-batch loss: 0.074\n",
      "[epoch: 9, i:  5099] avg mini-batch loss: 0.054\n",
      "[epoch: 9, i:  5199] avg mini-batch loss: 0.048\n",
      "[epoch: 9, i:  5299] avg mini-batch loss: 0.062\n",
      "[epoch: 9, i:  5399] avg mini-batch loss: 0.053\n",
      "[epoch: 9, i:  5499] avg mini-batch loss: 0.058\n",
      "[epoch: 9, i:  5599] avg mini-batch loss: 0.072\n",
      "[epoch: 9, i:  5699] avg mini-batch loss: 0.063\n",
      "[epoch: 9, i:  5799] avg mini-batch loss: 0.067\n",
      "[epoch: 9, i:  5899] avg mini-batch loss: 0.058\n",
      "[epoch: 9, i:  5999] avg mini-batch loss: 0.068\n",
      "[epoch: 9, i:  6099] avg mini-batch loss: 0.040\n",
      "[epoch: 9, i:  6199] avg mini-batch loss: 0.051\n",
      "[epoch: 9, i:  6299] avg mini-batch loss: 0.069\n",
      "[epoch: 9, i:  6399] avg mini-batch loss: 0.059\n",
      "[epoch: 9, i:  6499] avg mini-batch loss: 0.075\n",
      "[epoch: 9, i:  6599] avg mini-batch loss: 0.102\n",
      "[epoch: 9, i:  6699] avg mini-batch loss: 0.092\n",
      "[epoch: 9, i:  6799] avg mini-batch loss: 0.071\n",
      "[epoch: 9, i:  6899] avg mini-batch loss: 0.088\n",
      "[epoch: 9, i:  6999] avg mini-batch loss: 0.083\n",
      "[epoch: 9, i:  7099] avg mini-batch loss: 0.070\n",
      "[epoch: 9, i:  7199] avg mini-batch loss: 0.070\n",
      "[epoch: 9, i:  7299] avg mini-batch loss: 0.035\n",
      "[epoch: 9, i:  7399] avg mini-batch loss: 0.044\n",
      "[epoch: 9, i:  7499] avg mini-batch loss: 0.066\n",
      "[epoch: 9, i:  7599] avg mini-batch loss: 0.046\n",
      "[epoch: 9, i:  7699] avg mini-batch loss: 0.061\n",
      "[epoch: 9, i:  7799] avg mini-batch loss: 0.039\n",
      "[epoch: 9, i:  7899] avg mini-batch loss: 0.051\n",
      "[epoch: 9, i:  7999] avg mini-batch loss: 0.093\n",
      "[epoch: 9, i:  8099] avg mini-batch loss: 0.061\n",
      "[epoch: 9, i:  8199] avg mini-batch loss: 0.072\n",
      "[epoch: 9, i:  8299] avg mini-batch loss: 0.059\n",
      "[epoch: 9, i:  8399] avg mini-batch loss: 0.075\n",
      "[epoch: 9, i:  8499] avg mini-batch loss: 0.046\n",
      "[epoch: 9, i:  8599] avg mini-batch loss: 0.044\n",
      "[epoch: 9, i:  8699] avg mini-batch loss: 0.054\n",
      "[epoch: 9, i:  8799] avg mini-batch loss: 0.059\n",
      "[epoch: 9, i:  8899] avg mini-batch loss: 0.058\n",
      "[epoch: 9, i:  8999] avg mini-batch loss: 0.047\n",
      "[epoch: 9, i:  9099] avg mini-batch loss: 0.030\n",
      "[epoch: 9, i:  9199] avg mini-batch loss: 0.074\n",
      "[epoch: 9, i:  9299] avg mini-batch loss: 0.045\n",
      "[epoch: 9, i:  9399] avg mini-batch loss: 0.101\n",
      "[epoch: 9, i:  9499] avg mini-batch loss: 0.061\n",
      "[epoch: 9, i:  9599] avg mini-batch loss: 0.071\n",
      "[epoch: 9, i:  9699] avg mini-batch loss: 0.055\n",
      "[epoch: 9, i:  9799] avg mini-batch loss: 0.053\n",
      "[epoch: 9, i:  9899] avg mini-batch loss: 0.099\n",
      "[epoch: 9, i:  9999] avg mini-batch loss: 0.060\n",
      "[epoch: 9, i: 10099] avg mini-batch loss: 0.070\n",
      "[epoch: 9, i: 10199] avg mini-batch loss: 0.044\n",
      "[epoch: 9, i: 10299] avg mini-batch loss: 0.098\n",
      "[epoch: 9, i: 10399] avg mini-batch loss: 0.121\n",
      "[epoch: 9, i: 10499] avg mini-batch loss: 0.074\n",
      "[epoch: 9, i: 10599] avg mini-batch loss: 0.124\n",
      "[epoch: 9, i: 10699] avg mini-batch loss: 0.082\n",
      "[epoch: 9, i: 10799] avg mini-batch loss: 0.072\n",
      "[epoch: 9, i: 10899] avg mini-batch loss: 0.059\n",
      "[epoch: 9, i: 10999] avg mini-batch loss: 0.089\n",
      "[epoch: 9, i: 11099] avg mini-batch loss: 0.061\n",
      "[epoch: 9, i: 11199] avg mini-batch loss: 0.098\n",
      "[epoch: 9, i: 11299] avg mini-batch loss: 0.082\n",
      "[epoch: 9, i: 11399] avg mini-batch loss: 0.070\n",
      "[epoch: 9, i: 11499] avg mini-batch loss: 0.049\n",
      "[epoch: 9, i: 11599] avg mini-batch loss: 0.080\n",
      "[epoch: 9, i: 11699] avg mini-batch loss: 0.086\n",
      "[epoch: 9, i: 11799] avg mini-batch loss: 0.072\n",
      "[epoch: 9, i: 11899] avg mini-batch loss: 0.089\n",
      "[epoch: 9, i: 11999] avg mini-batch loss: 0.072\n",
      "[epoch: 9, i: 12099] avg mini-batch loss: 0.076\n",
      "[epoch: 9, i: 12199] avg mini-batch loss: 0.053\n",
      "[epoch: 9, i: 12299] avg mini-batch loss: 0.064\n",
      "[epoch: 9, i: 12399] avg mini-batch loss: 0.086\n",
      "[epoch: 9, i: 12499] avg mini-batch loss: 0.093\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = []   # Avg. losses.\n",
    "epochs = 10       # Total epochs.\n",
    "print_freq = 100  # Print frequency.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_loss = 0.0       # Initialize running loss.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step.\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # Print statistics.\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n",
    "                epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 80 %\n"
     ]
    }
   ],
   "source": [
    "# Get test accuracy.\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
