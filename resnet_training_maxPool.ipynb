{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.max_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "net = ResNet18()     # Create the network instance.\n",
    "net.to(device)  # Move the network parameters to the specified device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "# We use stochastic gradient descent (SGD) as optimizer.\n",
    "opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:    99] avg mini-batch loss: 5.861\n",
      "[epoch: 0, i:   199] avg mini-batch loss: 3.319\n",
      "[epoch: 0, i:   299] avg mini-batch loss: 2.731\n",
      "[epoch: 0, i:   399] avg mini-batch loss: 2.666\n",
      "[epoch: 0, i:   499] avg mini-batch loss: 2.668\n",
      "[epoch: 0, i:   599] avg mini-batch loss: 2.564\n",
      "[epoch: 0, i:   699] avg mini-batch loss: 2.463\n",
      "[epoch: 0, i:   799] avg mini-batch loss: 2.356\n",
      "[epoch: 0, i:   899] avg mini-batch loss: 2.331\n",
      "[epoch: 0, i:   999] avg mini-batch loss: 2.317\n",
      "[epoch: 0, i:  1099] avg mini-batch loss: 2.387\n",
      "[epoch: 0, i:  1199] avg mini-batch loss: 2.338\n",
      "[epoch: 0, i:  1299] avg mini-batch loss: 2.257\n",
      "[epoch: 0, i:  1399] avg mini-batch loss: 2.238\n",
      "[epoch: 0, i:  1499] avg mini-batch loss: 2.236\n",
      "[epoch: 0, i:  1599] avg mini-batch loss: 2.261\n",
      "[epoch: 0, i:  1699] avg mini-batch loss: 2.307\n",
      "[epoch: 0, i:  1799] avg mini-batch loss: 2.089\n",
      "[epoch: 0, i:  1899] avg mini-batch loss: 2.145\n",
      "[epoch: 0, i:  1999] avg mini-batch loss: 2.191\n",
      "[epoch: 0, i:  2099] avg mini-batch loss: 2.197\n",
      "[epoch: 0, i:  2199] avg mini-batch loss: 2.043\n",
      "[epoch: 0, i:  2299] avg mini-batch loss: 2.271\n",
      "[epoch: 0, i:  2399] avg mini-batch loss: 2.169\n",
      "[epoch: 0, i:  2499] avg mini-batch loss: 2.090\n",
      "[epoch: 0, i:  2599] avg mini-batch loss: 2.073\n",
      "[epoch: 0, i:  2699] avg mini-batch loss: 2.032\n",
      "[epoch: 0, i:  2799] avg mini-batch loss: 2.077\n",
      "[epoch: 0, i:  2899] avg mini-batch loss: 2.001\n",
      "[epoch: 0, i:  2999] avg mini-batch loss: 2.076\n",
      "[epoch: 0, i:  3099] avg mini-batch loss: 2.106\n",
      "[epoch: 0, i:  3199] avg mini-batch loss: 1.960\n",
      "[epoch: 0, i:  3299] avg mini-batch loss: 1.970\n",
      "[epoch: 0, i:  3399] avg mini-batch loss: 2.044\n",
      "[epoch: 0, i:  3499] avg mini-batch loss: 2.060\n",
      "[epoch: 0, i:  3599] avg mini-batch loss: 1.933\n",
      "[epoch: 0, i:  3699] avg mini-batch loss: 2.031\n",
      "[epoch: 0, i:  3799] avg mini-batch loss: 1.999\n",
      "[epoch: 0, i:  3899] avg mini-batch loss: 1.878\n",
      "[epoch: 0, i:  3999] avg mini-batch loss: 1.966\n",
      "[epoch: 0, i:  4099] avg mini-batch loss: 1.916\n",
      "[epoch: 0, i:  4199] avg mini-batch loss: 1.944\n",
      "[epoch: 0, i:  4299] avg mini-batch loss: 1.815\n",
      "[epoch: 0, i:  4399] avg mini-batch loss: 1.853\n",
      "[epoch: 0, i:  4499] avg mini-batch loss: 2.042\n",
      "[epoch: 0, i:  4599] avg mini-batch loss: 1.842\n",
      "[epoch: 0, i:  4699] avg mini-batch loss: 1.880\n",
      "[epoch: 0, i:  4799] avg mini-batch loss: 1.909\n",
      "[epoch: 0, i:  4899] avg mini-batch loss: 1.851\n",
      "[epoch: 0, i:  4999] avg mini-batch loss: 1.896\n",
      "[epoch: 0, i:  5099] avg mini-batch loss: 1.911\n",
      "[epoch: 0, i:  5199] avg mini-batch loss: 1.836\n",
      "[epoch: 0, i:  5299] avg mini-batch loss: 1.837\n",
      "[epoch: 0, i:  5399] avg mini-batch loss: 1.833\n",
      "[epoch: 0, i:  5499] avg mini-batch loss: 1.754\n",
      "[epoch: 0, i:  5599] avg mini-batch loss: 1.889\n",
      "[epoch: 0, i:  5699] avg mini-batch loss: 1.838\n",
      "[epoch: 0, i:  5799] avg mini-batch loss: 1.851\n",
      "[epoch: 0, i:  5899] avg mini-batch loss: 1.822\n",
      "[epoch: 0, i:  5999] avg mini-batch loss: 1.812\n",
      "[epoch: 0, i:  6099] avg mini-batch loss: 1.797\n",
      "[epoch: 0, i:  6199] avg mini-batch loss: 1.791\n",
      "[epoch: 0, i:  6299] avg mini-batch loss: 1.791\n",
      "[epoch: 0, i:  6399] avg mini-batch loss: 1.797\n",
      "[epoch: 0, i:  6499] avg mini-batch loss: 1.710\n",
      "[epoch: 0, i:  6599] avg mini-batch loss: 1.775\n",
      "[epoch: 0, i:  6699] avg mini-batch loss: 1.761\n",
      "[epoch: 0, i:  6799] avg mini-batch loss: 1.791\n",
      "[epoch: 0, i:  6899] avg mini-batch loss: 1.739\n",
      "[epoch: 0, i:  6999] avg mini-batch loss: 1.763\n",
      "[epoch: 0, i:  7099] avg mini-batch loss: 1.697\n",
      "[epoch: 0, i:  7199] avg mini-batch loss: 1.726\n",
      "[epoch: 0, i:  7299] avg mini-batch loss: 1.812\n",
      "[epoch: 0, i:  7399] avg mini-batch loss: 1.749\n",
      "[epoch: 0, i:  7499] avg mini-batch loss: 1.741\n",
      "[epoch: 0, i:  7599] avg mini-batch loss: 1.679\n",
      "[epoch: 0, i:  7699] avg mini-batch loss: 1.654\n",
      "[epoch: 0, i:  7799] avg mini-batch loss: 1.656\n",
      "[epoch: 0, i:  7899] avg mini-batch loss: 1.655\n",
      "[epoch: 0, i:  7999] avg mini-batch loss: 1.630\n",
      "[epoch: 0, i:  8099] avg mini-batch loss: 1.653\n",
      "[epoch: 0, i:  8199] avg mini-batch loss: 1.747\n",
      "[epoch: 0, i:  8299] avg mini-batch loss: 1.677\n",
      "[epoch: 0, i:  8399] avg mini-batch loss: 1.613\n",
      "[epoch: 0, i:  8499] avg mini-batch loss: 1.644\n",
      "[epoch: 0, i:  8599] avg mini-batch loss: 1.681\n",
      "[epoch: 0, i:  8699] avg mini-batch loss: 1.605\n",
      "[epoch: 0, i:  8799] avg mini-batch loss: 1.577\n",
      "[epoch: 0, i:  8899] avg mini-batch loss: 1.661\n",
      "[epoch: 0, i:  8999] avg mini-batch loss: 1.638\n",
      "[epoch: 0, i:  9099] avg mini-batch loss: 1.741\n",
      "[epoch: 0, i:  9199] avg mini-batch loss: 1.683\n",
      "[epoch: 0, i:  9299] avg mini-batch loss: 1.672\n",
      "[epoch: 0, i:  9399] avg mini-batch loss: 1.689\n",
      "[epoch: 0, i:  9499] avg mini-batch loss: 1.583\n",
      "[epoch: 0, i:  9599] avg mini-batch loss: 1.523\n",
      "[epoch: 0, i:  9699] avg mini-batch loss: 1.596\n",
      "[epoch: 0, i:  9799] avg mini-batch loss: 1.594\n",
      "[epoch: 0, i:  9899] avg mini-batch loss: 1.580\n",
      "[epoch: 0, i:  9999] avg mini-batch loss: 1.564\n",
      "[epoch: 0, i: 10099] avg mini-batch loss: 1.640\n",
      "[epoch: 0, i: 10199] avg mini-batch loss: 1.597\n",
      "[epoch: 0, i: 10299] avg mini-batch loss: 1.645\n",
      "[epoch: 0, i: 10399] avg mini-batch loss: 1.547\n",
      "[epoch: 0, i: 10499] avg mini-batch loss: 1.536\n",
      "[epoch: 0, i: 10599] avg mini-batch loss: 1.576\n",
      "[epoch: 0, i: 10699] avg mini-batch loss: 1.574\n",
      "[epoch: 0, i: 10799] avg mini-batch loss: 1.647\n",
      "[epoch: 0, i: 10899] avg mini-batch loss: 1.589\n",
      "[epoch: 0, i: 10999] avg mini-batch loss: 1.577\n",
      "[epoch: 0, i: 11099] avg mini-batch loss: 1.611\n",
      "[epoch: 0, i: 11199] avg mini-batch loss: 1.590\n",
      "[epoch: 0, i: 11299] avg mini-batch loss: 1.491\n",
      "[epoch: 0, i: 11399] avg mini-batch loss: 1.605\n",
      "[epoch: 0, i: 11499] avg mini-batch loss: 1.478\n",
      "[epoch: 0, i: 11599] avg mini-batch loss: 1.500\n",
      "[epoch: 0, i: 11699] avg mini-batch loss: 1.543\n",
      "[epoch: 0, i: 11799] avg mini-batch loss: 1.539\n",
      "[epoch: 0, i: 11899] avg mini-batch loss: 1.547\n",
      "[epoch: 0, i: 11999] avg mini-batch loss: 1.562\n",
      "[epoch: 0, i: 12099] avg mini-batch loss: 1.455\n",
      "[epoch: 0, i: 12199] avg mini-batch loss: 1.675\n",
      "[epoch: 0, i: 12299] avg mini-batch loss: 1.465\n",
      "[epoch: 0, i: 12399] avg mini-batch loss: 1.539\n",
      "[epoch: 0, i: 12499] avg mini-batch loss: 1.432\n",
      "[epoch: 1, i:    99] avg mini-batch loss: 1.462\n",
      "[epoch: 1, i:   199] avg mini-batch loss: 1.420\n",
      "[epoch: 1, i:   299] avg mini-batch loss: 1.459\n",
      "[epoch: 1, i:   399] avg mini-batch loss: 1.509\n",
      "[epoch: 1, i:   499] avg mini-batch loss: 1.388\n",
      "[epoch: 1, i:   599] avg mini-batch loss: 1.453\n",
      "[epoch: 1, i:   699] avg mini-batch loss: 1.523\n",
      "[epoch: 1, i:   799] avg mini-batch loss: 1.402\n",
      "[epoch: 1, i:   899] avg mini-batch loss: 1.509\n",
      "[epoch: 1, i:   999] avg mini-batch loss: 1.421\n",
      "[epoch: 1, i:  1099] avg mini-batch loss: 1.475\n",
      "[epoch: 1, i:  1199] avg mini-batch loss: 1.424\n",
      "[epoch: 1, i:  1299] avg mini-batch loss: 1.349\n",
      "[epoch: 1, i:  1399] avg mini-batch loss: 1.432\n",
      "[epoch: 1, i:  1499] avg mini-batch loss: 1.465\n",
      "[epoch: 1, i:  1599] avg mini-batch loss: 1.422\n",
      "[epoch: 1, i:  1699] avg mini-batch loss: 1.319\n",
      "[epoch: 1, i:  1799] avg mini-batch loss: 1.452\n",
      "[epoch: 1, i:  1899] avg mini-batch loss: 1.310\n",
      "[epoch: 1, i:  1999] avg mini-batch loss: 1.393\n",
      "[epoch: 1, i:  2099] avg mini-batch loss: 1.371\n",
      "[epoch: 1, i:  2199] avg mini-batch loss: 1.298\n",
      "[epoch: 1, i:  2299] avg mini-batch loss: 1.249\n",
      "[epoch: 1, i:  2399] avg mini-batch loss: 1.351\n",
      "[epoch: 1, i:  2499] avg mini-batch loss: 1.418\n",
      "[epoch: 1, i:  2599] avg mini-batch loss: 1.455\n",
      "[epoch: 1, i:  2699] avg mini-batch loss: 1.304\n",
      "[epoch: 1, i:  2799] avg mini-batch loss: 1.336\n",
      "[epoch: 1, i:  2899] avg mini-batch loss: 1.373\n",
      "[epoch: 1, i:  2999] avg mini-batch loss: 1.324\n",
      "[epoch: 1, i:  3099] avg mini-batch loss: 1.504\n",
      "[epoch: 1, i:  3199] avg mini-batch loss: 1.439\n",
      "[epoch: 1, i:  3299] avg mini-batch loss: 1.535\n",
      "[epoch: 1, i:  3399] avg mini-batch loss: 1.370\n",
      "[epoch: 1, i:  3499] avg mini-batch loss: 1.330\n",
      "[epoch: 1, i:  3599] avg mini-batch loss: 1.327\n",
      "[epoch: 1, i:  3699] avg mini-batch loss: 1.320\n",
      "[epoch: 1, i:  3799] avg mini-batch loss: 1.346\n",
      "[epoch: 1, i:  3899] avg mini-batch loss: 1.313\n",
      "[epoch: 1, i:  3999] avg mini-batch loss: 1.433\n",
      "[epoch: 1, i:  4099] avg mini-batch loss: 1.367\n",
      "[epoch: 1, i:  4199] avg mini-batch loss: 1.287\n",
      "[epoch: 1, i:  4299] avg mini-batch loss: 1.426\n",
      "[epoch: 1, i:  4399] avg mini-batch loss: 1.247\n",
      "[epoch: 1, i:  4499] avg mini-batch loss: 1.220\n",
      "[epoch: 1, i:  4599] avg mini-batch loss: 1.257\n",
      "[epoch: 1, i:  4699] avg mini-batch loss: 1.207\n",
      "[epoch: 1, i:  4799] avg mini-batch loss: 1.206\n",
      "[epoch: 1, i:  4899] avg mini-batch loss: 1.321\n",
      "[epoch: 1, i:  4999] avg mini-batch loss: 1.367\n",
      "[epoch: 1, i:  5099] avg mini-batch loss: 1.265\n",
      "[epoch: 1, i:  5199] avg mini-batch loss: 1.241\n",
      "[epoch: 1, i:  5299] avg mini-batch loss: 1.141\n",
      "[epoch: 1, i:  5399] avg mini-batch loss: 1.211\n",
      "[epoch: 1, i:  5499] avg mini-batch loss: 1.192\n",
      "[epoch: 1, i:  5599] avg mini-batch loss: 1.323\n",
      "[epoch: 1, i:  5699] avg mini-batch loss: 1.343\n",
      "[epoch: 1, i:  5799] avg mini-batch loss: 1.138\n",
      "[epoch: 1, i:  5899] avg mini-batch loss: 1.325\n",
      "[epoch: 1, i:  5999] avg mini-batch loss: 1.341\n",
      "[epoch: 1, i:  6099] avg mini-batch loss: 1.153\n",
      "[epoch: 1, i:  6199] avg mini-batch loss: 1.161\n",
      "[epoch: 1, i:  6299] avg mini-batch loss: 1.259\n",
      "[epoch: 1, i:  6399] avg mini-batch loss: 1.210\n",
      "[epoch: 1, i:  6499] avg mini-batch loss: 1.366\n",
      "[epoch: 1, i:  6599] avg mini-batch loss: 1.194\n",
      "[epoch: 1, i:  6699] avg mini-batch loss: 1.269\n",
      "[epoch: 1, i:  6799] avg mini-batch loss: 1.262\n",
      "[epoch: 1, i:  6899] avg mini-batch loss: 1.234\n",
      "[epoch: 1, i:  6999] avg mini-batch loss: 1.205\n",
      "[epoch: 1, i:  7099] avg mini-batch loss: 1.259\n",
      "[epoch: 1, i:  7199] avg mini-batch loss: 1.172\n",
      "[epoch: 1, i:  7299] avg mini-batch loss: 1.235\n",
      "[epoch: 1, i:  7399] avg mini-batch loss: 1.228\n",
      "[epoch: 1, i:  7499] avg mini-batch loss: 1.348\n",
      "[epoch: 1, i:  7599] avg mini-batch loss: 1.166\n",
      "[epoch: 1, i:  7699] avg mini-batch loss: 1.303\n",
      "[epoch: 1, i:  7799] avg mini-batch loss: 1.093\n",
      "[epoch: 1, i:  7899] avg mini-batch loss: 1.113\n",
      "[epoch: 1, i:  7999] avg mini-batch loss: 1.016\n",
      "[epoch: 1, i:  8099] avg mini-batch loss: 1.168\n",
      "[epoch: 1, i:  8199] avg mini-batch loss: 1.214\n",
      "[epoch: 1, i:  8299] avg mini-batch loss: 1.155\n",
      "[epoch: 1, i:  8399] avg mini-batch loss: 1.203\n",
      "[epoch: 1, i:  8499] avg mini-batch loss: 1.134\n",
      "[epoch: 1, i:  8599] avg mini-batch loss: 1.078\n",
      "[epoch: 1, i:  8699] avg mini-batch loss: 1.037\n",
      "[epoch: 1, i:  8799] avg mini-batch loss: 1.063\n",
      "[epoch: 1, i:  8899] avg mini-batch loss: 0.953\n",
      "[epoch: 1, i:  8999] avg mini-batch loss: 1.134\n",
      "[epoch: 1, i:  9099] avg mini-batch loss: 1.199\n",
      "[epoch: 1, i:  9199] avg mini-batch loss: 1.109\n",
      "[epoch: 1, i:  9299] avg mini-batch loss: 1.187\n",
      "[epoch: 1, i:  9399] avg mini-batch loss: 1.129\n",
      "[epoch: 1, i:  9499] avg mini-batch loss: 1.147\n",
      "[epoch: 1, i:  9599] avg mini-batch loss: 1.081\n",
      "[epoch: 1, i:  9699] avg mini-batch loss: 1.173\n",
      "[epoch: 1, i:  9799] avg mini-batch loss: 1.166\n",
      "[epoch: 1, i:  9899] avg mini-batch loss: 1.066\n",
      "[epoch: 1, i:  9999] avg mini-batch loss: 1.121\n",
      "[epoch: 1, i: 10099] avg mini-batch loss: 1.137\n",
      "[epoch: 1, i: 10199] avg mini-batch loss: 1.149\n",
      "[epoch: 1, i: 10299] avg mini-batch loss: 1.145\n",
      "[epoch: 1, i: 10399] avg mini-batch loss: 1.087\n",
      "[epoch: 1, i: 10499] avg mini-batch loss: 1.112\n",
      "[epoch: 1, i: 10599] avg mini-batch loss: 1.060\n",
      "[epoch: 1, i: 10699] avg mini-batch loss: 1.088\n",
      "[epoch: 1, i: 10799] avg mini-batch loss: 1.068\n",
      "[epoch: 1, i: 10899] avg mini-batch loss: 1.084\n",
      "[epoch: 1, i: 10999] avg mini-batch loss: 1.205\n",
      "[epoch: 1, i: 11099] avg mini-batch loss: 1.043\n",
      "[epoch: 1, i: 11199] avg mini-batch loss: 1.070\n",
      "[epoch: 1, i: 11299] avg mini-batch loss: 1.123\n",
      "[epoch: 1, i: 11399] avg mini-batch loss: 1.043\n",
      "[epoch: 1, i: 11499] avg mini-batch loss: 1.084\n",
      "[epoch: 1, i: 11599] avg mini-batch loss: 1.034\n",
      "[epoch: 1, i: 11699] avg mini-batch loss: 1.094\n",
      "[epoch: 1, i: 11799] avg mini-batch loss: 1.127\n",
      "[epoch: 1, i: 11899] avg mini-batch loss: 1.046\n",
      "[epoch: 1, i: 11999] avg mini-batch loss: 1.096\n",
      "[epoch: 1, i: 12099] avg mini-batch loss: 0.946\n",
      "[epoch: 1, i: 12199] avg mini-batch loss: 1.082\n",
      "[epoch: 1, i: 12299] avg mini-batch loss: 1.125\n",
      "[epoch: 1, i: 12399] avg mini-batch loss: 1.178\n",
      "[epoch: 1, i: 12499] avg mini-batch loss: 1.112\n",
      "[epoch: 2, i:    99] avg mini-batch loss: 0.899\n",
      "[epoch: 2, i:   199] avg mini-batch loss: 0.848\n",
      "[epoch: 2, i:   299] avg mini-batch loss: 1.112\n",
      "[epoch: 2, i:   399] avg mini-batch loss: 0.956\n",
      "[epoch: 2, i:   499] avg mini-batch loss: 1.008\n",
      "[epoch: 2, i:   599] avg mini-batch loss: 1.072\n",
      "[epoch: 2, i:   699] avg mini-batch loss: 0.895\n",
      "[epoch: 2, i:   799] avg mini-batch loss: 1.108\n",
      "[epoch: 2, i:   899] avg mini-batch loss: 0.962\n",
      "[epoch: 2, i:   999] avg mini-batch loss: 0.971\n",
      "[epoch: 2, i:  1099] avg mini-batch loss: 1.002\n",
      "[epoch: 2, i:  1199] avg mini-batch loss: 1.011\n",
      "[epoch: 2, i:  1299] avg mini-batch loss: 0.983\n",
      "[epoch: 2, i:  1399] avg mini-batch loss: 1.012\n",
      "[epoch: 2, i:  1499] avg mini-batch loss: 1.026\n",
      "[epoch: 2, i:  1599] avg mini-batch loss: 0.964\n",
      "[epoch: 2, i:  1699] avg mini-batch loss: 0.950\n",
      "[epoch: 2, i:  1799] avg mini-batch loss: 0.955\n",
      "[epoch: 2, i:  1899] avg mini-batch loss: 0.870\n",
      "[epoch: 2, i:  1999] avg mini-batch loss: 0.971\n",
      "[epoch: 2, i:  2099] avg mini-batch loss: 0.990\n",
      "[epoch: 2, i:  2199] avg mini-batch loss: 0.848\n",
      "[epoch: 2, i:  2299] avg mini-batch loss: 0.962\n",
      "[epoch: 2, i:  2399] avg mini-batch loss: 0.989\n",
      "[epoch: 2, i:  2499] avg mini-batch loss: 1.022\n",
      "[epoch: 2, i:  2599] avg mini-batch loss: 0.952\n",
      "[epoch: 2, i:  2699] avg mini-batch loss: 0.913\n",
      "[epoch: 2, i:  2799] avg mini-batch loss: 1.019\n",
      "[epoch: 2, i:  2899] avg mini-batch loss: 0.969\n",
      "[epoch: 2, i:  2999] avg mini-batch loss: 0.867\n",
      "[epoch: 2, i:  3099] avg mini-batch loss: 0.938\n",
      "[epoch: 2, i:  3199] avg mini-batch loss: 0.976\n",
      "[epoch: 2, i:  3299] avg mini-batch loss: 0.952\n",
      "[epoch: 2, i:  3399] avg mini-batch loss: 0.951\n",
      "[epoch: 2, i:  3499] avg mini-batch loss: 0.992\n",
      "[epoch: 2, i:  3599] avg mini-batch loss: 0.965\n",
      "[epoch: 2, i:  3699] avg mini-batch loss: 0.982\n",
      "[epoch: 2, i:  3799] avg mini-batch loss: 0.818\n",
      "[epoch: 2, i:  3899] avg mini-batch loss: 0.961\n",
      "[epoch: 2, i:  3999] avg mini-batch loss: 0.834\n",
      "[epoch: 2, i:  4099] avg mini-batch loss: 0.896\n",
      "[epoch: 2, i:  4199] avg mini-batch loss: 0.942\n",
      "[epoch: 2, i:  4299] avg mini-batch loss: 0.980\n",
      "[epoch: 2, i:  4399] avg mini-batch loss: 0.871\n",
      "[epoch: 2, i:  4499] avg mini-batch loss: 0.869\n",
      "[epoch: 2, i:  4599] avg mini-batch loss: 0.927\n",
      "[epoch: 2, i:  4699] avg mini-batch loss: 0.888\n",
      "[epoch: 2, i:  4799] avg mini-batch loss: 0.960\n",
      "[epoch: 2, i:  4899] avg mini-batch loss: 0.913\n",
      "[epoch: 2, i:  4999] avg mini-batch loss: 0.932\n",
      "[epoch: 2, i:  5099] avg mini-batch loss: 0.814\n",
      "[epoch: 2, i:  5199] avg mini-batch loss: 0.947\n",
      "[epoch: 2, i:  5299] avg mini-batch loss: 0.978\n",
      "[epoch: 2, i:  5399] avg mini-batch loss: 0.910\n",
      "[epoch: 2, i:  5499] avg mini-batch loss: 0.988\n",
      "[epoch: 2, i:  5599] avg mini-batch loss: 0.989\n",
      "[epoch: 2, i:  5699] avg mini-batch loss: 0.917\n",
      "[epoch: 2, i:  5799] avg mini-batch loss: 0.861\n",
      "[epoch: 2, i:  5899] avg mini-batch loss: 0.958\n",
      "[epoch: 2, i:  5999] avg mini-batch loss: 0.934\n",
      "[epoch: 2, i:  6099] avg mini-batch loss: 0.879\n",
      "[epoch: 2, i:  6199] avg mini-batch loss: 0.858\n",
      "[epoch: 2, i:  6299] avg mini-batch loss: 0.940\n",
      "[epoch: 2, i:  6399] avg mini-batch loss: 0.883\n",
      "[epoch: 2, i:  6499] avg mini-batch loss: 0.889\n",
      "[epoch: 2, i:  6599] avg mini-batch loss: 0.982\n",
      "[epoch: 2, i:  6699] avg mini-batch loss: 0.760\n",
      "[epoch: 2, i:  6799] avg mini-batch loss: 0.949\n",
      "[epoch: 2, i:  6899] avg mini-batch loss: 0.928\n",
      "[epoch: 2, i:  6999] avg mini-batch loss: 0.854\n",
      "[epoch: 2, i:  7099] avg mini-batch loss: 0.856\n",
      "[epoch: 2, i:  7199] avg mini-batch loss: 0.929\n",
      "[epoch: 2, i:  7299] avg mini-batch loss: 0.786\n",
      "[epoch: 2, i:  7399] avg mini-batch loss: 0.902\n",
      "[epoch: 2, i:  7499] avg mini-batch loss: 0.868\n",
      "[epoch: 2, i:  7599] avg mini-batch loss: 0.866\n",
      "[epoch: 2, i:  7699] avg mini-batch loss: 0.859\n",
      "[epoch: 2, i:  7799] avg mini-batch loss: 0.852\n",
      "[epoch: 2, i:  7899] avg mini-batch loss: 0.955\n",
      "[epoch: 2, i:  7999] avg mini-batch loss: 0.760\n",
      "[epoch: 2, i:  8099] avg mini-batch loss: 0.897\n",
      "[epoch: 2, i:  8199] avg mini-batch loss: 0.846\n",
      "[epoch: 2, i:  8299] avg mini-batch loss: 0.949\n",
      "[epoch: 2, i:  8399] avg mini-batch loss: 0.853\n",
      "[epoch: 2, i:  8499] avg mini-batch loss: 0.904\n",
      "[epoch: 2, i:  8599] avg mini-batch loss: 0.914\n",
      "[epoch: 2, i:  8699] avg mini-batch loss: 0.841\n",
      "[epoch: 2, i:  8799] avg mini-batch loss: 0.941\n",
      "[epoch: 2, i:  8899] avg mini-batch loss: 0.873\n",
      "[epoch: 2, i:  8999] avg mini-batch loss: 1.013\n",
      "[epoch: 2, i:  9099] avg mini-batch loss: 0.829\n",
      "[epoch: 2, i:  9199] avg mini-batch loss: 0.884\n",
      "[epoch: 2, i:  9299] avg mini-batch loss: 0.795\n",
      "[epoch: 2, i:  9399] avg mini-batch loss: 0.709\n",
      "[epoch: 2, i:  9499] avg mini-batch loss: 0.841\n",
      "[epoch: 2, i:  9599] avg mini-batch loss: 0.856\n",
      "[epoch: 2, i:  9699] avg mini-batch loss: 0.797\n",
      "[epoch: 2, i:  9799] avg mini-batch loss: 0.825\n",
      "[epoch: 2, i:  9899] avg mini-batch loss: 0.814\n",
      "[epoch: 2, i:  9999] avg mini-batch loss: 0.867\n",
      "[epoch: 2, i: 10099] avg mini-batch loss: 0.820\n",
      "[epoch: 2, i: 10199] avg mini-batch loss: 0.854\n",
      "[epoch: 2, i: 10299] avg mini-batch loss: 0.854\n",
      "[epoch: 2, i: 10399] avg mini-batch loss: 0.846\n",
      "[epoch: 2, i: 10499] avg mini-batch loss: 0.836\n",
      "[epoch: 2, i: 10599] avg mini-batch loss: 0.762\n",
      "[epoch: 2, i: 10699] avg mini-batch loss: 0.842\n",
      "[epoch: 2, i: 10799] avg mini-batch loss: 0.910\n",
      "[epoch: 2, i: 10899] avg mini-batch loss: 0.843\n",
      "[epoch: 2, i: 10999] avg mini-batch loss: 0.831\n",
      "[epoch: 2, i: 11099] avg mini-batch loss: 0.861\n",
      "[epoch: 2, i: 11199] avg mini-batch loss: 0.855\n",
      "[epoch: 2, i: 11299] avg mini-batch loss: 0.912\n",
      "[epoch: 2, i: 11399] avg mini-batch loss: 0.841\n",
      "[epoch: 2, i: 11499] avg mini-batch loss: 0.785\n",
      "[epoch: 2, i: 11599] avg mini-batch loss: 0.837\n",
      "[epoch: 2, i: 11699] avg mini-batch loss: 0.804\n",
      "[epoch: 2, i: 11799] avg mini-batch loss: 0.778\n",
      "[epoch: 2, i: 11899] avg mini-batch loss: 0.780\n",
      "[epoch: 2, i: 11999] avg mini-batch loss: 0.836\n",
      "[epoch: 2, i: 12099] avg mini-batch loss: 0.907\n",
      "[epoch: 2, i: 12199] avg mini-batch loss: 0.722\n",
      "[epoch: 2, i: 12299] avg mini-batch loss: 0.836\n",
      "[epoch: 2, i: 12399] avg mini-batch loss: 0.796\n",
      "[epoch: 2, i: 12499] avg mini-batch loss: 0.862\n",
      "[epoch: 3, i:    99] avg mini-batch loss: 0.729\n",
      "[epoch: 3, i:   199] avg mini-batch loss: 0.772\n",
      "[epoch: 3, i:   299] avg mini-batch loss: 0.637\n",
      "[epoch: 3, i:   399] avg mini-batch loss: 0.766\n",
      "[epoch: 3, i:   499] avg mini-batch loss: 0.807\n",
      "[epoch: 3, i:   599] avg mini-batch loss: 0.656\n",
      "[epoch: 3, i:   699] avg mini-batch loss: 0.732\n",
      "[epoch: 3, i:   799] avg mini-batch loss: 0.622\n",
      "[epoch: 3, i:   899] avg mini-batch loss: 0.624\n",
      "[epoch: 3, i:   999] avg mini-batch loss: 0.687\n",
      "[epoch: 3, i:  1099] avg mini-batch loss: 0.681\n",
      "[epoch: 3, i:  1199] avg mini-batch loss: 0.688\n",
      "[epoch: 3, i:  1299] avg mini-batch loss: 0.667\n",
      "[epoch: 3, i:  1399] avg mini-batch loss: 0.646\n",
      "[epoch: 3, i:  1499] avg mini-batch loss: 0.805\n",
      "[epoch: 3, i:  1599] avg mini-batch loss: 0.723\n",
      "[epoch: 3, i:  1699] avg mini-batch loss: 0.687\n",
      "[epoch: 3, i:  1799] avg mini-batch loss: 0.655\n",
      "[epoch: 3, i:  1899] avg mini-batch loss: 0.751\n",
      "[epoch: 3, i:  1999] avg mini-batch loss: 0.714\n",
      "[epoch: 3, i:  2099] avg mini-batch loss: 0.754\n",
      "[epoch: 3, i:  2199] avg mini-batch loss: 0.635\n",
      "[epoch: 3, i:  2299] avg mini-batch loss: 0.663\n",
      "[epoch: 3, i:  2399] avg mini-batch loss: 0.727\n",
      "[epoch: 3, i:  2499] avg mini-batch loss: 0.761\n",
      "[epoch: 3, i:  2599] avg mini-batch loss: 0.747\n",
      "[epoch: 3, i:  2699] avg mini-batch loss: 0.825\n",
      "[epoch: 3, i:  2799] avg mini-batch loss: 0.785\n",
      "[epoch: 3, i:  2899] avg mini-batch loss: 0.614\n",
      "[epoch: 3, i:  2999] avg mini-batch loss: 0.701\n",
      "[epoch: 3, i:  3099] avg mini-batch loss: 0.668\n",
      "[epoch: 3, i:  3199] avg mini-batch loss: 0.635\n",
      "[epoch: 3, i:  3299] avg mini-batch loss: 0.642\n",
      "[epoch: 3, i:  3399] avg mini-batch loss: 0.634\n",
      "[epoch: 3, i:  3499] avg mini-batch loss: 0.706\n",
      "[epoch: 3, i:  3599] avg mini-batch loss: 0.724\n",
      "[epoch: 3, i:  3699] avg mini-batch loss: 0.677\n",
      "[epoch: 3, i:  3799] avg mini-batch loss: 0.716\n",
      "[epoch: 3, i:  3899] avg mini-batch loss: 0.692\n",
      "[epoch: 3, i:  3999] avg mini-batch loss: 0.684\n",
      "[epoch: 3, i:  4099] avg mini-batch loss: 0.722\n",
      "[epoch: 3, i:  4199] avg mini-batch loss: 0.681\n",
      "[epoch: 3, i:  4299] avg mini-batch loss: 0.790\n",
      "[epoch: 3, i:  4399] avg mini-batch loss: 0.689\n",
      "[epoch: 3, i:  4499] avg mini-batch loss: 0.798\n",
      "[epoch: 3, i:  4599] avg mini-batch loss: 0.846\n",
      "[epoch: 3, i:  4699] avg mini-batch loss: 0.656\n",
      "[epoch: 3, i:  4799] avg mini-batch loss: 0.630\n",
      "[epoch: 3, i:  4899] avg mini-batch loss: 0.740\n",
      "[epoch: 3, i:  4999] avg mini-batch loss: 0.745\n",
      "[epoch: 3, i:  5099] avg mini-batch loss: 0.681\n",
      "[epoch: 3, i:  5199] avg mini-batch loss: 0.749\n",
      "[epoch: 3, i:  5299] avg mini-batch loss: 0.700\n",
      "[epoch: 3, i:  5399] avg mini-batch loss: 0.709\n",
      "[epoch: 3, i:  5499] avg mini-batch loss: 0.609\n",
      "[epoch: 3, i:  5599] avg mini-batch loss: 0.816\n",
      "[epoch: 3, i:  5699] avg mini-batch loss: 0.749\n",
      "[epoch: 3, i:  5799] avg mini-batch loss: 0.671\n",
      "[epoch: 3, i:  5899] avg mini-batch loss: 0.631\n",
      "[epoch: 3, i:  5999] avg mini-batch loss: 0.714\n",
      "[epoch: 3, i:  6099] avg mini-batch loss: 0.773\n",
      "[epoch: 3, i:  6199] avg mini-batch loss: 0.649\n",
      "[epoch: 3, i:  6299] avg mini-batch loss: 0.811\n",
      "[epoch: 3, i:  6399] avg mini-batch loss: 0.735\n",
      "[epoch: 3, i:  6499] avg mini-batch loss: 0.606\n",
      "[epoch: 3, i:  6599] avg mini-batch loss: 0.626\n",
      "[epoch: 3, i:  6699] avg mini-batch loss: 0.671\n",
      "[epoch: 3, i:  6799] avg mini-batch loss: 0.682\n",
      "[epoch: 3, i:  6899] avg mini-batch loss: 0.818\n",
      "[epoch: 3, i:  6999] avg mini-batch loss: 0.807\n",
      "[epoch: 3, i:  7099] avg mini-batch loss: 0.729\n",
      "[epoch: 3, i:  7199] avg mini-batch loss: 0.657\n",
      "[epoch: 3, i:  7299] avg mini-batch loss: 0.702\n",
      "[epoch: 3, i:  7399] avg mini-batch loss: 0.682\n",
      "[epoch: 3, i:  7499] avg mini-batch loss: 0.704\n",
      "[epoch: 3, i:  7599] avg mini-batch loss: 0.647\n",
      "[epoch: 3, i:  7699] avg mini-batch loss: 0.631\n",
      "[epoch: 3, i:  7799] avg mini-batch loss: 0.803\n",
      "[epoch: 3, i:  7899] avg mini-batch loss: 0.673\n",
      "[epoch: 3, i:  7999] avg mini-batch loss: 0.688\n",
      "[epoch: 3, i:  8099] avg mini-batch loss: 0.670\n",
      "[epoch: 3, i:  8199] avg mini-batch loss: 0.682\n",
      "[epoch: 3, i:  8299] avg mini-batch loss: 0.599\n",
      "[epoch: 3, i:  8399] avg mini-batch loss: 0.761\n",
      "[epoch: 3, i:  8499] avg mini-batch loss: 0.647\n",
      "[epoch: 3, i:  8599] avg mini-batch loss: 0.718\n",
      "[epoch: 3, i:  8699] avg mini-batch loss: 0.791\n",
      "[epoch: 3, i:  8799] avg mini-batch loss: 0.695\n",
      "[epoch: 3, i:  8899] avg mini-batch loss: 0.648\n",
      "[epoch: 3, i:  8999] avg mini-batch loss: 0.672\n",
      "[epoch: 3, i:  9099] avg mini-batch loss: 0.753\n",
      "[epoch: 3, i:  9199] avg mini-batch loss: 0.712\n",
      "[epoch: 3, i:  9299] avg mini-batch loss: 0.691\n",
      "[epoch: 3, i:  9399] avg mini-batch loss: 0.733\n",
      "[epoch: 3, i:  9499] avg mini-batch loss: 0.656\n",
      "[epoch: 3, i:  9599] avg mini-batch loss: 0.612\n",
      "[epoch: 3, i:  9699] avg mini-batch loss: 0.668\n",
      "[epoch: 3, i:  9799] avg mini-batch loss: 0.774\n",
      "[epoch: 3, i:  9899] avg mini-batch loss: 0.653\n",
      "[epoch: 3, i:  9999] avg mini-batch loss: 0.678\n",
      "[epoch: 3, i: 10099] avg mini-batch loss: 0.613\n",
      "[epoch: 3, i: 10199] avg mini-batch loss: 0.644\n",
      "[epoch: 3, i: 10299] avg mini-batch loss: 0.761\n",
      "[epoch: 3, i: 10399] avg mini-batch loss: 0.780\n",
      "[epoch: 3, i: 10499] avg mini-batch loss: 0.673\n",
      "[epoch: 3, i: 10599] avg mini-batch loss: 0.546\n",
      "[epoch: 3, i: 10699] avg mini-batch loss: 0.637\n",
      "[epoch: 3, i: 10799] avg mini-batch loss: 0.755\n",
      "[epoch: 3, i: 10899] avg mini-batch loss: 0.655\n",
      "[epoch: 3, i: 10999] avg mini-batch loss: 0.677\n",
      "[epoch: 3, i: 11099] avg mini-batch loss: 0.626\n",
      "[epoch: 3, i: 11199] avg mini-batch loss: 0.683\n",
      "[epoch: 3, i: 11299] avg mini-batch loss: 0.607\n",
      "[epoch: 3, i: 11399] avg mini-batch loss: 0.674\n",
      "[epoch: 3, i: 11499] avg mini-batch loss: 0.720\n",
      "[epoch: 3, i: 11599] avg mini-batch loss: 0.702\n",
      "[epoch: 3, i: 11699] avg mini-batch loss: 0.757\n",
      "[epoch: 3, i: 11799] avg mini-batch loss: 0.766\n",
      "[epoch: 3, i: 11899] avg mini-batch loss: 0.683\n",
      "[epoch: 3, i: 11999] avg mini-batch loss: 0.611\n",
      "[epoch: 3, i: 12099] avg mini-batch loss: 0.674\n",
      "[epoch: 3, i: 12199] avg mini-batch loss: 0.653\n",
      "[epoch: 3, i: 12299] avg mini-batch loss: 0.570\n",
      "[epoch: 3, i: 12399] avg mini-batch loss: 0.719\n",
      "[epoch: 3, i: 12499] avg mini-batch loss: 0.757\n",
      "[epoch: 4, i:    99] avg mini-batch loss: 0.526\n",
      "[epoch: 4, i:   199] avg mini-batch loss: 0.569\n",
      "[epoch: 4, i:   299] avg mini-batch loss: 0.488\n",
      "[epoch: 4, i:   399] avg mini-batch loss: 0.479\n",
      "[epoch: 4, i:   499] avg mini-batch loss: 0.589\n",
      "[epoch: 4, i:   599] avg mini-batch loss: 0.411\n",
      "[epoch: 4, i:   699] avg mini-batch loss: 0.543\n",
      "[epoch: 4, i:   799] avg mini-batch loss: 0.551\n",
      "[epoch: 4, i:   899] avg mini-batch loss: 0.513\n",
      "[epoch: 4, i:   999] avg mini-batch loss: 0.656\n",
      "[epoch: 4, i:  1099] avg mini-batch loss: 0.494\n",
      "[epoch: 4, i:  1199] avg mini-batch loss: 0.635\n",
      "[epoch: 4, i:  1299] avg mini-batch loss: 0.516\n",
      "[epoch: 4, i:  1399] avg mini-batch loss: 0.544\n",
      "[epoch: 4, i:  1499] avg mini-batch loss: 0.592\n",
      "[epoch: 4, i:  1599] avg mini-batch loss: 0.473\n",
      "[epoch: 4, i:  1699] avg mini-batch loss: 0.472\n",
      "[epoch: 4, i:  1799] avg mini-batch loss: 0.532\n",
      "[epoch: 4, i:  1899] avg mini-batch loss: 0.540\n",
      "[epoch: 4, i:  1999] avg mini-batch loss: 0.611\n",
      "[epoch: 4, i:  2099] avg mini-batch loss: 0.497\n",
      "[epoch: 4, i:  2199] avg mini-batch loss: 0.444\n",
      "[epoch: 4, i:  2299] avg mini-batch loss: 0.608\n",
      "[epoch: 4, i:  2399] avg mini-batch loss: 0.553\n",
      "[epoch: 4, i:  2499] avg mini-batch loss: 0.575\n",
      "[epoch: 4, i:  2599] avg mini-batch loss: 0.599\n",
      "[epoch: 4, i:  2699] avg mini-batch loss: 0.463\n",
      "[epoch: 4, i:  2799] avg mini-batch loss: 0.587\n",
      "[epoch: 4, i:  2899] avg mini-batch loss: 0.576\n",
      "[epoch: 4, i:  2999] avg mini-batch loss: 0.597\n",
      "[epoch: 4, i:  3099] avg mini-batch loss: 0.572\n",
      "[epoch: 4, i:  3199] avg mini-batch loss: 0.551\n",
      "[epoch: 4, i:  3299] avg mini-batch loss: 0.526\n",
      "[epoch: 4, i:  3399] avg mini-batch loss: 0.596\n",
      "[epoch: 4, i:  3499] avg mini-batch loss: 0.571\n",
      "[epoch: 4, i:  3599] avg mini-batch loss: 0.509\n",
      "[epoch: 4, i:  3699] avg mini-batch loss: 0.635\n",
      "[epoch: 4, i:  3799] avg mini-batch loss: 0.543\n",
      "[epoch: 4, i:  3899] avg mini-batch loss: 0.502\n",
      "[epoch: 4, i:  3999] avg mini-batch loss: 0.515\n",
      "[epoch: 4, i:  4099] avg mini-batch loss: 0.556\n",
      "[epoch: 4, i:  4199] avg mini-batch loss: 0.493\n",
      "[epoch: 4, i:  4299] avg mini-batch loss: 0.610\n",
      "[epoch: 4, i:  4399] avg mini-batch loss: 0.528\n",
      "[epoch: 4, i:  4499] avg mini-batch loss: 0.563\n",
      "[epoch: 4, i:  4599] avg mini-batch loss: 0.587\n",
      "[epoch: 4, i:  4699] avg mini-batch loss: 0.581\n",
      "[epoch: 4, i:  4799] avg mini-batch loss: 0.563\n",
      "[epoch: 4, i:  4899] avg mini-batch loss: 0.534\n",
      "[epoch: 4, i:  4999] avg mini-batch loss: 0.505\n",
      "[epoch: 4, i:  5099] avg mini-batch loss: 0.475\n",
      "[epoch: 4, i:  5199] avg mini-batch loss: 0.559\n",
      "[epoch: 4, i:  5299] avg mini-batch loss: 0.585\n",
      "[epoch: 4, i:  5399] avg mini-batch loss: 0.523\n",
      "[epoch: 4, i:  5499] avg mini-batch loss: 0.598\n",
      "[epoch: 4, i:  5599] avg mini-batch loss: 0.488\n",
      "[epoch: 4, i:  5699] avg mini-batch loss: 0.509\n",
      "[epoch: 4, i:  5799] avg mini-batch loss: 0.449\n",
      "[epoch: 4, i:  5899] avg mini-batch loss: 0.558\n",
      "[epoch: 4, i:  5999] avg mini-batch loss: 0.566\n",
      "[epoch: 4, i:  6099] avg mini-batch loss: 0.595\n",
      "[epoch: 4, i:  6199] avg mini-batch loss: 0.600\n",
      "[epoch: 4, i:  6299] avg mini-batch loss: 0.547\n",
      "[epoch: 4, i:  6399] avg mini-batch loss: 0.589\n",
      "[epoch: 4, i:  6499] avg mini-batch loss: 0.584\n",
      "[epoch: 4, i:  6599] avg mini-batch loss: 0.615\n",
      "[epoch: 4, i:  6699] avg mini-batch loss: 0.476\n",
      "[epoch: 4, i:  6799] avg mini-batch loss: 0.648\n",
      "[epoch: 4, i:  6899] avg mini-batch loss: 0.462\n",
      "[epoch: 4, i:  6999] avg mini-batch loss: 0.509\n",
      "[epoch: 4, i:  7099] avg mini-batch loss: 0.513\n",
      "[epoch: 4, i:  7199] avg mini-batch loss: 0.592\n",
      "[epoch: 4, i:  7299] avg mini-batch loss: 0.557\n",
      "[epoch: 4, i:  7399] avg mini-batch loss: 0.582\n",
      "[epoch: 4, i:  7499] avg mini-batch loss: 0.588\n",
      "[epoch: 4, i:  7599] avg mini-batch loss: 0.566\n",
      "[epoch: 4, i:  7699] avg mini-batch loss: 0.599\n",
      "[epoch: 4, i:  7799] avg mini-batch loss: 0.625\n",
      "[epoch: 4, i:  7899] avg mini-batch loss: 0.577\n",
      "[epoch: 4, i:  7999] avg mini-batch loss: 0.492\n",
      "[epoch: 4, i:  8099] avg mini-batch loss: 0.550\n",
      "[epoch: 4, i:  8199] avg mini-batch loss: 0.582\n",
      "[epoch: 4, i:  8299] avg mini-batch loss: 0.518\n",
      "[epoch: 4, i:  8399] avg mini-batch loss: 0.520\n",
      "[epoch: 4, i:  8499] avg mini-batch loss: 0.544\n",
      "[epoch: 4, i:  8599] avg mini-batch loss: 0.464\n",
      "[epoch: 4, i:  8699] avg mini-batch loss: 0.543\n",
      "[epoch: 4, i:  8799] avg mini-batch loss: 0.584\n",
      "[epoch: 4, i:  8899] avg mini-batch loss: 0.573\n",
      "[epoch: 4, i:  8999] avg mini-batch loss: 0.465\n",
      "[epoch: 4, i:  9099] avg mini-batch loss: 0.485\n",
      "[epoch: 4, i:  9199] avg mini-batch loss: 0.580\n",
      "[epoch: 4, i:  9299] avg mini-batch loss: 0.518\n",
      "[epoch: 4, i:  9399] avg mini-batch loss: 0.638\n",
      "[epoch: 4, i:  9499] avg mini-batch loss: 0.590\n",
      "[epoch: 4, i:  9599] avg mini-batch loss: 0.493\n",
      "[epoch: 4, i:  9699] avg mini-batch loss: 0.642\n",
      "[epoch: 4, i:  9799] avg mini-batch loss: 0.520\n",
      "[epoch: 4, i:  9899] avg mini-batch loss: 0.539\n",
      "[epoch: 4, i:  9999] avg mini-batch loss: 0.629\n",
      "[epoch: 4, i: 10099] avg mini-batch loss: 0.597\n",
      "[epoch: 4, i: 10199] avg mini-batch loss: 0.576\n",
      "[epoch: 4, i: 10299] avg mini-batch loss: 0.451\n",
      "[epoch: 4, i: 10399] avg mini-batch loss: 0.574\n",
      "[epoch: 4, i: 10499] avg mini-batch loss: 0.562\n",
      "[epoch: 4, i: 10599] avg mini-batch loss: 0.559\n",
      "[epoch: 4, i: 10699] avg mini-batch loss: 0.564\n",
      "[epoch: 4, i: 10799] avg mini-batch loss: 0.623\n",
      "[epoch: 4, i: 10899] avg mini-batch loss: 0.571\n",
      "[epoch: 4, i: 10999] avg mini-batch loss: 0.648\n",
      "[epoch: 4, i: 11099] avg mini-batch loss: 0.594\n",
      "[epoch: 4, i: 11199] avg mini-batch loss: 0.500\n",
      "[epoch: 4, i: 11299] avg mini-batch loss: 0.602\n",
      "[epoch: 4, i: 11399] avg mini-batch loss: 0.556\n",
      "[epoch: 4, i: 11499] avg mini-batch loss: 0.604\n",
      "[epoch: 4, i: 11599] avg mini-batch loss: 0.578\n",
      "[epoch: 4, i: 11699] avg mini-batch loss: 0.593\n",
      "[epoch: 4, i: 11799] avg mini-batch loss: 0.632\n",
      "[epoch: 4, i: 11899] avg mini-batch loss: 0.566\n",
      "[epoch: 4, i: 11999] avg mini-batch loss: 0.578\n",
      "[epoch: 4, i: 12099] avg mini-batch loss: 0.619\n",
      "[epoch: 4, i: 12199] avg mini-batch loss: 0.595\n",
      "[epoch: 4, i: 12299] avg mini-batch loss: 0.560\n",
      "[epoch: 4, i: 12399] avg mini-batch loss: 0.534\n",
      "[epoch: 4, i: 12499] avg mini-batch loss: 0.510\n",
      "[epoch: 5, i:    99] avg mini-batch loss: 0.438\n",
      "[epoch: 5, i:   199] avg mini-batch loss: 0.395\n",
      "[epoch: 5, i:   299] avg mini-batch loss: 0.377\n",
      "[epoch: 5, i:   399] avg mini-batch loss: 0.444\n",
      "[epoch: 5, i:   499] avg mini-batch loss: 0.375\n",
      "[epoch: 5, i:   599] avg mini-batch loss: 0.393\n",
      "[epoch: 5, i:   699] avg mini-batch loss: 0.356\n",
      "[epoch: 5, i:   799] avg mini-batch loss: 0.342\n",
      "[epoch: 5, i:   899] avg mini-batch loss: 0.435\n",
      "[epoch: 5, i:   999] avg mini-batch loss: 0.369\n",
      "[epoch: 5, i:  1099] avg mini-batch loss: 0.516\n",
      "[epoch: 5, i:  1199] avg mini-batch loss: 0.435\n",
      "[epoch: 5, i:  1299] avg mini-batch loss: 0.407\n",
      "[epoch: 5, i:  1399] avg mini-batch loss: 0.390\n",
      "[epoch: 5, i:  1499] avg mini-batch loss: 0.391\n",
      "[epoch: 5, i:  1599] avg mini-batch loss: 0.418\n",
      "[epoch: 5, i:  1699] avg mini-batch loss: 0.434\n",
      "[epoch: 5, i:  1799] avg mini-batch loss: 0.391\n",
      "[epoch: 5, i:  1899] avg mini-batch loss: 0.416\n",
      "[epoch: 5, i:  1999] avg mini-batch loss: 0.479\n",
      "[epoch: 5, i:  2099] avg mini-batch loss: 0.487\n",
      "[epoch: 5, i:  2199] avg mini-batch loss: 0.432\n",
      "[epoch: 5, i:  2299] avg mini-batch loss: 0.416\n",
      "[epoch: 5, i:  2399] avg mini-batch loss: 0.351\n",
      "[epoch: 5, i:  2499] avg mini-batch loss: 0.386\n",
      "[epoch: 5, i:  2599] avg mini-batch loss: 0.357\n",
      "[epoch: 5, i:  2699] avg mini-batch loss: 0.375\n",
      "[epoch: 5, i:  2799] avg mini-batch loss: 0.389\n",
      "[epoch: 5, i:  2899] avg mini-batch loss: 0.471\n",
      "[epoch: 5, i:  2999] avg mini-batch loss: 0.375\n",
      "[epoch: 5, i:  3099] avg mini-batch loss: 0.348\n",
      "[epoch: 5, i:  3199] avg mini-batch loss: 0.560\n",
      "[epoch: 5, i:  3299] avg mini-batch loss: 0.467\n",
      "[epoch: 5, i:  3399] avg mini-batch loss: 0.419\n",
      "[epoch: 5, i:  3499] avg mini-batch loss: 0.415\n",
      "[epoch: 5, i:  3599] avg mini-batch loss: 0.402\n",
      "[epoch: 5, i:  3699] avg mini-batch loss: 0.436\n",
      "[epoch: 5, i:  3799] avg mini-batch loss: 0.499\n",
      "[epoch: 5, i:  3899] avg mini-batch loss: 0.458\n",
      "[epoch: 5, i:  3999] avg mini-batch loss: 0.516\n",
      "[epoch: 5, i:  4099] avg mini-batch loss: 0.393\n",
      "[epoch: 5, i:  4199] avg mini-batch loss: 0.367\n",
      "[epoch: 5, i:  4299] avg mini-batch loss: 0.429\n",
      "[epoch: 5, i:  4399] avg mini-batch loss: 0.472\n",
      "[epoch: 5, i:  4499] avg mini-batch loss: 0.483\n",
      "[epoch: 5, i:  4599] avg mini-batch loss: 0.350\n",
      "[epoch: 5, i:  4699] avg mini-batch loss: 0.439\n",
      "[epoch: 5, i:  4799] avg mini-batch loss: 0.450\n",
      "[epoch: 5, i:  4899] avg mini-batch loss: 0.440\n",
      "[epoch: 5, i:  4999] avg mini-batch loss: 0.426\n",
      "[epoch: 5, i:  5099] avg mini-batch loss: 0.441\n",
      "[epoch: 5, i:  5199] avg mini-batch loss: 0.477\n",
      "[epoch: 5, i:  5299] avg mini-batch loss: 0.474\n",
      "[epoch: 5, i:  5399] avg mini-batch loss: 0.409\n",
      "[epoch: 5, i:  5499] avg mini-batch loss: 0.413\n",
      "[epoch: 5, i:  5599] avg mini-batch loss: 0.447\n",
      "[epoch: 5, i:  5699] avg mini-batch loss: 0.453\n",
      "[epoch: 5, i:  5799] avg mini-batch loss: 0.380\n",
      "[epoch: 5, i:  5899] avg mini-batch loss: 0.440\n",
      "[epoch: 5, i:  5999] avg mini-batch loss: 0.462\n",
      "[epoch: 5, i:  6099] avg mini-batch loss: 0.517\n",
      "[epoch: 5, i:  6199] avg mini-batch loss: 0.502\n",
      "[epoch: 5, i:  6299] avg mini-batch loss: 0.422\n",
      "[epoch: 5, i:  6399] avg mini-batch loss: 0.412\n",
      "[epoch: 5, i:  6499] avg mini-batch loss: 0.503\n",
      "[epoch: 5, i:  6599] avg mini-batch loss: 0.433\n",
      "[epoch: 5, i:  6699] avg mini-batch loss: 0.548\n",
      "[epoch: 5, i:  6799] avg mini-batch loss: 0.357\n",
      "[epoch: 5, i:  6899] avg mini-batch loss: 0.420\n",
      "[epoch: 5, i:  6999] avg mini-batch loss: 0.439\n",
      "[epoch: 5, i:  7099] avg mini-batch loss: 0.425\n",
      "[epoch: 5, i:  7199] avg mini-batch loss: 0.436\n",
      "[epoch: 5, i:  7299] avg mini-batch loss: 0.490\n",
      "[epoch: 5, i:  7399] avg mini-batch loss: 0.372\n",
      "[epoch: 5, i:  7499] avg mini-batch loss: 0.486\n",
      "[epoch: 5, i:  7599] avg mini-batch loss: 0.408\n",
      "[epoch: 5, i:  7699] avg mini-batch loss: 0.486\n",
      "[epoch: 5, i:  7799] avg mini-batch loss: 0.483\n",
      "[epoch: 5, i:  7899] avg mini-batch loss: 0.414\n",
      "[epoch: 5, i:  7999] avg mini-batch loss: 0.360\n",
      "[epoch: 5, i:  8099] avg mini-batch loss: 0.510\n",
      "[epoch: 5, i:  8199] avg mini-batch loss: 0.473\n",
      "[epoch: 5, i:  8299] avg mini-batch loss: 0.455\n",
      "[epoch: 5, i:  8399] avg mini-batch loss: 0.396\n",
      "[epoch: 5, i:  8499] avg mini-batch loss: 0.401\n",
      "[epoch: 5, i:  8599] avg mini-batch loss: 0.483\n",
      "[epoch: 5, i:  8699] avg mini-batch loss: 0.442\n",
      "[epoch: 5, i:  8799] avg mini-batch loss: 0.451\n",
      "[epoch: 5, i:  8899] avg mini-batch loss: 0.536\n",
      "[epoch: 5, i:  8999] avg mini-batch loss: 0.460\n",
      "[epoch: 5, i:  9099] avg mini-batch loss: 0.495\n",
      "[epoch: 5, i:  9199] avg mini-batch loss: 0.515\n",
      "[epoch: 5, i:  9299] avg mini-batch loss: 0.463\n",
      "[epoch: 5, i:  9399] avg mini-batch loss: 0.453\n",
      "[epoch: 5, i:  9499] avg mini-batch loss: 0.551\n",
      "[epoch: 5, i:  9599] avg mini-batch loss: 0.507\n",
      "[epoch: 5, i:  9699] avg mini-batch loss: 0.462\n",
      "[epoch: 5, i:  9799] avg mini-batch loss: 0.403\n",
      "[epoch: 5, i:  9899] avg mini-batch loss: 0.470\n",
      "[epoch: 5, i:  9999] avg mini-batch loss: 0.415\n",
      "[epoch: 5, i: 10099] avg mini-batch loss: 0.483\n",
      "[epoch: 5, i: 10199] avg mini-batch loss: 0.511\n",
      "[epoch: 5, i: 10299] avg mini-batch loss: 0.517\n",
      "[epoch: 5, i: 10399] avg mini-batch loss: 0.436\n",
      "[epoch: 5, i: 10499] avg mini-batch loss: 0.470\n",
      "[epoch: 5, i: 10599] avg mini-batch loss: 0.532\n",
      "[epoch: 5, i: 10699] avg mini-batch loss: 0.429\n",
      "[epoch: 5, i: 10799] avg mini-batch loss: 0.504\n",
      "[epoch: 5, i: 10899] avg mini-batch loss: 0.419\n",
      "[epoch: 5, i: 10999] avg mini-batch loss: 0.536\n",
      "[epoch: 5, i: 11099] avg mini-batch loss: 0.444\n",
      "[epoch: 5, i: 11199] avg mini-batch loss: 0.509\n",
      "[epoch: 5, i: 11299] avg mini-batch loss: 0.378\n",
      "[epoch: 5, i: 11399] avg mini-batch loss: 0.442\n",
      "[epoch: 5, i: 11499] avg mini-batch loss: 0.486\n",
      "[epoch: 5, i: 11599] avg mini-batch loss: 0.426\n",
      "[epoch: 5, i: 11699] avg mini-batch loss: 0.474\n",
      "[epoch: 5, i: 11799] avg mini-batch loss: 0.469\n",
      "[epoch: 5, i: 11899] avg mini-batch loss: 0.493\n",
      "[epoch: 5, i: 11999] avg mini-batch loss: 0.486\n",
      "[epoch: 5, i: 12099] avg mini-batch loss: 0.451\n",
      "[epoch: 5, i: 12199] avg mini-batch loss: 0.432\n",
      "[epoch: 5, i: 12299] avg mini-batch loss: 0.496\n",
      "[epoch: 5, i: 12399] avg mini-batch loss: 0.472\n",
      "[epoch: 5, i: 12499] avg mini-batch loss: 0.471\n",
      "[epoch: 6, i:    99] avg mini-batch loss: 0.267\n",
      "[epoch: 6, i:   199] avg mini-batch loss: 0.299\n",
      "[epoch: 6, i:   299] avg mini-batch loss: 0.330\n",
      "[epoch: 6, i:   399] avg mini-batch loss: 0.319\n",
      "[epoch: 6, i:   499] avg mini-batch loss: 0.342\n",
      "[epoch: 6, i:   599] avg mini-batch loss: 0.283\n",
      "[epoch: 6, i:   699] avg mini-batch loss: 0.308\n",
      "[epoch: 6, i:   799] avg mini-batch loss: 0.291\n",
      "[epoch: 6, i:   899] avg mini-batch loss: 0.307\n",
      "[epoch: 6, i:   999] avg mini-batch loss: 0.302\n",
      "[epoch: 6, i:  1099] avg mini-batch loss: 0.356\n",
      "[epoch: 6, i:  1199] avg mini-batch loss: 0.291\n",
      "[epoch: 6, i:  1299] avg mini-batch loss: 0.359\n",
      "[epoch: 6, i:  1399] avg mini-batch loss: 0.281\n",
      "[epoch: 6, i:  1499] avg mini-batch loss: 0.279\n",
      "[epoch: 6, i:  1599] avg mini-batch loss: 0.368\n",
      "[epoch: 6, i:  1699] avg mini-batch loss: 0.356\n",
      "[epoch: 6, i:  1799] avg mini-batch loss: 0.396\n",
      "[epoch: 6, i:  1899] avg mini-batch loss: 0.356\n",
      "[epoch: 6, i:  1999] avg mini-batch loss: 0.260\n",
      "[epoch: 6, i:  2099] avg mini-batch loss: 0.337\n",
      "[epoch: 6, i:  2199] avg mini-batch loss: 0.325\n",
      "[epoch: 6, i:  2299] avg mini-batch loss: 0.394\n",
      "[epoch: 6, i:  2399] avg mini-batch loss: 0.339\n",
      "[epoch: 6, i:  2499] avg mini-batch loss: 0.398\n",
      "[epoch: 6, i:  2599] avg mini-batch loss: 0.331\n",
      "[epoch: 6, i:  2699] avg mini-batch loss: 0.303\n",
      "[epoch: 6, i:  2799] avg mini-batch loss: 0.355\n",
      "[epoch: 6, i:  2899] avg mini-batch loss: 0.377\n",
      "[epoch: 6, i:  2999] avg mini-batch loss: 0.293\n",
      "[epoch: 6, i:  3099] avg mini-batch loss: 0.301\n",
      "[epoch: 6, i:  3199] avg mini-batch loss: 0.352\n",
      "[epoch: 6, i:  3299] avg mini-batch loss: 0.348\n",
      "[epoch: 6, i:  3399] avg mini-batch loss: 0.339\n",
      "[epoch: 6, i:  3499] avg mini-batch loss: 0.305\n",
      "[epoch: 6, i:  3599] avg mini-batch loss: 0.396\n",
      "[epoch: 6, i:  3699] avg mini-batch loss: 0.362\n",
      "[epoch: 6, i:  3799] avg mini-batch loss: 0.385\n",
      "[epoch: 6, i:  3899] avg mini-batch loss: 0.421\n",
      "[epoch: 6, i:  3999] avg mini-batch loss: 0.325\n",
      "[epoch: 6, i:  4099] avg mini-batch loss: 0.275\n",
      "[epoch: 6, i:  4199] avg mini-batch loss: 0.347\n",
      "[epoch: 6, i:  4299] avg mini-batch loss: 0.411\n",
      "[epoch: 6, i:  4399] avg mini-batch loss: 0.323\n",
      "[epoch: 6, i:  4499] avg mini-batch loss: 0.382\n",
      "[epoch: 6, i:  4599] avg mini-batch loss: 0.293\n",
      "[epoch: 6, i:  4699] avg mini-batch loss: 0.262\n",
      "[epoch: 6, i:  4799] avg mini-batch loss: 0.387\n",
      "[epoch: 6, i:  4899] avg mini-batch loss: 0.412\n",
      "[epoch: 6, i:  4999] avg mini-batch loss: 0.323\n",
      "[epoch: 6, i:  5099] avg mini-batch loss: 0.351\n",
      "[epoch: 6, i:  5199] avg mini-batch loss: 0.349\n",
      "[epoch: 6, i:  5299] avg mini-batch loss: 0.298\n",
      "[epoch: 6, i:  5399] avg mini-batch loss: 0.341\n",
      "[epoch: 6, i:  5499] avg mini-batch loss: 0.305\n",
      "[epoch: 6, i:  5599] avg mini-batch loss: 0.358\n",
      "[epoch: 6, i:  5699] avg mini-batch loss: 0.390\n",
      "[epoch: 6, i:  5799] avg mini-batch loss: 0.332\n",
      "[epoch: 6, i:  5899] avg mini-batch loss: 0.393\n",
      "[epoch: 6, i:  5999] avg mini-batch loss: 0.362\n",
      "[epoch: 6, i:  6099] avg mini-batch loss: 0.298\n",
      "[epoch: 6, i:  6199] avg mini-batch loss: 0.361\n",
      "[epoch: 6, i:  6299] avg mini-batch loss: 0.372\n",
      "[epoch: 6, i:  6399] avg mini-batch loss: 0.348\n",
      "[epoch: 6, i:  6499] avg mini-batch loss: 0.344\n",
      "[epoch: 6, i:  6599] avg mini-batch loss: 0.442\n",
      "[epoch: 6, i:  6699] avg mini-batch loss: 0.375\n",
      "[epoch: 6, i:  6799] avg mini-batch loss: 0.339\n",
      "[epoch: 6, i:  6899] avg mini-batch loss: 0.400\n",
      "[epoch: 6, i:  6999] avg mini-batch loss: 0.389\n",
      "[epoch: 6, i:  7099] avg mini-batch loss: 0.411\n",
      "[epoch: 6, i:  7199] avg mini-batch loss: 0.362\n",
      "[epoch: 6, i:  7299] avg mini-batch loss: 0.268\n",
      "[epoch: 6, i:  7399] avg mini-batch loss: 0.272\n",
      "[epoch: 6, i:  7499] avg mini-batch loss: 0.267\n",
      "[epoch: 6, i:  7599] avg mini-batch loss: 0.435\n",
      "[epoch: 6, i:  7699] avg mini-batch loss: 0.449\n",
      "[epoch: 6, i:  7799] avg mini-batch loss: 0.388\n",
      "[epoch: 6, i:  7899] avg mini-batch loss: 0.353\n",
      "[epoch: 6, i:  7999] avg mini-batch loss: 0.311\n",
      "[epoch: 6, i:  8099] avg mini-batch loss: 0.390\n",
      "[epoch: 6, i:  8199] avg mini-batch loss: 0.356\n",
      "[epoch: 6, i:  8299] avg mini-batch loss: 0.296\n",
      "[epoch: 6, i:  8399] avg mini-batch loss: 0.430\n",
      "[epoch: 6, i:  8499] avg mini-batch loss: 0.359\n",
      "[epoch: 6, i:  8599] avg mini-batch loss: 0.367\n",
      "[epoch: 6, i:  8699] avg mini-batch loss: 0.308\n",
      "[epoch: 6, i:  8799] avg mini-batch loss: 0.356\n",
      "[epoch: 6, i:  8899] avg mini-batch loss: 0.345\n",
      "[epoch: 6, i:  8999] avg mini-batch loss: 0.305\n",
      "[epoch: 6, i:  9099] avg mini-batch loss: 0.321\n",
      "[epoch: 6, i:  9199] avg mini-batch loss: 0.370\n",
      "[epoch: 6, i:  9299] avg mini-batch loss: 0.335\n",
      "[epoch: 6, i:  9399] avg mini-batch loss: 0.390\n",
      "[epoch: 6, i:  9499] avg mini-batch loss: 0.410\n",
      "[epoch: 6, i:  9599] avg mini-batch loss: 0.353\n",
      "[epoch: 6, i:  9699] avg mini-batch loss: 0.378\n",
      "[epoch: 6, i:  9799] avg mini-batch loss: 0.398\n",
      "[epoch: 6, i:  9899] avg mini-batch loss: 0.340\n",
      "[epoch: 6, i:  9999] avg mini-batch loss: 0.321\n",
      "[epoch: 6, i: 10099] avg mini-batch loss: 0.435\n",
      "[epoch: 6, i: 10199] avg mini-batch loss: 0.438\n",
      "[epoch: 6, i: 10299] avg mini-batch loss: 0.344\n",
      "[epoch: 6, i: 10399] avg mini-batch loss: 0.362\n",
      "[epoch: 6, i: 10499] avg mini-batch loss: 0.353\n",
      "[epoch: 6, i: 10599] avg mini-batch loss: 0.374\n",
      "[epoch: 6, i: 10699] avg mini-batch loss: 0.346\n",
      "[epoch: 6, i: 10799] avg mini-batch loss: 0.394\n",
      "[epoch: 6, i: 10899] avg mini-batch loss: 0.295\n",
      "[epoch: 6, i: 10999] avg mini-batch loss: 0.380\n",
      "[epoch: 6, i: 11099] avg mini-batch loss: 0.387\n",
      "[epoch: 6, i: 11199] avg mini-batch loss: 0.439\n",
      "[epoch: 6, i: 11299] avg mini-batch loss: 0.357\n",
      "[epoch: 6, i: 11399] avg mini-batch loss: 0.382\n",
      "[epoch: 6, i: 11499] avg mini-batch loss: 0.303\n",
      "[epoch: 6, i: 11599] avg mini-batch loss: 0.412\n",
      "[epoch: 6, i: 11699] avg mini-batch loss: 0.423\n",
      "[epoch: 6, i: 11799] avg mini-batch loss: 0.392\n",
      "[epoch: 6, i: 11899] avg mini-batch loss: 0.409\n",
      "[epoch: 6, i: 11999] avg mini-batch loss: 0.345\n",
      "[epoch: 6, i: 12099] avg mini-batch loss: 0.362\n",
      "[epoch: 6, i: 12199] avg mini-batch loss: 0.427\n",
      "[epoch: 6, i: 12299] avg mini-batch loss: 0.363\n",
      "[epoch: 6, i: 12399] avg mini-batch loss: 0.351\n",
      "[epoch: 6, i: 12499] avg mini-batch loss: 0.380\n",
      "[epoch: 7, i:    99] avg mini-batch loss: 0.279\n",
      "[epoch: 7, i:   199] avg mini-batch loss: 0.209\n",
      "[epoch: 7, i:   299] avg mini-batch loss: 0.212\n",
      "[epoch: 7, i:   399] avg mini-batch loss: 0.176\n",
      "[epoch: 7, i:   499] avg mini-batch loss: 0.268\n",
      "[epoch: 7, i:   599] avg mini-batch loss: 0.204\n",
      "[epoch: 7, i:   699] avg mini-batch loss: 0.283\n",
      "[epoch: 7, i:   799] avg mini-batch loss: 0.262\n",
      "[epoch: 7, i:   899] avg mini-batch loss: 0.241\n",
      "[epoch: 7, i:   999] avg mini-batch loss: 0.167\n",
      "[epoch: 7, i:  1099] avg mini-batch loss: 0.263\n",
      "[epoch: 7, i:  1199] avg mini-batch loss: 0.205\n",
      "[epoch: 7, i:  1299] avg mini-batch loss: 0.201\n",
      "[epoch: 7, i:  1399] avg mini-batch loss: 0.211\n",
      "[epoch: 7, i:  1499] avg mini-batch loss: 0.245\n",
      "[epoch: 7, i:  1599] avg mini-batch loss: 0.233\n",
      "[epoch: 7, i:  1699] avg mini-batch loss: 0.223\n",
      "[epoch: 7, i:  1799] avg mini-batch loss: 0.193\n",
      "[epoch: 7, i:  1899] avg mini-batch loss: 0.230\n",
      "[epoch: 7, i:  1999] avg mini-batch loss: 0.233\n",
      "[epoch: 7, i:  2099] avg mini-batch loss: 0.259\n",
      "[epoch: 7, i:  2199] avg mini-batch loss: 0.206\n",
      "[epoch: 7, i:  2299] avg mini-batch loss: 0.233\n",
      "[epoch: 7, i:  2399] avg mini-batch loss: 0.258\n",
      "[epoch: 7, i:  2499] avg mini-batch loss: 0.234\n",
      "[epoch: 7, i:  2599] avg mini-batch loss: 0.328\n",
      "[epoch: 7, i:  2699] avg mini-batch loss: 0.294\n",
      "[epoch: 7, i:  2799] avg mini-batch loss: 0.295\n",
      "[epoch: 7, i:  2899] avg mini-batch loss: 0.245\n",
      "[epoch: 7, i:  2999] avg mini-batch loss: 0.243\n",
      "[epoch: 7, i:  3099] avg mini-batch loss: 0.292\n",
      "[epoch: 7, i:  3199] avg mini-batch loss: 0.253\n",
      "[epoch: 7, i:  3299] avg mini-batch loss: 0.321\n",
      "[epoch: 7, i:  3399] avg mini-batch loss: 0.277\n",
      "[epoch: 7, i:  3499] avg mini-batch loss: 0.250\n",
      "[epoch: 7, i:  3599] avg mini-batch loss: 0.331\n",
      "[epoch: 7, i:  3699] avg mini-batch loss: 0.305\n",
      "[epoch: 7, i:  3799] avg mini-batch loss: 0.270\n",
      "[epoch: 7, i:  3899] avg mini-batch loss: 0.283\n",
      "[epoch: 7, i:  3999] avg mini-batch loss: 0.277\n",
      "[epoch: 7, i:  4099] avg mini-batch loss: 0.223\n",
      "[epoch: 7, i:  4199] avg mini-batch loss: 0.184\n",
      "[epoch: 7, i:  4299] avg mini-batch loss: 0.274\n",
      "[epoch: 7, i:  4399] avg mini-batch loss: 0.296\n",
      "[epoch: 7, i:  4499] avg mini-batch loss: 0.283\n",
      "[epoch: 7, i:  4599] avg mini-batch loss: 0.273\n",
      "[epoch: 7, i:  4699] avg mini-batch loss: 0.246\n",
      "[epoch: 7, i:  4799] avg mini-batch loss: 0.271\n",
      "[epoch: 7, i:  4899] avg mini-batch loss: 0.265\n",
      "[epoch: 7, i:  4999] avg mini-batch loss: 0.253\n",
      "[epoch: 7, i:  5099] avg mini-batch loss: 0.302\n",
      "[epoch: 7, i:  5199] avg mini-batch loss: 0.207\n",
      "[epoch: 7, i:  5299] avg mini-batch loss: 0.257\n",
      "[epoch: 7, i:  5399] avg mini-batch loss: 0.265\n",
      "[epoch: 7, i:  5499] avg mini-batch loss: 0.326\n",
      "[epoch: 7, i:  5599] avg mini-batch loss: 0.269\n",
      "[epoch: 7, i:  5699] avg mini-batch loss: 0.360\n",
      "[epoch: 7, i:  5799] avg mini-batch loss: 0.308\n",
      "[epoch: 7, i:  5899] avg mini-batch loss: 0.246\n",
      "[epoch: 7, i:  5999] avg mini-batch loss: 0.215\n",
      "[epoch: 7, i:  6099] avg mini-batch loss: 0.332\n",
      "[epoch: 7, i:  6199] avg mini-batch loss: 0.265\n",
      "[epoch: 7, i:  6299] avg mini-batch loss: 0.264\n",
      "[epoch: 7, i:  6399] avg mini-batch loss: 0.270\n",
      "[epoch: 7, i:  6499] avg mini-batch loss: 0.353\n",
      "[epoch: 7, i:  6599] avg mini-batch loss: 0.247\n",
      "[epoch: 7, i:  6699] avg mini-batch loss: 0.211\n",
      "[epoch: 7, i:  6799] avg mini-batch loss: 0.281\n",
      "[epoch: 7, i:  6899] avg mini-batch loss: 0.257\n",
      "[epoch: 7, i:  6999] avg mini-batch loss: 0.216\n",
      "[epoch: 7, i:  7099] avg mini-batch loss: 0.305\n",
      "[epoch: 7, i:  7199] avg mini-batch loss: 0.301\n",
      "[epoch: 7, i:  7299] avg mini-batch loss: 0.300\n",
      "[epoch: 7, i:  7399] avg mini-batch loss: 0.260\n",
      "[epoch: 7, i:  7499] avg mini-batch loss: 0.315\n",
      "[epoch: 7, i:  7599] avg mini-batch loss: 0.299\n",
      "[epoch: 7, i:  7699] avg mini-batch loss: 0.282\n",
      "[epoch: 7, i:  7799] avg mini-batch loss: 0.280\n",
      "[epoch: 7, i:  7899] avg mini-batch loss: 0.290\n",
      "[epoch: 7, i:  7999] avg mini-batch loss: 0.260\n",
      "[epoch: 7, i:  8099] avg mini-batch loss: 0.289\n",
      "[epoch: 7, i:  8199] avg mini-batch loss: 0.272\n",
      "[epoch: 7, i:  8299] avg mini-batch loss: 0.259\n",
      "[epoch: 7, i:  8399] avg mini-batch loss: 0.307\n",
      "[epoch: 7, i:  8499] avg mini-batch loss: 0.311\n",
      "[epoch: 7, i:  8599] avg mini-batch loss: 0.300\n",
      "[epoch: 7, i:  8699] avg mini-batch loss: 0.271\n",
      "[epoch: 7, i:  8799] avg mini-batch loss: 0.213\n",
      "[epoch: 7, i:  8899] avg mini-batch loss: 0.305\n",
      "[epoch: 7, i:  8999] avg mini-batch loss: 0.266\n",
      "[epoch: 7, i:  9099] avg mini-batch loss: 0.311\n",
      "[epoch: 7, i:  9199] avg mini-batch loss: 0.292\n",
      "[epoch: 7, i:  9299] avg mini-batch loss: 0.258\n",
      "[epoch: 7, i:  9399] avg mini-batch loss: 0.247\n",
      "[epoch: 7, i:  9499] avg mini-batch loss: 0.393\n",
      "[epoch: 7, i:  9599] avg mini-batch loss: 0.227\n",
      "[epoch: 7, i:  9699] avg mini-batch loss: 0.287\n",
      "[epoch: 7, i:  9799] avg mini-batch loss: 0.278\n",
      "[epoch: 7, i:  9899] avg mini-batch loss: 0.297\n",
      "[epoch: 7, i:  9999] avg mini-batch loss: 0.250\n",
      "[epoch: 7, i: 10099] avg mini-batch loss: 0.325\n",
      "[epoch: 7, i: 10199] avg mini-batch loss: 0.291\n",
      "[epoch: 7, i: 10299] avg mini-batch loss: 0.289\n",
      "[epoch: 7, i: 10399] avg mini-batch loss: 0.344\n",
      "[epoch: 7, i: 10499] avg mini-batch loss: 0.275\n",
      "[epoch: 7, i: 10599] avg mini-batch loss: 0.221\n",
      "[epoch: 7, i: 10699] avg mini-batch loss: 0.299\n",
      "[epoch: 7, i: 10799] avg mini-batch loss: 0.373\n",
      "[epoch: 7, i: 10899] avg mini-batch loss: 0.321\n",
      "[epoch: 7, i: 10999] avg mini-batch loss: 0.333\n",
      "[epoch: 7, i: 11099] avg mini-batch loss: 0.346\n",
      "[epoch: 7, i: 11199] avg mini-batch loss: 0.273\n",
      "[epoch: 7, i: 11299] avg mini-batch loss: 0.328\n",
      "[epoch: 7, i: 11399] avg mini-batch loss: 0.308\n",
      "[epoch: 7, i: 11499] avg mini-batch loss: 0.273\n",
      "[epoch: 7, i: 11599] avg mini-batch loss: 0.307\n",
      "[epoch: 7, i: 11699] avg mini-batch loss: 0.274\n",
      "[epoch: 7, i: 11799] avg mini-batch loss: 0.334\n",
      "[epoch: 7, i: 11899] avg mini-batch loss: 0.278\n",
      "[epoch: 7, i: 11999] avg mini-batch loss: 0.276\n",
      "[epoch: 7, i: 12099] avg mini-batch loss: 0.249\n",
      "[epoch: 7, i: 12199] avg mini-batch loss: 0.226\n",
      "[epoch: 7, i: 12299] avg mini-batch loss: 0.269\n",
      "[epoch: 7, i: 12399] avg mini-batch loss: 0.269\n",
      "[epoch: 7, i: 12499] avg mini-batch loss: 0.316\n",
      "[epoch: 8, i:    99] avg mini-batch loss: 0.185\n",
      "[epoch: 8, i:   199] avg mini-batch loss: 0.161\n",
      "[epoch: 8, i:   299] avg mini-batch loss: 0.199\n",
      "[epoch: 8, i:   399] avg mini-batch loss: 0.136\n",
      "[epoch: 8, i:   499] avg mini-batch loss: 0.157\n",
      "[epoch: 8, i:   599] avg mini-batch loss: 0.248\n",
      "[epoch: 8, i:   699] avg mini-batch loss: 0.151\n",
      "[epoch: 8, i:   799] avg mini-batch loss: 0.169\n",
      "[epoch: 8, i:   899] avg mini-batch loss: 0.189\n",
      "[epoch: 8, i:   999] avg mini-batch loss: 0.130\n",
      "[epoch: 8, i:  1099] avg mini-batch loss: 0.161\n",
      "[epoch: 8, i:  1199] avg mini-batch loss: 0.190\n",
      "[epoch: 8, i:  1299] avg mini-batch loss: 0.178\n",
      "[epoch: 8, i:  1399] avg mini-batch loss: 0.185\n",
      "[epoch: 8, i:  1499] avg mini-batch loss: 0.141\n",
      "[epoch: 8, i:  1599] avg mini-batch loss: 0.186\n",
      "[epoch: 8, i:  1699] avg mini-batch loss: 0.145\n",
      "[epoch: 8, i:  1799] avg mini-batch loss: 0.141\n",
      "[epoch: 8, i:  1899] avg mini-batch loss: 0.183\n",
      "[epoch: 8, i:  1999] avg mini-batch loss: 0.168\n",
      "[epoch: 8, i:  2099] avg mini-batch loss: 0.185\n",
      "[epoch: 8, i:  2199] avg mini-batch loss: 0.219\n",
      "[epoch: 8, i:  2299] avg mini-batch loss: 0.208\n",
      "[epoch: 8, i:  2399] avg mini-batch loss: 0.195\n",
      "[epoch: 8, i:  2499] avg mini-batch loss: 0.177\n",
      "[epoch: 8, i:  2599] avg mini-batch loss: 0.110\n",
      "[epoch: 8, i:  2699] avg mini-batch loss: 0.213\n",
      "[epoch: 8, i:  2799] avg mini-batch loss: 0.169\n",
      "[epoch: 8, i:  2899] avg mini-batch loss: 0.188\n",
      "[epoch: 8, i:  2999] avg mini-batch loss: 0.168\n",
      "[epoch: 8, i:  3099] avg mini-batch loss: 0.151\n",
      "[epoch: 8, i:  3199] avg mini-batch loss: 0.148\n",
      "[epoch: 8, i:  3299] avg mini-batch loss: 0.194\n",
      "[epoch: 8, i:  3399] avg mini-batch loss: 0.260\n",
      "[epoch: 8, i:  3499] avg mini-batch loss: 0.181\n",
      "[epoch: 8, i:  3599] avg mini-batch loss: 0.126\n",
      "[epoch: 8, i:  3699] avg mini-batch loss: 0.184\n",
      "[epoch: 8, i:  3799] avg mini-batch loss: 0.177\n",
      "[epoch: 8, i:  3899] avg mini-batch loss: 0.186\n",
      "[epoch: 8, i:  3999] avg mini-batch loss: 0.192\n",
      "[epoch: 8, i:  4099] avg mini-batch loss: 0.136\n",
      "[epoch: 8, i:  4199] avg mini-batch loss: 0.193\n",
      "[epoch: 8, i:  4299] avg mini-batch loss: 0.264\n",
      "[epoch: 8, i:  4399] avg mini-batch loss: 0.274\n",
      "[epoch: 8, i:  4499] avg mini-batch loss: 0.234\n",
      "[epoch: 8, i:  4599] avg mini-batch loss: 0.252\n",
      "[epoch: 8, i:  4699] avg mini-batch loss: 0.152\n",
      "[epoch: 8, i:  4799] avg mini-batch loss: 0.177\n",
      "[epoch: 8, i:  4899] avg mini-batch loss: 0.157\n",
      "[epoch: 8, i:  4999] avg mini-batch loss: 0.252\n",
      "[epoch: 8, i:  5099] avg mini-batch loss: 0.203\n",
      "[epoch: 8, i:  5199] avg mini-batch loss: 0.223\n",
      "[epoch: 8, i:  5299] avg mini-batch loss: 0.164\n",
      "[epoch: 8, i:  5399] avg mini-batch loss: 0.215\n",
      "[epoch: 8, i:  5499] avg mini-batch loss: 0.191\n",
      "[epoch: 8, i:  5599] avg mini-batch loss: 0.157\n",
      "[epoch: 8, i:  5699] avg mini-batch loss: 0.250\n",
      "[epoch: 8, i:  5799] avg mini-batch loss: 0.181\n",
      "[epoch: 8, i:  5899] avg mini-batch loss: 0.206\n",
      "[epoch: 8, i:  5999] avg mini-batch loss: 0.196\n",
      "[epoch: 8, i:  6099] avg mini-batch loss: 0.227\n",
      "[epoch: 8, i:  6199] avg mini-batch loss: 0.153\n",
      "[epoch: 8, i:  6299] avg mini-batch loss: 0.180\n",
      "[epoch: 8, i:  6399] avg mini-batch loss: 0.139\n",
      "[epoch: 8, i:  6499] avg mini-batch loss: 0.198\n",
      "[epoch: 8, i:  6599] avg mini-batch loss: 0.251\n",
      "[epoch: 8, i:  6699] avg mini-batch loss: 0.179\n",
      "[epoch: 8, i:  6799] avg mini-batch loss: 0.185\n",
      "[epoch: 8, i:  6899] avg mini-batch loss: 0.187\n",
      "[epoch: 8, i:  6999] avg mini-batch loss: 0.321\n",
      "[epoch: 8, i:  7099] avg mini-batch loss: 0.256\n",
      "[epoch: 8, i:  7199] avg mini-batch loss: 0.152\n",
      "[epoch: 8, i:  7299] avg mini-batch loss: 0.217\n",
      "[epoch: 8, i:  7399] avg mini-batch loss: 0.248\n",
      "[epoch: 8, i:  7499] avg mini-batch loss: 0.146\n",
      "[epoch: 8, i:  7599] avg mini-batch loss: 0.162\n",
      "[epoch: 8, i:  7699] avg mini-batch loss: 0.202\n",
      "[epoch: 8, i:  7799] avg mini-batch loss: 0.229\n",
      "[epoch: 8, i:  7899] avg mini-batch loss: 0.205\n",
      "[epoch: 8, i:  7999] avg mini-batch loss: 0.192\n",
      "[epoch: 8, i:  8099] avg mini-batch loss: 0.160\n",
      "[epoch: 8, i:  8199] avg mini-batch loss: 0.207\n",
      "[epoch: 8, i:  8299] avg mini-batch loss: 0.223\n",
      "[epoch: 8, i:  8399] avg mini-batch loss: 0.263\n",
      "[epoch: 8, i:  8499] avg mini-batch loss: 0.260\n",
      "[epoch: 8, i:  8599] avg mini-batch loss: 0.206\n",
      "[epoch: 8, i:  8699] avg mini-batch loss: 0.269\n",
      "[epoch: 8, i:  8799] avg mini-batch loss: 0.217\n",
      "[epoch: 8, i:  8899] avg mini-batch loss: 0.239\n",
      "[epoch: 8, i:  8999] avg mini-batch loss: 0.296\n",
      "[epoch: 8, i:  9099] avg mini-batch loss: 0.243\n",
      "[epoch: 8, i:  9199] avg mini-batch loss: 0.220\n",
      "[epoch: 8, i:  9299] avg mini-batch loss: 0.208\n",
      "[epoch: 8, i:  9399] avg mini-batch loss: 0.229\n",
      "[epoch: 8, i:  9499] avg mini-batch loss: 0.178\n",
      "[epoch: 8, i:  9599] avg mini-batch loss: 0.186\n",
      "[epoch: 8, i:  9699] avg mini-batch loss: 0.209\n",
      "[epoch: 8, i:  9799] avg mini-batch loss: 0.180\n",
      "[epoch: 8, i:  9899] avg mini-batch loss: 0.226\n",
      "[epoch: 8, i:  9999] avg mini-batch loss: 0.231\n",
      "[epoch: 8, i: 10099] avg mini-batch loss: 0.226\n",
      "[epoch: 8, i: 10199] avg mini-batch loss: 0.219\n",
      "[epoch: 8, i: 10299] avg mini-batch loss: 0.262\n",
      "[epoch: 8, i: 10399] avg mini-batch loss: 0.222\n",
      "[epoch: 8, i: 10499] avg mini-batch loss: 0.325\n",
      "[epoch: 8, i: 10599] avg mini-batch loss: 0.213\n",
      "[epoch: 8, i: 10699] avg mini-batch loss: 0.214\n",
      "[epoch: 8, i: 10799] avg mini-batch loss: 0.198\n",
      "[epoch: 8, i: 10899] avg mini-batch loss: 0.215\n",
      "[epoch: 8, i: 10999] avg mini-batch loss: 0.201\n",
      "[epoch: 8, i: 11099] avg mini-batch loss: 0.258\n",
      "[epoch: 8, i: 11199] avg mini-batch loss: 0.202\n",
      "[epoch: 8, i: 11299] avg mini-batch loss: 0.201\n",
      "[epoch: 8, i: 11399] avg mini-batch loss: 0.206\n",
      "[epoch: 8, i: 11499] avg mini-batch loss: 0.213\n",
      "[epoch: 8, i: 11599] avg mini-batch loss: 0.270\n",
      "[epoch: 8, i: 11699] avg mini-batch loss: 0.204\n",
      "[epoch: 8, i: 11799] avg mini-batch loss: 0.252\n",
      "[epoch: 8, i: 11899] avg mini-batch loss: 0.234\n",
      "[epoch: 8, i: 11999] avg mini-batch loss: 0.243\n",
      "[epoch: 8, i: 12099] avg mini-batch loss: 0.189\n",
      "[epoch: 8, i: 12199] avg mini-batch loss: 0.173\n",
      "[epoch: 8, i: 12299] avg mini-batch loss: 0.200\n",
      "[epoch: 8, i: 12399] avg mini-batch loss: 0.169\n",
      "[epoch: 8, i: 12499] avg mini-batch loss: 0.184\n",
      "[epoch: 9, i:    99] avg mini-batch loss: 0.118\n",
      "[epoch: 9, i:   199] avg mini-batch loss: 0.157\n",
      "[epoch: 9, i:   299] avg mini-batch loss: 0.114\n",
      "[epoch: 9, i:   399] avg mini-batch loss: 0.133\n",
      "[epoch: 9, i:   499] avg mini-batch loss: 0.133\n",
      "[epoch: 9, i:   599] avg mini-batch loss: 0.077\n",
      "[epoch: 9, i:   699] avg mini-batch loss: 0.154\n",
      "[epoch: 9, i:   799] avg mini-batch loss: 0.120\n",
      "[epoch: 9, i:   899] avg mini-batch loss: 0.154\n",
      "[epoch: 9, i:   999] avg mini-batch loss: 0.102\n",
      "[epoch: 9, i:  1099] avg mini-batch loss: 0.092\n",
      "[epoch: 9, i:  1199] avg mini-batch loss: 0.098\n",
      "[epoch: 9, i:  1299] avg mini-batch loss: 0.143\n",
      "[epoch: 9, i:  1399] avg mini-batch loss: 0.109\n",
      "[epoch: 9, i:  1499] avg mini-batch loss: 0.079\n",
      "[epoch: 9, i:  1599] avg mini-batch loss: 0.121\n",
      "[epoch: 9, i:  1699] avg mini-batch loss: 0.113\n",
      "[epoch: 9, i:  1799] avg mini-batch loss: 0.119\n",
      "[epoch: 9, i:  1899] avg mini-batch loss: 0.104\n",
      "[epoch: 9, i:  1999] avg mini-batch loss: 0.085\n",
      "[epoch: 9, i:  2099] avg mini-batch loss: 0.143\n",
      "[epoch: 9, i:  2199] avg mini-batch loss: 0.185\n",
      "[epoch: 9, i:  2299] avg mini-batch loss: 0.149\n",
      "[epoch: 9, i:  2399] avg mini-batch loss: 0.151\n",
      "[epoch: 9, i:  2499] avg mini-batch loss: 0.068\n",
      "[epoch: 9, i:  2599] avg mini-batch loss: 0.157\n",
      "[epoch: 9, i:  2699] avg mini-batch loss: 0.101\n",
      "[epoch: 9, i:  2799] avg mini-batch loss: 0.207\n",
      "[epoch: 9, i:  2899] avg mini-batch loss: 0.174\n",
      "[epoch: 9, i:  2999] avg mini-batch loss: 0.126\n",
      "[epoch: 9, i:  3099] avg mini-batch loss: 0.187\n",
      "[epoch: 9, i:  3199] avg mini-batch loss: 0.129\n",
      "[epoch: 9, i:  3299] avg mini-batch loss: 0.097\n",
      "[epoch: 9, i:  3399] avg mini-batch loss: 0.178\n",
      "[epoch: 9, i:  3499] avg mini-batch loss: 0.154\n",
      "[epoch: 9, i:  3599] avg mini-batch loss: 0.139\n",
      "[epoch: 9, i:  3699] avg mini-batch loss: 0.110\n",
      "[epoch: 9, i:  3799] avg mini-batch loss: 0.110\n",
      "[epoch: 9, i:  3899] avg mini-batch loss: 0.145\n",
      "[epoch: 9, i:  3999] avg mini-batch loss: 0.110\n",
      "[epoch: 9, i:  4099] avg mini-batch loss: 0.185\n",
      "[epoch: 9, i:  4199] avg mini-batch loss: 0.157\n",
      "[epoch: 9, i:  4299] avg mini-batch loss: 0.113\n",
      "[epoch: 9, i:  4399] avg mini-batch loss: 0.127\n",
      "[epoch: 9, i:  4499] avg mini-batch loss: 0.151\n",
      "[epoch: 9, i:  4599] avg mini-batch loss: 0.082\n",
      "[epoch: 9, i:  4699] avg mini-batch loss: 0.125\n",
      "[epoch: 9, i:  4799] avg mini-batch loss: 0.120\n",
      "[epoch: 9, i:  4899] avg mini-batch loss: 0.104\n",
      "[epoch: 9, i:  4999] avg mini-batch loss: 0.148\n",
      "[epoch: 9, i:  5099] avg mini-batch loss: 0.187\n",
      "[epoch: 9, i:  5199] avg mini-batch loss: 0.089\n",
      "[epoch: 9, i:  5299] avg mini-batch loss: 0.128\n",
      "[epoch: 9, i:  5399] avg mini-batch loss: 0.103\n",
      "[epoch: 9, i:  5499] avg mini-batch loss: 0.166\n",
      "[epoch: 9, i:  5599] avg mini-batch loss: 0.129\n",
      "[epoch: 9, i:  5699] avg mini-batch loss: 0.188\n",
      "[epoch: 9, i:  5799] avg mini-batch loss: 0.179\n",
      "[epoch: 9, i:  5899] avg mini-batch loss: 0.178\n",
      "[epoch: 9, i:  5999] avg mini-batch loss: 0.144\n",
      "[epoch: 9, i:  6099] avg mini-batch loss: 0.114\n",
      "[epoch: 9, i:  6199] avg mini-batch loss: 0.220\n",
      "[epoch: 9, i:  6299] avg mini-batch loss: 0.127\n",
      "[epoch: 9, i:  6399] avg mini-batch loss: 0.109\n",
      "[epoch: 9, i:  6499] avg mini-batch loss: 0.157\n",
      "[epoch: 9, i:  6599] avg mini-batch loss: 0.178\n",
      "[epoch: 9, i:  6699] avg mini-batch loss: 0.171\n",
      "[epoch: 9, i:  6799] avg mini-batch loss: 0.183\n",
      "[epoch: 9, i:  6899] avg mini-batch loss: 0.169\n",
      "[epoch: 9, i:  6999] avg mini-batch loss: 0.183\n",
      "[epoch: 9, i:  7099] avg mini-batch loss: 0.201\n",
      "[epoch: 9, i:  7199] avg mini-batch loss: 0.166\n",
      "[epoch: 9, i:  7299] avg mini-batch loss: 0.142\n",
      "[epoch: 9, i:  7399] avg mini-batch loss: 0.188\n",
      "[epoch: 9, i:  7499] avg mini-batch loss: 0.159\n",
      "[epoch: 9, i:  7599] avg mini-batch loss: 0.181\n",
      "[epoch: 9, i:  7699] avg mini-batch loss: 0.171\n",
      "[epoch: 9, i:  7799] avg mini-batch loss: 0.176\n",
      "[epoch: 9, i:  7899] avg mini-batch loss: 0.169\n",
      "[epoch: 9, i:  7999] avg mini-batch loss: 0.141\n",
      "[epoch: 9, i:  8099] avg mini-batch loss: 0.214\n",
      "[epoch: 9, i:  8199] avg mini-batch loss: 0.218\n",
      "[epoch: 9, i:  8299] avg mini-batch loss: 0.145\n",
      "[epoch: 9, i:  8399] avg mini-batch loss: 0.125\n",
      "[epoch: 9, i:  8499] avg mini-batch loss: 0.198\n",
      "[epoch: 9, i:  8599] avg mini-batch loss: 0.175\n",
      "[epoch: 9, i:  8699] avg mini-batch loss: 0.181\n",
      "[epoch: 9, i:  8799] avg mini-batch loss: 0.120\n",
      "[epoch: 9, i:  8899] avg mini-batch loss: 0.185\n",
      "[epoch: 9, i:  8999] avg mini-batch loss: 0.199\n",
      "[epoch: 9, i:  9099] avg mini-batch loss: 0.218\n",
      "[epoch: 9, i:  9199] avg mini-batch loss: 0.177\n",
      "[epoch: 9, i:  9299] avg mini-batch loss: 0.159\n",
      "[epoch: 9, i:  9399] avg mini-batch loss: 0.119\n",
      "[epoch: 9, i:  9499] avg mini-batch loss: 0.137\n",
      "[epoch: 9, i:  9599] avg mini-batch loss: 0.129\n",
      "[epoch: 9, i:  9699] avg mini-batch loss: 0.205\n",
      "[epoch: 9, i:  9799] avg mini-batch loss: 0.235\n",
      "[epoch: 9, i:  9899] avg mini-batch loss: 0.136\n",
      "[epoch: 9, i:  9999] avg mini-batch loss: 0.196\n",
      "[epoch: 9, i: 10099] avg mini-batch loss: 0.172\n",
      "[epoch: 9, i: 10199] avg mini-batch loss: 0.193\n",
      "[epoch: 9, i: 10299] avg mini-batch loss: 0.195\n",
      "[epoch: 9, i: 10399] avg mini-batch loss: 0.158\n",
      "[epoch: 9, i: 10499] avg mini-batch loss: 0.266\n",
      "[epoch: 9, i: 10599] avg mini-batch loss: 0.178\n",
      "[epoch: 9, i: 10699] avg mini-batch loss: 0.175\n",
      "[epoch: 9, i: 10799] avg mini-batch loss: 0.166\n",
      "[epoch: 9, i: 10899] avg mini-batch loss: 0.172\n",
      "[epoch: 9, i: 10999] avg mini-batch loss: 0.191\n",
      "[epoch: 9, i: 11099] avg mini-batch loss: 0.143\n",
      "[epoch: 9, i: 11199] avg mini-batch loss: 0.274\n",
      "[epoch: 9, i: 11299] avg mini-batch loss: 0.178\n",
      "[epoch: 9, i: 11399] avg mini-batch loss: 0.210\n",
      "[epoch: 9, i: 11499] avg mini-batch loss: 0.221\n",
      "[epoch: 9, i: 11599] avg mini-batch loss: 0.121\n",
      "[epoch: 9, i: 11699] avg mini-batch loss: 0.124\n",
      "[epoch: 9, i: 11799] avg mini-batch loss: 0.130\n",
      "[epoch: 9, i: 11899] avg mini-batch loss: 0.162\n",
      "[epoch: 9, i: 11999] avg mini-batch loss: 0.192\n",
      "[epoch: 9, i: 12099] avg mini-batch loss: 0.150\n",
      "[epoch: 9, i: 12199] avg mini-batch loss: 0.244\n",
      "[epoch: 9, i: 12299] avg mini-batch loss: 0.123\n",
      "[epoch: 9, i: 12399] avg mini-batch loss: 0.217\n",
      "[epoch: 9, i: 12499] avg mini-batch loss: 0.224\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = []   # Avg. losses.\n",
    "epochs = 10       # Total epochs.\n",
    "print_freq = 100  # Print frequency.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_loss = 0.0       # Initialize running loss.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step.\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # Print statistics.\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n",
    "                epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 79 %\n"
     ]
    }
   ],
   "source": [
    "# Get test accuracy.\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
